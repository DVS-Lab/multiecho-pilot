{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23aafd6-7423-4a1a-8fc2-f575b6c70300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5057e-9dcf-4209-8753-dce819f6f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole-brain TSNR data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv')\n",
    "\n",
    "# Load the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Display the header (first 5 rows) and column names\n",
    "    print(\"Column names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Display basic info about the data\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c278d-98e3-4f40-b476-3058b0c7e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics for whole-brain TSNR data\n",
    "import pandas as pd\n",
    "import os\n",
    "from pymer4.models import Lmer\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv')\n",
    "\n",
    "# Load the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Preprocess the data\n",
    "data = data.rename(columns={\n",
    "    'Subject': 'Subj',\n",
    "    'ReceiveCoilName': 'HC',\n",
    "    'tsnrMedian': 'TSNR'\n",
    "})\n",
    "\n",
    "# Extract MB and ME from AcquisitionType\n",
    "data['MB'] = data['AcquisitionType'].str.extract(r'(mb\\d+)')[0]\n",
    "data['ME'] = data['AcquisitionType'].str.extract(r'(me\\d+)')[0]\n",
    "\n",
    "# Convert to categorical\n",
    "data['HC'] = pd.Categorical(data['HC'], categories=[20, 64])\n",
    "data['MB'] = pd.Categorical(data['MB'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data['ME'] = pd.Categorical(data['ME'], categories=['me1', 'me4'])\n",
    "data['Subj'] = data['Subj'].astype(str)\n",
    "\n",
    "# Filter out invalid rows and 'sp' subjects\n",
    "data = data.dropna(subset=['TSNR', 'HC', 'MB', 'ME', 'Subj'])\n",
    "data = data[~data['Subj'].str.contains('sp', na=False)]\n",
    "\n",
    "# Print data summary\n",
    "print(\"Data summary (unique subjects per condition):\")\n",
    "print(data.groupby(['HC', 'MB', 'ME'], observed=True)['Subj'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data.copy()\n",
    "data_model['HC'] = data_model['HC'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['MB'] = pd.Categorical(data_model['MB'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['ME'] = pd.Categorical(data_model['ME'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer('TSNR ~ HC * MB * ME + (1 | Subj)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary for debugging\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'HC': 'Head Coil',\n",
    "    'MB': 'Multiband',\n",
    "    'ME': 'Multi-echo',\n",
    "    'HC:MB': 'Head Coil × Multiband',\n",
    "    'HC:ME': 'Head Coil × Multi-echo',\n",
    "    'MB:ME': 'Multiband × Multi-echo',\n",
    "    'HC:MB:ME': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "# Extract residual variance from model.ranef_var\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    # Fallback: Use second row (index 1) for residual variance\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['Subj'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model (TSNR ~ HC * MB * ME + (1 | Subj)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9427c-b2f2-4dd9-b491-4915c77c6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-smoothed data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/smoothness-all-zero.csv')\n",
    "\n",
    "# Load the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Display the header (first 5 rows) and column names\n",
    "    print(\"Column names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Display basic info about the data\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0fc13b-e1fb-4126-ae39-527068f2f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for pre-smoothed data\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/smoothness-all-zero.csv')\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "# Load and process the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Debug: Print raw data info\n",
    "    print(\"\\nRaw data info:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nFirst 10 rows of raw data:\")\n",
    "    print(data.head(10))\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    data = data.rename(columns={\n",
    "        data.columns[0]: 'path',\n",
    "        'Unnamed: 3': 'smoothness'\n",
    "    })\n",
    "    \n",
    "    # Shift path column to align file paths with previous row's smoothness\n",
    "    data['file_path'] = data['path'].shift(-1)\n",
    "    \n",
    "    # Filter rows with non-null smoothness\n",
    "    data = data[data['smoothness'].notnull()]\n",
    "    print(f\"\\nAfter filtering non-null smoothness: {len(data)} rows\")\n",
    "    \n",
    "    # Debug: Print data with shifted paths\n",
    "    print(\"\\nData with shifted paths (first 5 rows):\")\n",
    "    print(data[['path', 'file_path', 'smoothness']].head())\n",
    "    \n",
    "    # Extract subject, mb, and me from file_path\n",
    "    def parse_path(path):\n",
    "        try:\n",
    "            if not isinstance(path, str):\n",
    "                return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "            sub_match = re.search(r'sub-(\\d+)', path)\n",
    "            acq_match = re.search(r'acq-(mb\\dme\\d)', path)\n",
    "            subject = sub_match.group(1) if sub_match else None\n",
    "            acq = acq_match.group(1) if acq_match else None\n",
    "            if acq:\n",
    "                mb = acq[:3]  # e.g., mb1\n",
    "                me = acq[3:]  # e.g., me1\n",
    "            else:\n",
    "                mb = None\n",
    "                me = None\n",
    "            return pd.Series({'subject': subject, 'mb': mb, 'me': me})\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing path {path}: {str(e)}\")\n",
    "            return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "    \n",
    "    # Apply parsing to file_path\n",
    "    parsed_data = data['file_path'].apply(parse_path)\n",
    "    data = pd.concat([data, parsed_data], axis=1)\n",
    "    \n",
    "    # Debug: Print parsing results\n",
    "    print(f\"\\nAfter parsing: {len(data)} rows\")\n",
    "    print(\"\\nParsed data (first 5 rows):\")\n",
    "    print(data[['file_path', 'subject', 'mb', 'me', 'smoothness']].head())\n",
    "    \n",
    "    # Assign headcoil\n",
    "    data['headcoil'] = data['subject'].apply(lambda x: '64' if x in HEADCOIL_64_SUBJECTS else '20' if x else None)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    data = data[['subject', 'headcoil', 'mb', 'me', 'smoothness']]\n",
    "    \n",
    "    # Convert to categorical\n",
    "    data['headcoil'] = pd.Categorical(data['headcoil'], categories=['20', '64'])\n",
    "    data['mb'] = pd.Categorical(data['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "    data['me'] = pd.Categorical(data['me'], categories=['me1', 'me4'])\n",
    "    data['subject'] = data['subject'].astype(str)\n",
    "    \n",
    "    # Filter out invalid rows\n",
    "    data = data.dropna(subset=['subject', 'mb', 'me', 'smoothness'])\n",
    "    data = data[~data['subject'].str.contains('sp', na=False)]\n",
    "    data = data[data['subject'] != 'nan']\n",
    "    \n",
    "    # Debug: Print final data\n",
    "    print(f\"\\nProcessed {len(data)} rows with {data['subject'].nunique()} unique subjects\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Check if data is empty\n",
    "if data.empty:\n",
    "    print(\"Error: No valid data after processing. Please check file paths and parsing logic.\")\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    raw_data = pd.read_csv(csv_path)\n",
    "    print(raw_data.head(10))\n",
    "    exit()\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer('smoothness ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model (smoothness ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('pre-smoothness_lme_anova.csv', index=False)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
   "id": "77e62eaf-28ac-4287-9f6c-fa9123972820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smoothness Values (Pre) by Subject and mb/me Combination:\n",
      "mb_me    mb1me1  mb3me1  mb6me1  mb1me4  mb3me4  mb6me4\n",
      "subject                                                \n",
      "10015       NaN   4.321   4.598     NaN     NaN     NaN\n",
      "10017     4.582   4.181   4.161   3.892   3.837   3.757\n",
      "10024     4.040   4.338   4.240   4.017   3.941   3.874\n",
      "10028     4.086     NaN     NaN   3.889   4.258   4.241\n",
      "10035     4.152   4.196   4.093   3.932   3.860   3.798\n",
      "10041     4.093   4.556   4.507   4.150   4.012   3.940\n",
      "10043     4.302   4.359   4.185   3.991   3.880   3.835\n",
      "10054     4.136   4.368   4.309   3.969   3.839   3.841\n",
      "10059     4.086   4.327   4.276   4.023   3.937   3.889\n",
      "10069     4.119   3.896   3.960   3.630   3.612   3.521\n",
      "10074     3.768   3.926   3.822   3.637   3.558   3.533\n",
      "10078     3.750   4.186   4.058   3.816   3.723   3.675\n",
      "10080     3.934   4.366   4.318   4.027   3.878   3.781\n",
      "10085     4.090   4.210   4.153   3.846   3.760   3.768\n",
      "10094     3.974   4.316   4.291   3.965   3.856   3.784\n",
      "10108     4.068   4.301   4.211   3.993   3.904   3.826\n",
      "10125     4.362   4.550   4.408   4.207   4.075   4.017\n",
      "10130     4.337   4.040   4.038   3.701   3.700   3.614\n",
      "10136     3.991   4.337   4.277   4.019   3.917   3.866\n",
      "10137     4.157   4.215   4.189   3.903   3.798   3.743\n",
      "10142     4.054   4.219   4.180   3.923   3.943   3.777\n",
      "10150     4.145   4.136   4.089   3.858   3.798   3.674\n",
      "10154     3.952   3.897   3.764   3.608   3.520   3.467\n",
      "10166     3.710   4.238   4.161   3.957   3.850   3.822\n",
      "10185     4.221   3.763   3.740   3.598   3.545   3.448\n",
      "10186     3.621   4.100   4.073   3.804   3.709   3.624\n",
      "10188     3.965   4.085   4.034   3.836   3.767   3.646\n",
      "10198       NaN   4.225   4.032   4.074   3.752   3.647\n",
      "10203     3.924   3.835   3.804   3.616   3.504   3.447\n",
      "10221     3.754   4.217   4.109   3.878   3.758   3.683\n",
      "10223     4.046   4.246   4.177   3.926   3.829   3.794\n",
      "10234     4.040   4.171   4.060   3.766   3.659   3.586\n",
      "10296     3.973   4.334   4.301   4.078   3.991   3.866\n",
      "10303     4.299   4.200   3.785   3.846     NaN   3.683\n",
      "10318     3.906   3.989   3.893   3.749   3.678   3.630\n",
      "10319     3.800   4.205   4.021   3.878   3.790   3.695\n",
      "10320     4.018   4.116   4.017   3.863   3.776   3.677\n",
      "10321     3.919   3.843   3.777   3.653   3.540   3.474\n",
      "10363     3.680   3.995   3.859   3.747   3.664   3.551\n",
      "10382     3.756   4.202   4.262   3.923   3.839   3.804\n",
      "10391     4.120   3.973   3.919   3.759   3.668   3.543\n",
      "10416     3.814   4.010   3.938   3.720   3.605   3.643\n",
      "10422     3.821   4.001   3.974   3.736   3.653   3.632\n",
      "10438     3.808   4.214   4.131   3.876   3.837   3.777\n",
      "10589       NaN   4.210     NaN     NaN   4.081     NaN\n",
      "10590       NaN   4.101     NaN     NaN   4.056     NaN\n",
      "10603       NaN   4.510     NaN     NaN   4.498     NaN\n",
      "10606       NaN   4.268     NaN     NaN   4.160     NaN\n",
      "10608       NaN   4.635     NaN     NaN   4.633     NaN\n",
      "10640       NaN   4.190     NaN     NaN   4.026     NaN\n",
      "10644       NaN   4.410     NaN     NaN   4.184     NaN\n",
      "10652     4.147   4.272   4.149     NaN     NaN     NaN\n",
      "10659       NaN   4.506     NaN     NaN   4.631     NaN\n",
      "10690       NaN   4.738     NaN     NaN   4.473     NaN\n",
      "10691       NaN   4.571     NaN     NaN   4.513     NaN\n",
      "10716     4.326   3.841   3.702     NaN     NaN     NaN\n",
      "10723       NaN   4.262     NaN     NaN   4.142     NaN\n",
      "10738       NaN   3.960   3.756     NaN     NaN     NaN\n",
      "10741       NaN   4.515     NaN     NaN   4.179     NaN\n",
      "10777       NaN   4.147     NaN     NaN   4.018     NaN\n",
      "10803       NaN   4.589     NaN     NaN   4.312     NaN\n",
      "12042     4.218   4.241   4.203   3.973   3.815   3.776\n",
      "\n",
      "Pivot table saved to 'smoothness_pivot_table.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap (if needed)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/smoothness-all-zero.csv')\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "# Load and process the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    data = data.rename(columns={\n",
    "        data.columns[0]: 'path',\n",
    "        'Unnamed: 3': 'smoothness'\n",
    "    })\n",
    "    \n",
    "    # Shift path column to align file paths with previous row's smoothness\n",
    "    data['file_path'] = data['path'].shift(-1)\n",
    "    \n",
    "    # Filter rows with non-null smoothness\n",
    "    data = data[data['smoothness'].notnull()]\n",
    "    \n",
    "    # Extract subject, mb, and me from file_path\n",
    "    def parse_path(path):\n",
    "        try:\n",
    "            if not isinstance(path, str):\n",
    "                return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "            sub_match = re.search(r'sub-(\\d+)', path)\n",
    "            acq_match = re.search(r'acq-(mb\\dme\\d)', path)\n",
    "            subject = sub_match.group(1) if sub_match else None\n",
    "            acq = acq_match.group(1) if acq_match else None\n",
    "            if acq:\n",
    "                mb = acq[:3]  # e.g., mb1\n",
    "                me = acq[3:]  # e.g., me1\n",
    "            else:\n",
    "                mb = None\n",
    "                me = None\n",
    "            return pd.Series({'subject': subject, 'mb': mb, 'me': me})\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing path {path}: {str(e)}\")\n",
    "            return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "    \n",
    "    # Apply parsing to file_path\n",
    "    parsed_data = data['file_path'].apply(parse_path)\n",
    "    data = pd.concat([data, parsed_data], axis=1)\n",
    "    \n",
    "    # Assign headcoil\n",
    "    data['headcoil'] = data['subject'].apply(lambda x: '64' if x in HEADCOIL_64_SUBJECTS else '20' if x else None)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    data = data[['subject', 'headcoil', 'mb', 'me', 'smoothness']]\n",
    "    \n",
    "    # Convert to categorical\n",
    "    data['headcoil'] = pd.Categorical(data['headcoil'], categories=['20', '64'])\n",
    "    data['mb'] = pd.Categorical(data['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "    data['me'] = pd.Categorical(data['me'], categories=['me1', 'me4'])\n",
    "    data['subject'] = data['subject'].astype(str)\n",
    "    \n",
    "    # Filter out invalid rows\n",
    "    data = data.dropna(subset=['subject', 'mb', 'me', 'smoothness'])\n",
    "    data = data[~data['subject'].str.contains('sp', na=False)]\n",
    "    data = data[data['subject'] != 'nan']\n",
    "    \n",
    "    # Create a combined mb_me column for pivoting by converting categorical to string\n",
    "    data['mb_me'] = data['mb'].astype(str) + data['me'].astype(str)\n",
    "    \n",
    "    # Pivot the data to create a table with subjects as rows and mb_me combinations as columns\n",
    "    pivot_table = data.pivot_table(\n",
    "        values='smoothness',\n",
    "        index='subject',\n",
    "        columns='mb_me',\n",
    "        aggfunc='mean'  # In case of duplicates, take the mean\n",
    "    )\n",
    "    \n",
    "    # Ensure all expected mb_me combinations are present as columns\n",
    "    expected_columns = ['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4']\n",
    "    pivot_table = pivot_table.reindex(columns=expected_columns)\n",
    "    \n",
    "    # Sort the index (subjects) for consistency\n",
    "    pivot_table = pivot_table.sort_index()\n",
    "    \n",
    "    # Round smoothness values to 3 decimal places for readability\n",
    "    pivot_table = pivot_table.round(3)\n",
    "    \n",
    "    # Print the pivot table\n",
    "    print(\"\\nSmoothness Values (Pre) by Subject and mb/me Combination:\")\n",
    "    print(pivot_table.to_string())\n",
    "    \n",
    "    # Save the pivot table to a CSV file for further inspection\n",
    "    pivot_table.to_csv('smoothness-pre_pivot_table.csv')\n",
    "    print(\"\\nPivot table saved to 'smoothness_pivot_table.csv'\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    # Debug: Print raw data sample if processing fails\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    try:\n",
    "        raw_data = pd.read_csv(csv_path)\n",
    "        print(raw_data.head(10))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Check if pivot table is empty\n",
    "if 'pivot_table' in locals() and pivot_table.empty:\n",
    "    print(\"Error: No valid data after pivoting. Please check file paths and parsing logic.\")\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    try:\n",
    "        raw_data = pd.read_csv(csv_path)\n",
    "        print(raw_data.head(10))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbf4a96-3366-444d-bbef-e3efc83fd9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subjects with Complete Data for All 6 Acquisitions (mb1me1, mb3me1, mb6me1, mb1me4, mb3me4, mb6me4):\n",
      "Total N: 41\n",
      "\n",
      "N per Headcoil:\n",
      "  Headcoil 20: 17\n",
      "  Headcoil 64: 24\n",
      "\n",
      "Found 41 subjects with complete data:\n",
      "['10017', '10024', '10035', '10041', '10043', '10054', '10059', '10069', '10074', '10078', '10080', '10085', '10094', '10108', '10125', '10130', '10136', '10137', '10142', '10150', '10154', '10166', '10185', '10186', '10188', '10203', '10221', '10223', '10234', '10296', '10318', '10319', '10320', '10321', '10363', '10382', '10391', '10416', '10422', '10438', '12042']\n",
      "\n",
      "Smoothness Values for Complete Subjects:\n",
      "mb_me    mb1me1  mb3me1  mb6me1  mb1me4  mb3me4  mb6me4\n",
      "subject                                                \n",
      "10017     4.582   4.181   4.161   3.892   3.837   3.757\n",
      "10024     4.040   4.338   4.240   4.017   3.941   3.874\n",
      "10035     4.152   4.196   4.093   3.932   3.860   3.798\n",
      "10041     4.093   4.556   4.507   4.150   4.012   3.940\n",
      "10043     4.302   4.359   4.185   3.991   3.880   3.835\n",
      "10054     4.136   4.368   4.309   3.969   3.839   3.841\n",
      "10059     4.086   4.327   4.276   4.023   3.937   3.889\n",
      "10069     4.119   3.896   3.960   3.630   3.612   3.521\n",
      "10074     3.768   3.926   3.822   3.637   3.558   3.533\n",
      "10078     3.750   4.186   4.058   3.816   3.723   3.675\n",
      "10080     3.934   4.366   4.318   4.027   3.878   3.781\n",
      "10085     4.090   4.210   4.153   3.846   3.760   3.768\n",
      "10094     3.974   4.316   4.291   3.965   3.856   3.784\n",
      "10108     4.068   4.301   4.211   3.993   3.904   3.826\n",
      "10125     4.362   4.550   4.408   4.207   4.075   4.017\n",
      "10130     4.337   4.040   4.038   3.701   3.700   3.614\n",
      "10136     3.991   4.337   4.277   4.019   3.917   3.866\n",
      "10137     4.157   4.215   4.189   3.903   3.798   3.743\n",
      "10142     4.054   4.219   4.180   3.923   3.943   3.777\n",
      "10150     4.145   4.136   4.089   3.858   3.798   3.674\n",
      "10154     3.952   3.897   3.764   3.608   3.520   3.467\n",
      "10166     3.710   4.238   4.161   3.957   3.850   3.822\n",
      "10185     4.221   3.763   3.740   3.598   3.545   3.448\n",
      "10186     3.621   4.100   4.073   3.804   3.709   3.624\n",
      "10188     3.965   4.085   4.034   3.836   3.767   3.646\n",
      "10203     3.924   3.835   3.804   3.616   3.504   3.447\n",
      "10221     3.754   4.217   4.109   3.878   3.758   3.683\n",
      "10223     4.046   4.246   4.177   3.926   3.829   3.794\n",
      "10234     4.040   4.171   4.060   3.766   3.659   3.586\n",
      "10296     3.973   4.334   4.301   4.078   3.991   3.866\n",
      "10318     3.906   3.989   3.893   3.749   3.678   3.630\n",
      "10319     3.800   4.205   4.021   3.878   3.790   3.695\n",
      "10320     4.018   4.116   4.017   3.863   3.776   3.677\n",
      "10321     3.919   3.843   3.777   3.653   3.540   3.474\n",
      "10363     3.680   3.995   3.859   3.747   3.664   3.551\n",
      "10382     3.756   4.202   4.262   3.923   3.839   3.804\n",
      "10391     4.120   3.973   3.919   3.759   3.668   3.543\n",
      "10416     3.814   4.010   3.938   3.720   3.605   3.643\n",
      "10422     3.821   4.001   3.974   3.736   3.653   3.632\n",
      "10438     3.808   4.214   4.131   3.876   3.837   3.777\n",
      "12042     4.218   4.241   4.203   3.973   3.815   3.776\n",
      "\n",
      "Complete subjects table saved to 'complete_subjects_smoothness.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap (if needed)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/smoothness-all-zero.csv')\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "# Load and process the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    data = data.rename(columns={\n",
    "        data.columns[0]: 'path',\n",
    "        'Unnamed: 3': 'smoothness'\n",
    "    })\n",
    "    \n",
    "    # Shift path column to align file paths with previous row's smoothness\n",
    "    data['file_path'] = data['path'].shift(-1)\n",
    "    \n",
    "    # Filter rows with non-null smoothness\n",
    "    data = data[data['smoothness'].notnull()]\n",
    "    \n",
    "    # Extract subject, mb, and me from file_path\n",
    "    def parse_path(path):\n",
    "        try:\n",
    "            if not isinstance(path, str):\n",
    "                return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "            sub_match = re.search(r'sub-(\\d+)', path)\n",
    "            acq_match = re.search(r'acq-(mb\\dme\\d)', path)\n",
    "            subject = sub_match.group(1) if sub_match else None\n",
    "            acq = acq_match.group(1) if acq_match else None\n",
    "            if acq:\n",
    "                mb = acq[:3]  # e.g., mb1\n",
    "                me = acq[3:]  # e.g., me1\n",
    "            else:\n",
    "                mb = None\n",
    "                me = None\n",
    "            return pd.Series({'subject': subject, 'mb': mb, 'me': me})\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing path {path}: {str(e)}\")\n",
    "            return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "    \n",
    "    # Apply parsing to file_path\n",
    "    parsed_data = data['file_path'].apply(parse_path)\n",
    "    data = pd.concat([data, parsed_data], axis=1)\n",
    "    \n",
    "    # Assign headcoil\n",
    "    data['headcoil'] = data['subject'].apply(lambda x: '64' if x in HEADCOIL_64_SUBJECTS else '20' if x else None)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    data = data[['subject', 'headcoil', 'mb', 'me', 'smoothness']]\n",
    "    \n",
    "    # Convert to categorical\n",
    "    data['headcoil'] = pd.Categorical(data['headcoil'], categories=['20', '64'])\n",
    "    data['mb'] = pd.Categorical(data['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "    data['me'] = pd.Categorical(data['me'], categories=['me1', 'me4'])\n",
    "    data['subject'] = data['subject'].astype(str)\n",
    "    \n",
    "    # Filter out invalid rows\n",
    "    data = data.dropna(subset=['subject', 'mb', 'me', 'smoothness'])\n",
    "    data = data[~data['subject'].str.contains('sp', na=False)]\n",
    "    data = data[data['subject'] != 'nan']\n",
    "    \n",
    "    # Create a combined mb_me column for pivoting\n",
    "    data['mb_me'] = data['mb'].astype(str) + data['me'].astype(str)\n",
    "    \n",
    "    # Pivot the data to create a table with subjects as rows and mb_me combinations as columns\n",
    "    pivot_table = data.pivot_table(\n",
    "        values='smoothness',\n",
    "        index='subject',\n",
    "        columns='mb_me',\n",
    "        aggfunc='mean'  # In case of duplicates, take the mean\n",
    "    )\n",
    "    \n",
    "    # Ensure all expected mb_me combinations are present as columns\n",
    "    expected_columns = ['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4']\n",
    "    pivot_table = pivot_table.reindex(columns=expected_columns)\n",
    "    \n",
    "    # Identify subjects with no NaN values across all mb_me columns\n",
    "    complete_subjects = pivot_table.dropna()\n",
    "    \n",
    "    # Sort the index (subjects) for consistency\n",
    "    complete_subjects = complete_subjects.sort_index()\n",
    "    \n",
    "    # Round smoothness values to 3 decimal places for readability\n",
    "    complete_subjects = complete_subjects.round(3)\n",
    "    \n",
    "    # Get headcoil information for complete subjects\n",
    "    # Create a DataFrame with unique subjects and their headcoil values\n",
    "    headcoil_data = data[['subject', 'headcoil']].drop_duplicates().set_index('subject')\n",
    "    # Filter to only complete subjects\n",
    "    complete_headcoil = headcoil_data.loc[complete_subjects.index]\n",
    "    \n",
    "    # Calculate total N and N per headcoil\n",
    "    total_n = len(complete_subjects)\n",
    "    headcoil_counts = complete_headcoil['headcoil'].value_counts().reindex(['20', '64'], fill_value=0)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nSubjects with Complete Data for All 6 Acquisitions (mb1me1, mb3me1, mb6me1, mb1me4, mb3me4, mb6me4):\")\n",
    "    print(f\"Total N: {total_n}\")\n",
    "    print(\"\\nN per Headcoil:\")\n",
    "    print(f\"  Headcoil 20: {headcoil_counts['20']}\")\n",
    "    print(f\"  Headcoil 64: {headcoil_counts['64']}\")\n",
    "    \n",
    "    if complete_subjects.empty:\n",
    "        print(\"\\nNo subjects have complete data for all 6 acquisitions.\")\n",
    "    else:\n",
    "        print(f\"\\nFound {total_n} subjects with complete data:\")\n",
    "        print(complete_subjects.index.tolist())\n",
    "        print(\"\\nSmoothness Values for Complete Subjects:\")\n",
    "        print(complete_subjects.to_string())\n",
    "    \n",
    "    # Save the complete subjects table to a CSV file\n",
    "    complete_subjects.to_csv('complete_subjects_smoothness.csv')\n",
    "    print(\"\\nComplete subjects table saved to 'complete_subjects_smoothness.csv'\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    # Debug: Print raw data sample if processing fails\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    try:\n",
    "        raw_data = pd.read_csv(csv_path)\n",
    "        print(raw_data.head(10))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Check if pivot table is empty\n",
    "if 'pivot_table' in locals() and pivot_table.empty:\n",
    "    print(\"Error: No valid data after pivoting. Please check file paths and parsing logic.\")\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    try:\n",
    "        raw_data = pd.read_csv(csv_path)\n",
    "        print(raw_data.head(10))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c04418-b5ac-4a06-bb81-e1e47fd44027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1559476-f1a9-49d8-abba-47d80d129a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef92f8a-d4df-4e20-873d-10d970829849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db28a36-1d84-4abd-b0b4-d3b908631b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53dc536-6702-437e-94a3-6a975e540b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb92001-a75a-4633-b917-ff6c352c8651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c776bb-2ec1-4bc2-97b6-7bd46ab379e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd11ee-474f-4fd6-8c13-d6e3e8706a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111cfa6-1218-4bbc-9b2f-62ca8353cfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d8611-d241-489c-aeeb-008286bffce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d655f0e-cf7f-4d46-83de-f80f03beb829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20afb6-1c43-4d4e-9480-e211384c6692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a44d1-9708-4b6e-9e91-5179419c211f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
>>>>>>> b95eca4a9381aa513f1dafac02363f7d31be235f
   "id": "e2935d18-6ed8-4f21-b50f-64bb50ef5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-smoothed data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/smoothness-all.csv')\n",
    "\n",
    "# Load the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Display the header (first 5 rows) and column names\n",
    "    print(\"Column names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Display basic info about the data\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9c02d-81b4-4a97-8fa9-6f5a89281e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for post-smoothed data\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/smoothness-all.csv')\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"100 Seventy-eight\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "# Load and process the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Debug: Print raw data info\n",
    "    print(\"\\nRaw data info:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nFirst 10 rows of raw data:\")\n",
    "    print(data.head(10))\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    data = data.rename(columns={\n",
    "        data.columns[0]: 'path',\n",
    "        'Unnamed: 3': 'smoothness'\n",
    "    })\n",
    "    \n",
    "    # Shift path column to align file paths with previous row's smoothness\n",
    "    data['file_path'] = data['path'].shift(-1)\n",
    "    \n",
    "    # Filter rows with non-null smoothness\n",
    "    data = data[data['smoothness'].notnull()]\n",
    "    print(f\"\\nAfter filtering non-null smoothness: {len(data)} rows\")\n",
    "    \n",
    "    # Debug: Print data with shifted paths\n",
    "    print(\"\\nData with shifted paths (first 5 rows):\")\n",
    "    print(data[['path', 'file_path', 'smoothness']].head())\n",
    "    \n",
    "    # Extract subject, mb, and me from file_path\n",
    "    def parse_path(path):\n",
    "        try:\n",
    "            if not isinstance(path, str):\n",
    "                return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "            sub_match = re.search(r'sub-(\\d+)', path)\n",
    "            acq_match = re.search(r'acq-(mb\\dme\\d)', path)\n",
    "            subject = sub_match.group(1) if sub_match else None\n",
    "            acq = acq_match.group(1) if acq_match else None\n",
    "            if acq:\n",
    "                mb = acq[:3]  # e.g., mb1\n",
    "                me = acq[3:]  # e.g., me1\n",
    "            else:\n",
    "                mb = None\n",
    "                me = None\n",
    "            return pd.Series({'subject': subject, 'mb': mb, 'me': me})\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing path {path}: {str(e)}\")\n",
    "            return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "    \n",
    "    # Apply parsing to file_path\n",
    "    parsed_data = data['file_path'].apply(parse_path)\n",
    "    data = pd.concat([data, parsed_data], axis=1)\n",
    "    \n",
    "    # Debug: Print parsing results\n",
    "    print(f\"\\nAfter parsing: {len(data)} rows\")\n",
    "    print(\"\\nParsed data (first 5 rows):\")\n",
    "    print(data[['file_path', 'subject', 'mb', 'me', 'smoothness']].head())\n",
    "    \n",
    "    # Assign headcoil\n",
    "    data['headcoil'] = data['subject'].apply(lambda x: '64' if x in HEADCOIL_64_SUBJECTS else '20' if x else None)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    data = data[['subject', 'headcoil', 'mb', 'me', 'smoothness']]\n",
    "    \n",
    "    # Convert to categorical\n",
    "    data['headcoil'] = pd.Categorical(data['headcoil'], categories=['20', '64'])\n",
    "    data['mb'] = pd.Categorical(data['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "    data['me'] = pd.Categorical(data['me'], categories=['me1', 'me4'])\n",
    "    data['subject'] = data['subject'].astype(str)\n",
    "    \n",
    "    # Filter out invalid rows\n",
    "    data = data.dropna(subset=['subject', 'mb', 'me', 'smoothness'])\n",
    "    data = data[~data['subject'].str.contains('sp', na=False)]\n",
    "    data = data[data['subject'] != 'nan']\n",
    "    \n",
    "    # Debug: Print final data\n",
    "    print(f\"\\nProcessed {len(data)} rows with {data['subject'].nunique()} unique subjects\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Check if data is empty\n",
    "if data.empty:\n",
    "    print(\"Error: No valid data after processing. Please check file paths and parsing logic.\")\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    raw_data = pd.read_csv(csv_path)\n",
    "    print(raw_data.head(10))\n",
    "    exit()\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer('smoothness ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model (smoothness ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('post-smoothness_lme_anova.csv', index=False)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
   "id": "0dca3ec7-0a8e-444a-b930-d8529f3da75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smoothness Values (Post) by Subject and mb/me Combination:\n",
      "mb_me    mb1me1  mb3me1  mb6me1  mb1me4  mb3me4  mb6me4\n",
      "subject                                                \n",
      "10015       NaN   4.660   4.964     NaN     NaN     NaN\n",
      "10017     4.968   4.970   4.964   4.904   4.919   4.964\n",
      "10024     4.925   4.966   5.000   4.893   4.963   4.931\n",
      "10028     4.997     NaN     NaN   4.932   4.925   5.006\n",
      "10035     4.996   4.918   4.963   4.905   4.912   4.959\n",
      "10041     4.952   5.052   4.942   4.966   4.922   4.950\n",
      "10043     4.994   4.918   4.963   4.903   4.924   4.919\n",
      "10054     4.944   4.879   4.926   4.945   4.944   4.966\n",
      "10059     4.970   4.933   4.959   4.882   4.931   4.907\n",
      "10069     4.973   4.950   4.911   4.831   4.870   4.948\n",
      "10074     4.978   4.955   4.975   4.920   4.943   4.941\n",
      "10078     4.957   5.027   4.963   4.925   4.911   4.977\n",
      "10080     4.965   4.883   4.946   4.881   4.900   4.945\n",
      "10085     4.972   5.025   4.969   4.855   4.847   4.936\n",
      "10094     4.990   4.910   4.932   4.949   4.922   4.897\n",
      "10108     4.948   4.950   4.989   4.889   4.943   4.937\n",
      "10125     4.981   4.937   4.995   4.933   4.891   4.955\n",
      "10130     4.959   5.016   5.004   4.954   4.935   4.929\n",
      "10136     4.965   4.927   4.980   4.896   4.908   4.915\n",
      "10137     4.988   4.911   4.988   4.887   4.920   4.924\n",
      "10142     4.919   4.878   4.974   4.902   4.970   4.916\n",
      "10150     4.967   4.997   4.969   4.911   4.922   4.930\n",
      "10154     5.015   4.932   4.977   4.866   4.966   4.945\n",
      "10166     4.939   4.975   4.959   4.918   4.901   4.918\n",
      "10185     4.986   4.963   4.941   4.941   4.912   4.970\n",
      "10186     4.984   4.956   4.969   4.889   4.865   4.888\n",
      "10188     4.937   4.918   4.971   4.908   4.896   4.932\n",
      "10198       NaN   4.954   4.927   4.969   4.932   4.951\n",
      "10203     5.003   4.888   4.950   4.924   4.916   4.952\n",
      "10221     4.999   4.933   5.004   4.999   4.945   4.928\n",
      "10223     4.904   4.874   4.948   4.895   4.941   4.946\n",
      "10234     5.020   4.907   4.932   4.881   4.920   4.937\n",
      "10296     4.967   4.957   4.987   4.928   4.955   4.898\n",
      "10303     4.963   4.949   4.921   4.885     NaN   4.956\n",
      "10318     4.979   4.914   4.926   4.887   4.924   4.918\n",
      "10319     5.002   4.966   4.930   4.915   4.943   4.949\n",
      "10320     5.003   4.914   4.932   4.914   4.921   4.936\n",
      "10321     5.004   4.933   4.948   4.905   4.918   4.934\n",
      "10363     4.998   4.951   4.956   4.861   4.956   4.921\n",
      "10382     4.990   4.927   4.939   4.902   4.947   4.941\n",
      "10391     4.971   4.931   4.948   4.898   4.923   4.944\n",
      "10416     4.964   4.905   4.912   4.879   4.888   4.926\n",
      "10422     4.948   4.976   4.940   4.960   4.929   4.974\n",
      "10438     5.066   4.930   4.941   4.870   4.897   4.926\n",
      "10589       NaN   4.925     NaN     NaN   4.959     NaN\n",
      "10590       NaN   4.997     NaN     NaN   4.967     NaN\n",
      "10603       NaN   4.931     NaN     NaN   4.939     NaN\n",
      "10606       NaN   4.941     NaN     NaN   4.965     NaN\n",
      "10608       NaN   4.985     NaN     NaN   5.030     NaN\n",
      "10640       NaN   4.976     NaN     NaN   4.960     NaN\n",
      "10644       NaN   5.100     NaN     NaN   4.989     NaN\n",
      "10652     4.896   4.865   4.943     NaN     NaN     NaN\n",
      "10659       NaN   4.906     NaN     NaN   4.955     NaN\n",
      "10690       NaN   4.980     NaN     NaN   4.973     NaN\n",
      "10691       NaN   4.998     NaN     NaN   5.004     NaN\n",
      "10716     5.003   4.922   4.935     NaN     NaN     NaN\n",
      "10723       NaN   5.069     NaN     NaN   4.991     NaN\n",
      "10738       NaN   4.961   4.900     NaN     NaN     NaN\n",
      "10741       NaN   5.075     NaN     NaN   4.986     NaN\n",
      "10777       NaN   5.016     NaN     NaN   4.956     NaN\n",
      "10803       NaN   5.000     NaN     NaN   4.983     NaN\n",
      "12042     4.915   4.957   4.955   4.885   4.885   4.920\n",
      "\n",
      "Pivot table saved to 'smoothness_pivot_table.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap (if needed)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_path = os.path.expanduser('~/Documents/GitHub/multiecho-pilot/smoothness-all.csv')\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "# Load and process the CSV file\n",
    "try:\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    data = data.rename(columns={\n",
    "        data.columns[0]: 'path',\n",
    "        'Unnamed: 3': 'smoothness'\n",
    "    })\n",
    "    \n",
    "    # Shift path column to align file paths with previous row's smoothness\n",
    "    data['file_path'] = data['path'].shift(-1)\n",
    "    \n",
    "    # Filter rows with non-null smoothness\n",
    "    data = data[data['smoothness'].notnull()]\n",
    "    \n",
    "    # Extract subject, mb, and me from file_path\n",
    "    def parse_path(path):\n",
    "        try:\n",
    "            if not isinstance(path, str):\n",
    "                return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "            sub_match = re.search(r'sub-(\\d+)', path)\n",
    "            acq_match = re.search(r'acq-(mb\\dme\\d)', path)\n",
    "            subject = sub_match.group(1) if sub_match else None\n",
    "            acq = acq_match.group(1) if acq_match else None\n",
    "            if acq:\n",
    "                mb = acq[:3]  # e.g., mb1\n",
    "                me = acq[3:]  # e.g., me1\n",
    "            else:\n",
    "                mb = None\n",
    "                me = None\n",
    "            return pd.Series({'subject': subject, 'mb': mb, 'me': me})\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing path {path}: {str(e)}\")\n",
    "            return pd.Series({'subject': None, 'mb': None, 'me': None})\n",
    "    \n",
    "    # Apply parsing to file_path\n",
    "    parsed_data = data['file_path'].apply(parse_path)\n",
    "    data = pd.concat([data, parsed_data], axis=1)\n",
    "    \n",
    "    # Assign headcoil\n",
    "    data['headcoil'] = data['subject'].apply(lambda x: '64' if x in HEADCOIL_64_SUBJECTS else '20' if x else None)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    data = data[['subject', 'headcoil', 'mb', 'me', 'smoothness']]\n",
    "    \n",
    "    # Convert to categorical\n",
    "    data['headcoil'] = pd.Categorical(data['headcoil'], categories=['20', '64'])\n",
    "    data['mb'] = pd.Categorical(data['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "    data['me'] = pd.Categorical(data['me'], categories=['me1', 'me4'])\n",
    "    data['subject'] = data['subject'].astype(str)\n",
    "    \n",
    "    # Filter out invalid rows\n",
    "    data = data.dropna(subset=['subject', 'mb', 'me', 'smoothness'])\n",
    "    data = data[~data['subject'].str.contains('sp', na=False)]\n",
    "    data = data[data['subject'] != 'nan']\n",
    "    \n",
    "    # Create a combined mb_me column for pivoting by converting categorical to string\n",
    "    data['mb_me'] = data['mb'].astype(str) + data['me'].astype(str)\n",
    "    \n",
    "    # Pivot the data to create a table with subjects as rows and mb_me combinations as columns\n",
    "    pivot_table = data.pivot_table(\n",
    "        values='smoothness',\n",
    "        index='subject',\n",
    "        columns='mb_me',\n",
    "        aggfunc='mean'  # In case of duplicates, take the mean\n",
    "    )\n",
    "    \n",
    "    # Ensure all expected mb_me combinations are present as columns\n",
    "    expected_columns = ['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4']\n",
    "    pivot_table = pivot_table.reindex(columns=expected_columns)\n",
    "    \n",
    "    # Sort the index (subjects) for consistency\n",
    "    pivot_table = pivot_table.sort_index()\n",
    "    \n",
    "    # Round smoothness values to 3 decimal places for readability\n",
    "    pivot_table = pivot_table.round(3)\n",
    "    \n",
    "    # Print the pivot table\n",
    "    print(\"\\nSmoothness Values (Post) by Subject and mb/me Combination:\")\n",
    "    print(pivot_table.to_string())\n",
    "    \n",
    "    # Save the pivot table to a CSV file for further inspection\n",
    "    pivot_table.to_csv('smoothness-post_pivot_table.csv')\n",
    "    print(\"\\nPivot table saved to 'smoothness_pivot_table.csv'\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    # Debug: Print raw data sample if processing fails\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    try:\n",
    "        raw_data = pd.read_csv(csv_path)\n",
    "        print(raw_data.head(10))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# Check if pivot table is empty\n",
    "if 'pivot_table' in locals() and pivot_table.empty:\n",
    "    print(\"Error: No valid data after pivoting. Please check file paths and parsing logic.\")\n",
    "    print(\"\\nDebug: Raw data sample (first 10 rows):\")\n",
    "    try:\n",
    "        raw_data = pd.read_csv(csv_path)\n",
    "        print(raw_data.head(10))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
>>>>>>> b95eca4a9381aa513f1dafac02363f7d31be235f
   "id": "0e8180fa-ad38-411d-b5f2-d3f718662cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ROI-based data\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"act\"  # Filter for type-act\n",
    "IMG_VALUE = \"tsnr\"  # Filter for img-tsnr\n",
    "MASK_VALUE = \"VSconstrained\"  # Single mask for this example\n",
    "DENOISE_VALUE = \"base\"  # Filter for denoise-base\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 18,
>>>>>>> b95eca4a9381aa513f1dafac02363f7d31be235f
   "id": "02d47233-54d8-4046-a095-9849b404c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for TSNR in VS\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"tsnr\"\n",
    "MASK_VALUE = \"VSconstrained\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df004001-0773-4619-b263-a9a2b07b5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for TSNR in rFFA\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"tsnr\"\n",
    "MASK_VALUE = \"rFFA\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ea679-2fd4-41d1-a2b5-d944ed5c8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for TSNR in Motor Cortex\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"tsnr\"\n",
    "MASK_VALUE = \"bilateralMotor\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871966e3-48bd-42f8-9394-6953afd03c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for Beta Activation in VS\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"VSconstrained\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b878beb-6e48-4b64-986d-54a7d03229f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for Beta Activation in rFFA\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"rFFA\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_rFFA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b02805-d294-4e2d-9649-a580a883ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for Beta Activation in Motor Cortex\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"bilateralMotor\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d57bd-4835-460d-8488-f3f0a950ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for PPI in MEbonf\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"MEbonf\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46eea2-388c-4bcc-8494-d8d4920e0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for PPI in HCxMEbonf\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"HCxMEbonf\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b75a81-1aa3-41d7-8ae9-570e2198842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for PPI in 3waybonf\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pymer4.models import Lmer\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning from pymer4 about DataFrame.applymap\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=\"DataFrame.applymap has been deprecated\"\n",
    ")\n",
    "\n",
    "# Define parameters\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"3waybonf\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# Define subjects with 64-channel headcoil\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\",\n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\",\n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\",\n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    try:\n",
    "        df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "        if df.empty:\n",
    "            raise ValueError(\"No data extracted from files\")\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "        df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "        column_order = ['subject', 'headcoil'] + acq_params\n",
    "        df = df[column_order]\n",
    "        df['subject'] = df['subject'].astype(int)\n",
    "        df.sort_values('subject', inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Extract and create DataFrame\n",
    "try:\n",
    "    print(f\"\\nProcessing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    data_by_subject = extract_file_data(BASE_DIR, TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_VALUE)\n",
    "    if not data_by_subject:\n",
    "        raise FileNotFoundError(f\"No matching files found in {BASE_DIR} for specified parameters\")\n",
    "    \n",
    "    data = create_dataframe(data_by_subject, HEADCOIL_64_SUBJECTS)\n",
    "    if data is None:\n",
    "        raise ValueError(\"Failed to create DataFrame\")\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    print(\"\\nFirst 5 rows of the data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nData info:\")\n",
    "    print(data.info())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "    exit()\n",
    "\n",
    "# Reshape to long format for mixed effects model\n",
    "data_long = pd.melt(\n",
    "    data,\n",
    "    id_vars=['subject', 'headcoil'],\n",
    "    value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "    var_name='acq',\n",
    "    value_name=IMG_VALUE\n",
    ")\n",
    "data_long['mb'] = data_long['acq'].str[:3]\n",
    "data_long['me'] = data_long['acq'].str[3:]\n",
    "data_long = data_long.drop(columns=['acq'])\n",
    "\n",
    "# Convert to categorical\n",
    "data_long['headcoil'] = pd.Categorical(data_long['headcoil'], categories=['20', '64'])\n",
    "data_long['mb'] = pd.Categorical(data_long['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_long['me'] = pd.Categorical(data_long['me'], categories=['me1', 'me4'])\n",
    "data_long['subject'] = data_long['subject'].astype(str)\n",
    "\n",
    "# Filter out rows with missing tsnr\n",
    "data_long = data_long.dropna(subset=[IMG_VALUE])\n",
    "\n",
    "# Print data summary\n",
    "print(\"\\nData summary (unique subjects per condition):\")\n",
    "print(data_long.groupby(['headcoil', 'mb', 'me'], observed=True)['subject'].nunique())\n",
    "\n",
    "# Prepare data for pymer4 with sum-to-zero contrasts\n",
    "data_model = data_long.copy()\n",
    "data_model['headcoil'] = data_model['headcoil'].cat.codes - 0.5  # 20=-0.5, 64=0.5\n",
    "data_model['mb'] = pd.Categorical(data_model['mb'], categories=['mb1', 'mb3', 'mb6'])\n",
    "data_model['me'] = pd.Categorical(data_model['me'], categories=['me1', 'me4'])\n",
    "\n",
    "# Fit the LME model with pymer4\n",
    "model = Lmer(f'{IMG_VALUE} ~ headcoil * mb * me + (1 | subject)', data=data_model)\n",
    "model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Get ANOVA table with Satterthwaite approximation\n",
    "anova_table = model.anova()\n",
    "print(\"\\nANOVA table:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Define effect names and numerator df\n",
    "effect_map = {\n",
    "    'headcoil': 'Head Coil',\n",
    "    'mb': 'Multiband',\n",
    "    'me': 'Multi-echo',\n",
    "    'headcoil:mb': 'Head Coil × Multiband',\n",
    "    'headcoil:me': 'Head Coil × Multi-echo',\n",
    "    'mb:me': 'Multiband × Multi-echo',\n",
    "    'headcoil:mb:me': 'Head Coil × Multiband × Multi-echo'\n",
    "}\n",
    "df_dict = {\n",
    "    'Head Coil': 1,\n",
    "    'Multiband': 2,\n",
    "    'Multi-echo': 1,\n",
    "    'Head Coil × Multiband': 2,\n",
    "    'Head Coil × Multi-echo': 1,\n",
    "    'Multiband × Multi-echo': 2,\n",
    "    'Head Coil × Multiband × Multi-echo': 2\n",
    "}\n",
    "\n",
    "# Build APA table\n",
    "apa_data = []\n",
    "for effect in anova_table.index:\n",
    "    if effect in ['(Intercept)', 'Residuals']:\n",
    "        continue\n",
    "    effect_name = effect_map.get(effect, effect)\n",
    "    apa_data.append({\n",
    "        'Effect': effect_name,\n",
    "        'Sum Sq': anova_table.loc[effect, 'SS'] if 'SS' in anova_table.columns else np.nan,\n",
    "        'Mean Sq': anova_table.loc[effect, 'MS'] if 'MS' in anova_table.columns else np.nan,\n",
    "        'Num df': df_dict.get(effect_name, np.nan),\n",
    "        'Den df': anova_table.loc[effect, 'DenomDF'] if 'DenomDF' in anova_table.columns else np.nan,\n",
    "        'F': anova_table.loc[effect, 'F-stat'] if 'F-stat' in anova_table.columns else np.nan,\n",
    "        'p': anova_table.loc[effect, 'P-val'] if 'P-val' in anova_table.columns else np.nan,\n",
    "        'Partial η²': np.nan  # Computed below\n",
    "    })\n",
    "\n",
    "# Compute partial eta-squared\n",
    "try:\n",
    "    residual_var = model.ranef_var.loc[model.ranef_var['Name'] == '', 'Var'].iloc[0]\n",
    "except (KeyError, IndexError) as e:\n",
    "    print(\"Error accessing residual variance, printing model.ranef_var for debugging:\")\n",
    "    print(model.ranef_var)\n",
    "    residual_var = model.ranef_var.iloc[1]['Var']\n",
    "\n",
    "n_obs = len(data_model)\n",
    "n_fixed = sum(df_dict.values())\n",
    "n_subj = data_model['subject'].nunique()\n",
    "ss_residual = residual_var * (n_obs - n_fixed - n_subj)\n",
    "\n",
    "for i, row in enumerate(apa_data):\n",
    "    ss_effect = row['Sum Sq']\n",
    "    if pd.notna(ss_effect):\n",
    "        apa_data[i]['Partial η²'] = ss_effect / (ss_effect + ss_residual)\n",
    "\n",
    "# Create APA table\n",
    "apa_table = pd.DataFrame(apa_data)\n",
    "apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)\n",
    "apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "apa_table['F'] = apa_table['F'].round(2)\n",
    "apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "\n",
    "# Print and save APA table\n",
    "print(f\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model ({IMG_VALUE} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "print(apa_table.to_string(index=False))\n",
    "apa_table.to_csv('tsnr_lme_anova_VSconstrained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afb15b-1af4-4491-999b-9d5385140771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8 Part 1, Generate avg fd_mean values for each ME acq\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "input_file = \"~/Documents/GitHub/multiecho-pilot/derivatives/Task-sharedreward_Level-Acq_Outlier-info_mriqc-0.16.1.tsv\"\n",
    "output_file = \"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\"\n",
    "\n",
    "# Load the TSV file\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Filter out subjects ending in 'sp' and acquisitions containing 'me1'\n",
    "df = df[~df['Sub'].str.endswith('sp')]\n",
    "df = df[~df['acq'].str.contains('me1', na=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "#print(\"Filtered data saved to:\", output_file)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your spreadsheet data\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Extract the base 'acq' substring (e.g., mb1me4, mb3me4, mb6me4) from the 'acq' column\n",
    "df['acq_base'] = df['acq'].str.extract(r'(mb\\dme4)')\n",
    "\n",
    "# Group by 'Sub' and 'acq_base' and calculate the average of 'fd_mean' for each group\n",
    "averages = df.groupby(['Sub', 'acq_base'])['fd_mean'].mean().reset_index()\n",
    "\n",
    "# Save the results to a new spreadsheet\n",
    "output_file_path = 'fd_mean_averages.xlsx'  # Replace with your desired output file path\n",
    "averages.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Optionally, print the averages to verify\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c8098-7a46-4075-92b7-9312dbbac1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print base - tedana stats for VS\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from scipy import stats\n",
    "\n",
    "def initialize_plotting_engine():\n",
    "    \"\"\"Initialize the plotting environment with required settings\"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "\n",
    "def extract_file_data_with_difference(base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params):\n",
    "    \"\"\"Extract data and calculate differences between denoise methods for given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {base_dir}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in acq_params:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value and mask == mask_value and \n",
    "                denoise in [denoise_tedana, denoise_base]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in acq_params}\n",
    "                            for denoise in [denoise_tedana, denoise_base]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Subjects with data: {len(data_by_subject)}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in acq_params:\n",
    "            tedana_val = data[denoise_tedana].get(acq, np.nan)\n",
    "            base_val = data[denoise_base].get(acq, np.nan)\n",
    "            diff = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "            diff_by_subject[sub_id][acq] = diff\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects):\n",
    "    \"\"\"Create and merge DataFrame with framewise displacement data\"\"\"\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    column_order = ['subject'] + acq_params\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject'], value_vars=acq_params, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(fd_csv_path)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me\\d)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    nan_count = df_merged['fd_mean'].isna().sum()\n",
    "    print(f\"\\nNumber of NaN fd_mean values after merge: {nan_count} out of {len(df_merged)} rows\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def generate_summary_table(df, acq_params):\n",
    "    \"\"\"Generate APA-style summary table of statistics for each acquisition\"\"\"\n",
    "    stats_data = {\n",
    "        'Acquisition': [],\n",
    "        'N': [],\n",
    "        'Mean (SD)': [],\n",
    "        'Range': [],\n",
    "        'Pearson r (95% CI)': [],\n",
    "        'p-value': [],\n",
    "        'Slope (p)': [],\n",
    "        'R-squared': []\n",
    "    }\n",
    "    \n",
    "    # Bonferroni correction for 3 acquisitions\n",
    "    alpha = 0.05 / len(acq_params)\n",
    "    \n",
    "    for acq in acq_params:\n",
    "        acq_data = df[df['acq'] == acq].dropna(subset=['fd_mean', 'tedana_minus_base'])\n",
    "        \n",
    "        # Sample size\n",
    "        n = len(acq_data)\n",
    "        \n",
    "        # Descriptive statistics\n",
    "        mean = acq_data['tedana_minus_base'].mean()\n",
    "        sd = acq_data['tedana_minus_base'].std()\n",
    "        min_val = acq_data['tedana_minus_base'].min()\n",
    "        max_val = acq_data['tedana_minus_base'].max()\n",
    "        \n",
    "        # Correlation\n",
    "        if n > 1:\n",
    "            r, p = stats.pearsonr(acq_data['fd_mean'], acq_data['tedana_minus_base'])\n",
    "            # 95% CI for Pearson's r\n",
    "            z = np.arctanh(r)\n",
    "            se = 1 / np.sqrt(n - 3)\n",
    "            ci_lower_z = z - 1.96 * se\n",
    "            ci_upper_z = z + 1.96 * se\n",
    "            ci_lower = np.tanh(ci_lower_z)\n",
    "            ci_upper = np.tanh(ci_upper_z)\n",
    "            ci = f\"[{ci_lower:.2f}, {ci_upper:.2f}]\"\n",
    "            p_corrected = min(p * len(acq_params), 1.0)  # Bonferroni correction\n",
    "        else:\n",
    "            r, p, ci, p_corrected = np.nan, np.nan, \"[N/A, N/A]\", np.nan\n",
    "        \n",
    "        # Regression\n",
    "        if n > 1:\n",
    "            slope, intercept, r_value, p_slope, _ = stats.linregress(acq_data['fd_mean'], acq_data['tedana_minus_base'])\n",
    "            r_squared = r_value ** 2\n",
    "        else:\n",
    "            slope, p_slope, r_squared = np.nan, np.nan, np.nan\n",
    "        \n",
    "        # Format statistics\n",
    "        stats_data['Acquisition'].append(acq)\n",
    "        stats_data['N'].append(n)\n",
    "        stats_data['Mean (SD)'].append(f\"{mean:.2f} ({sd:.2f})\")\n",
    "        stats_data['Range'].append(f\"[{min_val:.2f}, {max_val:.2f}]\")\n",
    "        stats_data['Pearson r (95% CI)'].append(f\"{r:.2f} {ci}\")\n",
    "        stats_data['p-value'].append(f\"{p_corrected:.3f}\" if not np.isnan(p_corrected) else \"N/A\")\n",
    "        stats_data['Slope (p)'].append(f\"{slope:.2f} ({p_slope:.3f})\" if not np.isnan(slope) else \"N/A\")\n",
    "        stats_data['R-squared'].append(f\"{r_squared:.2f}\" if not np.isnan(r_squared) else \"N/A\")\n",
    "    \n",
    "    summary_df = pd.DataFrame(stats_data)\n",
    "    return summary_df\n",
    "\n",
    "def create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base):\n",
    "    \"\"\"Create scatter plots without headcoil split (blue dots)\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(acq_params), figsize=(24, 8), sharey=True)\n",
    "    \n",
    "    for i, acq in enumerate(acq_params):\n",
    "        ax = axes[i] if len(acq_params) > 1 else axes\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            data=acq_data, x='fd_mean', y='tedana_minus_base',\n",
    "            color='blue', ax=ax, s=300\n",
    "        )\n",
    "        \n",
    "        if len(acq_data) > 1:\n",
    "            sns.regplot(x='fd_mean', y='tedana_minus_base', data=acq_data,\n",
    "                        scatter=False, ax=ax, color='blue', line_kws={'linewidth': 3})\n",
    "        \n",
    "        ax.set_title(f'{acq}', fontsize=64, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{mask_value}\\n{denoise_tedana} - {denoise_base}', fontsize=56)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.tick_params(axis='both', which='major', labelsize=56)\n",
    "        ax.set_xlabel('')\n",
    "    \n",
    "    fig.text(0.5, -0.02, 'Mean Framewise Displacement', ha='center', fontsize=56)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def process_and_visualize_tedana_difference(type_value, img_value, mask_value, denoise_tedana, denoise_base, \n",
    "                                           base_dir=None, fd_csv_path=None, acq_params=None, \n",
    "                                           headcoil_64_subjects=None, save_files=True):\n",
    "    \"\"\"Run the analysis for tedana-base difference visualization (no headcoil split)\"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    if fd_csv_path is None:\n",
    "        fd_csv_path = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "    if acq_params is None:\n",
    "        acq_params = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    if headcoil_64_subjects is None:\n",
    "        headcoil_64_subjects = [\n",
    "            \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "            \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "            \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "            \"10186\", \"10188\", \"10221\"\n",
    "        ]\n",
    "    \n",
    "    initialize_plotting_engine()\n",
    "    \n",
    "    print(f\"\\nProcessing files for tedana - base difference: type={type_value}, img={img_value}, mask={mask_value}\")\n",
    "    \n",
    "    diff_by_subject = extract_file_data_with_difference(\n",
    "        base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params\n",
    "    )\n",
    "    \n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return None\n",
    "    \n",
    "    df = create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects)\n",
    "    \n",
    "    if save_files:\n",
    "        output_file = f\"multiecho_tedana_minus_base_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Generate summary table\n",
    "    print(\"\\nGenerating summary statistics table...\")\n",
    "    summary_table = generate_summary_table(df, acq_params)\n",
    "    if save_files:\n",
    "        table_file = f\"summary_stats_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        summary_table.to_csv(table_file, index=False)\n",
    "        print(f\"Summary table saved to {table_file}\")\n",
    "    print(\"\\nAPA-style Summary Table:\")\n",
    "    print(summary_table.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig = create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base)\n",
    "    \n",
    "    if save_files:\n",
    "        plot_file = f\"tedana_minus_base_scatter_{type_value}_{img_value}_{mask_value}.png\"\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return {\n",
    "        'dataframe': df,\n",
    "        'figure': fig,\n",
    "        'summary_table': summary_table\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"zstat\"\n",
    "    MASK_VALUE = \"VSconstrained\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac14525-68fa-454e-992e-c8e9b0f09c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print base - tedana stats for rFFA\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from scipy import stats\n",
    "\n",
    "def initialize_plotting_engine():\n",
    "    \"\"\"Initialize the plotting environment with required settings\"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "\n",
    "def extract_file_data_with_difference(base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params):\n",
    "    \"\"\"Extract data and calculate differences between denoise methods for given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {base_dir}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in acq_params:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value and mask == mask_value and \n",
    "                denoise in [denoise_tedana, denoise_base]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in acq_params}\n",
    "                            for denoise in [denoise_tedana, denoise_base]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Subjects with data: {len(data_by_subject)}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in acq_params:\n",
    "            tedana_val = data[denoise_tedana].get(acq, np.nan)\n",
    "            base_val = data[denoise_base].get(acq, np.nan)\n",
    "            diff = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "            diff_by_subject[sub_id][acq] = diff\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects):\n",
    "    \"\"\"Create and merge DataFrame with framewise displacement data\"\"\"\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    column_order = ['subject'] + acq_params\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject'], value_vars=acq_params, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(fd_csv_path)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me\\d)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    nan_count = df_merged['fd_mean'].isna().sum()\n",
    "    print(f\"\\nNumber of NaN fd_mean values after merge: {nan_count} out of {len(df_merged)} rows\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def generate_summary_table(df, acq_params):\n",
    "    \"\"\"Generate APA-style summary table of statistics for each acquisition\"\"\"\n",
    "    stats_data = {\n",
    "        'Acquisition': [],\n",
    "        'N': [],\n",
    "        'Mean (SD)': [],\n",
    "        'Range': [],\n",
    "        'Pearson r (95% CI)': [],\n",
    "        'p-value': [],\n",
    "        'Slope (p)': [],\n",
    "        'R-squared': []\n",
    "    }\n",
    "    \n",
    "    # Bonferroni correction for 3 acquisitions\n",
    "    alpha = 0.05 / len(acq_params)\n",
    "    \n",
    "    for acq in acq_params:\n",
    "        acq_data = df[df['acq'] == acq].dropna(subset=['fd_mean', 'tedana_minus_base'])\n",
    "        \n",
    "        # Sample size\n",
    "        n = len(acq_data)\n",
    "        \n",
    "        # Descriptive statistics\n",
    "        mean = acq_data['tedana_minus_base'].mean()\n",
    "        sd = acq_data['tedana_minus_base'].std()\n",
    "        min_val = acq_data['tedana_minus_base'].min()\n",
    "        max_val = acq_data['tedana_minus_base'].max()\n",
    "        \n",
    "        # Correlation\n",
    "        if n > 1:\n",
    "            r, p = stats.pearsonr(acq_data['fd_mean'], acq_data['tedana_minus_base'])\n",
    "            # 95% CI for Pearson's r\n",
    "            z = np.arctanh(r)\n",
    "            se = 1 / np.sqrt(n - 3)\n",
    "            ci_lower_z = z - 1.96 * se\n",
    "            ci_upper_z = z + 1.96 * se\n",
    "            ci_lower = np.tanh(ci_lower_z)\n",
    "            ci_upper = np.tanh(ci_upper_z)\n",
    "            ci = f\"[{ci_lower:.2f}, {ci_upper:.2f}]\"\n",
    "            p_corrected = min(p * len(acq_params), 1.0)  # Bonferroni correction\n",
    "        else:\n",
    "            r, p, ci, p_corrected = np.nan, np.nan, \"[N/A, N/A]\", np.nan\n",
    "        \n",
    "        # Regression\n",
    "        if n > 1:\n",
    "            slope, intercept, r_value, p_slope, _ = stats.linregress(acq_data['fd_mean'], acq_data['tedana_minus_base'])\n",
    "            r_squared = r_value ** 2\n",
    "        else:\n",
    "            slope, p_slope, r_squared = np.nan, np.nan, np.nan\n",
    "        \n",
    "        # Format statistics\n",
    "        stats_data['Acquisition'].append(acq)\n",
    "        stats_data['N'].append(n)\n",
    "        stats_data['Mean (SD)'].append(f\"{mean:.2f} ({sd:.2f})\")\n",
    "        stats_data['Range'].append(f\"[{min_val:.2f}, {max_val:.2f}]\")\n",
    "        stats_data['Pearson r (95% CI)'].append(f\"{r:.2f} {ci}\")\n",
    "        stats_data['p-value'].append(f\"{p_corrected:.3f}\" if not np.isnan(p_corrected) else \"N/A\")\n",
    "        stats_data['Slope (p)'].append(f\"{slope:.2f} ({p_slope:.3f})\" if not np.isnan(slope) else \"N/A\")\n",
    "        stats_data['R-squared'].append(f\"{r_squared:.2f}\" if not np.isnan(r_squared) else \"N/A\")\n",
    "    \n",
    "    summary_df = pd.DataFrame(stats_data)\n",
    "    return summary_df\n",
    "\n",
    "def create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base):\n",
    "    \"\"\"Create scatter plots without headcoil split (blue dots)\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(acq_params), figsize=(24, 8), sharey=True)\n",
    "    \n",
    "    for i, acq in enumerate(acq_params):\n",
    "        ax = axes[i] if len(acq_params) > 1 else axes\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            data=acq_data, x='fd_mean', y='tedana_minus_base',\n",
    "            color='blue', ax=ax, s=300\n",
    "        )\n",
    "        \n",
    "        if len(acq_data) > 1:\n",
    "            sns.regplot(x='fd_mean', y='tedana_minus_base', data=acq_data,\n",
    "                        scatter=False, ax=ax, color='blue', line_kws={'linewidth': 3})\n",
    "        \n",
    "        ax.set_title(f'{acq}', fontsize=64, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{mask_value}\\n{denoise_tedana} - {denoise_base}', fontsize=56)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.tick_params(axis='both', which='major', labelsize=56)\n",
    "        ax.set_xlabel('')\n",
    "    \n",
    "    fig.text(0.5, -0.02, 'Mean Framewise Displacement', ha='center', fontsize=56)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def process_and_visualize_tedana_difference(type_value, img_value, mask_value, denoise_tedana, denoise_base, \n",
    "                                           base_dir=None, fd_csv_path=None, acq_params=None, \n",
    "                                           headcoil_64_subjects=None, save_files=True):\n",
    "    \"\"\"Run the analysis for tedana-base difference visualization (no headcoil split)\"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    if fd_csv_path is None:\n",
    "        fd_csv_path = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "    if acq_params is None:\n",
    "        acq_params = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    if headcoil_64_subjects is None:\n",
    "        headcoil_64_subjects = [\n",
    "            \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "            \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "            \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "            \"10186\", \"10188\", \"10221\"\n",
    "        ]\n",
    "    \n",
    "    initialize_plotting_engine()\n",
    "    \n",
    "    print(f\"\\nProcessing files for tedana - base difference: type={type_value}, img={img_value}, mask={mask_value}\")\n",
    "    \n",
    "    diff_by_subject = extract_file_data_with_difference(\n",
    "        base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params\n",
    "    )\n",
    "    \n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return None\n",
    "    \n",
    "    df = create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects)\n",
    "    \n",
    "    if save_files:\n",
    "        output_file = f\"multiecho_tedana_minus_base_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Generate summary table\n",
    "    print(\"\\nGenerating summary statistics table...\")\n",
    "    summary_table = generate_summary_table(df, acq_params)\n",
    "    if save_files:\n",
    "        table_file = f\"summary_stats_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        summary_table.to_csv(table_file, index=False)\n",
    "        print(f\"Summary table saved to {table_file}\")\n",
    "    print(\"\\nAPA-style Summary Table:\")\n",
    "    print(summary_table.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig = create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base)\n",
    "    \n",
    "    if save_files:\n",
    "        plot_file = f\"tedana_minus_base_scatter_{type_value}_{img_value}_{mask_value}.png\"\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return {\n",
    "        'dataframe': df,\n",
    "        'figure': fig,\n",
    "        'summary_table': summary_table\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"beta\"\n",
    "    MASK_VALUE = \"rFFA\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd69b61-3d4f-46e7-846b-f57f91d3f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print base - tedana stats for Motor Cortex\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from scipy import stats\n",
    "\n",
    "def initialize_plotting_engine():\n",
    "    \"\"\"Initialize the plotting environment with required settings\"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "\n",
    "def extract_file_data_with_difference(base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params):\n",
    "    \"\"\"Extract data and calculate differences between denoise methods for given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {base_dir}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in acq_params:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value and mask == mask_value and \n",
    "                denoise in [denoise_tedana, denoise_base]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in acq_params}\n",
    "                            for denoise in [denoise_tedana, denoise_base]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Subjects with data: {len(data_by_subject)}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in acq_params:\n",
    "            tedana_val = data[denoise_tedana].get(acq, np.nan)\n",
    "            base_val = data[denoise_base].get(acq, np.nan)\n",
    "            diff = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "            diff_by_subject[sub_id][acq] = diff\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects):\n",
    "    \"\"\"Create and merge DataFrame with framewise displacement data\"\"\"\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    column_order = ['subject'] + acq_params\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject'], value_vars=acq_params, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(fd_csv_path)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me\\d)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    nan_count = df_merged['fd_mean'].isna().sum()\n",
    "    print(f\"\\nNumber of NaN fd_mean values after merge: {nan_count} out of {len(df_merged)} rows\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def generate_summary_table(df, acq_params):\n",
    "    \"\"\"Generate APA-style summary table of statistics for each acquisition\"\"\"\n",
    "    stats_data = {\n",
    "        'Acquisition': [],\n",
    "        'N': [],\n",
    "        'Mean (SD)': [],\n",
    "        'Range': [],\n",
    "        'Pearson r (95% CI)': [],\n",
    "        'p-value': [],\n",
    "        'Slope (p)': [],\n",
    "        'R-squared': []\n",
    "    }\n",
    "    \n",
    "    # Bonferroni correction for 3 acquisitions\n",
    "    alpha = 0.05 / len(acq_params)\n",
    "    \n",
    "    for acq in acq_params:\n",
    "        acq_data = df[df['acq'] == acq].dropna(subset=['fd_mean', 'tedana_minus_base'])\n",
    "        \n",
    "        # Sample size\n",
    "        n = len(acq_data)\n",
    "        \n",
    "        # Descriptive statistics\n",
    "        mean = acq_data['tedana_minus_base'].mean()\n",
    "        sd = acq_data['tedana_minus_base'].std()\n",
    "        min_val = acq_data['tedana_minus_base'].min()\n",
    "        max_val = acq_data['tedana_minus_base'].max()\n",
    "        \n",
    "        # Correlation\n",
    "        if n > 1:\n",
    "            r, p = stats.pearsonr(acq_data['fd_mean'], acq_data['tedana_minus_base'])\n",
    "            # 95% CI for Pearson's r\n",
    "            z = np.arctanh(r)\n",
    "            se = 1 / np.sqrt(n - 3)\n",
    "            ci_lower_z = z - 1.96 * se\n",
    "            ci_upper_z = z + 1.96 * se\n",
    "            ci_lower = np.tanh(ci_lower_z)\n",
    "            ci_upper = np.tanh(ci_upper_z)\n",
    "            ci = f\"[{ci_lower:.2f}, {ci_upper:.2f}]\"\n",
    "            p_corrected = min(p * len(acq_params), 1.0)  # Bonferroni correction\n",
    "        else:\n",
    "            r, p, ci, p_corrected = np.nan, np.nan, \"[N/A, N/A]\", np.nan\n",
    "        \n",
    "        # Regression\n",
    "        if n > 1:\n",
    "            slope, intercept, r_value, p_slope, _ = stats.linregress(acq_data['fd_mean'], acq_data['tedana_minus_base'])\n",
    "            r_squared = r_value ** 2\n",
    "        else:\n",
    "            slope, p_slope, r_squared = np.nan, np.nan, np.nan\n",
    "        \n",
    "        # Format statistics\n",
    "        stats_data['Acquisition'].append(acq)\n",
    "        stats_data['N'].append(n)\n",
    "        stats_data['Mean (SD)'].append(f\"{mean:.2f} ({sd:.2f})\")\n",
    "        stats_data['Range'].append(f\"[{min_val:.2f}, {max_val:.2f}]\")\n",
    "        stats_data['Pearson r (95% CI)'].append(f\"{r:.2f} {ci}\")\n",
    "        stats_data['p-value'].append(f\"{p_corrected:.3f}\" if not np.isnan(p_corrected) else \"N/A\")\n",
    "        stats_data['Slope (p)'].append(f\"{slope:.2f} ({p_slope:.3f})\" if not np.isnan(slope) else \"N/A\")\n",
    "        stats_data['R-squared'].append(f\"{r_squared:.2f}\" if not np.isnan(r_squared) else \"N/A\")\n",
    "    \n",
    "    summary_df = pd.DataFrame(stats_data)\n",
    "    return summary_df\n",
    "\n",
    "def create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base):\n",
    "    \"\"\"Create scatter plots without headcoil split (blue dots)\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(acq_params), figsize=(24, 8), sharey=True)\n",
    "    \n",
    "    for i, acq in enumerate(acq_params):\n",
    "        ax = axes[i] if len(acq_params) > 1 else axes\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            data=acq_data, x='fd_mean', y='tedana_minus_base',\n",
    "            color='blue', ax=ax, s=300\n",
    "        )\n",
    "        \n",
    "        if len(acq_data) > 1:\n",
    "            sns.regplot(x='fd_mean', y='tedana_minus_base', data=acq_data,\n",
    "                        scatter=False, ax=ax, color='blue', line_kws={'linewidth': 3})\n",
    "        \n",
    "        ax.set_title(f'{acq}', fontsize=64, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{mask_value}\\n{denoise_tedana} - {denoise_base}', fontsize=56)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.tick_params(axis='both', which='major', labelsize=56)\n",
    "        ax.set_xlabel('')\n",
    "    \n",
    "    fig.text(0.5, -0.02, 'Mean Framewise Displacement', ha='center', fontsize=56)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def process_and_visualize_tedana_difference(type_value, img_value, mask_value, denoise_tedana, denoise_base, \n",
    "                                           base_dir=None, fd_csv_path=None, acq_params=None, \n",
    "                                           headcoil_64_subjects=None, save_files=True):\n",
    "    \"\"\"Run the analysis for tedana-base difference visualization (no headcoil split)\"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    if fd_csv_path is None:\n",
    "        fd_csv_path = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "    if acq_params is None:\n",
    "        acq_params = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    if headcoil_64_subjects is None:\n",
    "        headcoil_64_subjects = [\n",
    "            \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "            \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "            \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "            \"10186\", \"10188\", \"10221\"\n",
    "        ]\n",
    "    \n",
    "    initialize_plotting_engine()\n",
    "    \n",
    "    print(f\"\\nProcessing files for tedana - base difference: type={type_value}, img={img_value}, mask={mask_value}\")\n",
    "    \n",
    "    diff_by_subject = extract_file_data_with_difference(\n",
    "        base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params\n",
    "    )\n",
    "    \n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return None\n",
    "    \n",
    "    df = create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects)\n",
    "    \n",
    "    if save_files:\n",
    "        output_file = f\"multiecho_tedana_minus_base_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Generate summary table\n",
    "    print(\"\\nGenerating summary statistics table...\")\n",
    "    summary_table = generate_summary_table(df, acq_params)\n",
    "    if save_files:\n",
    "        table_file = f\"summary_stats_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        summary_table.to_csv(table_file, index=False)\n",
    "        print(f\"Summary table saved to {table_file}\")\n",
    "    print(\"\\nAPA-style Summary Table:\")\n",
    "    print(summary_table.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig = create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base)\n",
    "    \n",
    "    if save_files:\n",
    "        plot_file = f\"tedana_minus_base_scatter_{type_value}_{img_value}_{mask_value}.png\"\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return {\n",
    "        'dataframe': df,\n",
    "        'figure': fig,\n",
    "        'summary_table': summary_table\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"beta\"\n",
    "    MASK_VALUE = \"bilateralMotor\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f89e12-4781-4c5e-9daf-dbffdd6cad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Activate pandas-R conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "base = importr('base')\n",
    "lme4 = importr('lme4')\n",
    "emmeans = importr('emmeans')\n",
    "ggplot2 = importr('ggplot2')\n",
    "\n",
    "def extract_file_data(base_dir, acq_params, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"\n",
    "    Extracts numerical data from text files matching specified parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_dir: Path to the directory containing text files.\n",
    "    - acq_params: List of acquisition parameters to include.\n",
    "    - type_value, img_value, mask_value, denoise_value: Filtering criteria for filenames.\n",
    "    \n",
    "    Returns:\n",
    "    - data_by_subject: Dictionary with subjects as keys and acquisition data as values.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+[a-zA-Z]*)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "\n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    matched_files = 0\n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' not in sub_id:\n",
    "                continue\n",
    "            if (file_type.lower() == type_value.lower() and \n",
    "                img.lower() == img_value.lower() and \n",
    "                mask.lower() == mask_value.lower() and \n",
    "                denoise.lower() == denoise_value.lower() and \n",
    "                acq in acq_params):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    matched_files += 1\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "    print(f\"Total matched files: {matched_files}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, acq_params):\n",
    "    \"\"\"\n",
    "    Converts extracted data into a structured DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data_by_subject: Dictionary with extracted numerical values.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame with subject IDs and extracted values.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index').reset_index()\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    column_order = ['subject'] + acq_params\n",
    "    df = df[column_order].sort_values('subject')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_plot_data(df, acq_params):\n",
    "    \"\"\"\n",
    "    Computes means and standard errors for each acquisition parameter.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing extracted values.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "\n",
    "    Returns:\n",
    "    - results: Dictionary with mean values, errors, and subject count.\n",
    "    \"\"\"\n",
    "    means = {acq: df[acq].mean() for acq in acq_params}\n",
    "    errors = {acq: df[acq].sem() for acq in acq_params}\n",
    "    return {'means': means, 'errors': errors, 'count': len(df)}\n",
    "\n",
    "def create_bar_plot(plot_data, acq_params, title, y_label):\n",
    "    \"\"\"\n",
    "    Creates a formatted bar plot with error bars.\n",
    "\n",
    "    Parameters:\n",
    "    - plot_data: Dictionary with mean values, errors, and subject count.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    - title: Plot title.\n",
    "    - y_label: Y-axis label.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The created matplotlib figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "\n",
    "    means = [plot_data['means'][acq] for acq in acq_params]\n",
    "    errors = [plot_data['errors'][acq] for acq in acq_params]\n",
    "    \n",
    "    x_positions = np.arange(len(acq_params))\n",
    "    ax.bar(x_positions, means, color='lavender', yerr=errors, capsize=5, width=0.8)\n",
    "\n",
    "    ax.set_ylabel(y_label, fontsize=40)\n",
    "    ax.set_title(title, fontsize=48, fontweight='bold')\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(acq_params, fontsize=32, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Acquisition', fontsize=40)\n",
    "    ax.tick_params(axis='both', labelsize=32)\n",
    "\n",
    "    y_min = min([v - e for v, e in zip(means, errors) if not np.isnan(v)])\n",
    "    y_max = max([v + e for v, e in zip(means, errors) if not np.isnan(v)])\n",
    "    margin = (y_max - y_min) * 0.1\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plot(emm_df, mask_value, output_dir, type_value, img_value, denoise_value):\n",
    "    \"\"\"\n",
    "    Create a line plot for estimated marginal means and save as PNG.\n",
    "\n",
    "    Parameters:\n",
    "    - emm_df: DataFrame with EMM data.\n",
    "    - mask_value: Mask value for labeling.\n",
    "    - output_dir: Directory to save the plot.\n",
    "    - type_value, img_value, denoise_value: Parameters for filename.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The created matplotlib figure.\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    acq_params = sorted(emm_df['acq'].unique())\n",
    "    custom_labels = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "    lavender_color = '#800080'\n",
    "\n",
    "    for acq in acq_params:\n",
    "        acq_data = emm_df[emm_df['acq'] == acq]\n",
    "        if not acq_data.empty:\n",
    "            emmean = acq_data['emmean'].values[0]\n",
    "            se = acq_data['SE'].values[0]\n",
    "            x_pos = acq_params.index(acq)\n",
    "            ax.errorbar([x_pos], [emmean], yerr=[se], fmt='o', color=lavender_color, capsize=8, capthick=4, elinewidth=3, markersize=15)\n",
    "\n",
    "    x_positions = np.arange(len(acq_params))\n",
    "    emmeans = [emm_df[emm_df['acq'] == acq]['emmean'].values[0] for acq in acq_params]\n",
    "    ax.plot(x_positions, emmeans, color=lavender_color, linewidth=5, linestyle='-')\n",
    "\n",
    "    ax.set_ylabel(f\"{img_value} EMMs\", fontsize=56)\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(custom_labels, fontsize=32, rotation=45, ha='right')\n",
    "    ax.set_xlabel(\"Acquisition\", fontsize=40)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=32)\n",
    "\n",
    "    y_values = emm_df['emmean'].values\n",
    "    y_errors = emm_df['SE'].values\n",
    "    if y_values.size > 0:\n",
    "        y_upper = max(y_values + y_errors)\n",
    "        y_lower = min(y_values - y_errors)\n",
    "        padding = (y_upper - y_lower) * 0.1\n",
    "        ax.set_ylim(y_lower - padding, y_upper + padding)\n",
    "    else:\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if output_dir:\n",
    "        plot_file = os.path.join(output_dir, f\"emm_plot_{type_value}_{img_value}_{mask_value}_{denoise_value}.png\")\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"EMM plot saved as '{plot_file}'\")\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "def generate_summary_table(df_long_clean, acq_params, lmm_result, tukey_acq, emm_df):\n",
    "    \"\"\"\n",
    "    Generate APA-style summary table of ANOVA and related statistics.\n",
    "\n",
    "    Parameters:\n",
    "    - df_long_clean: DataFrame with cleaned data for analysis.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    - lmm_result: Linear mixed-effects model result.\n",
    "    - tukey_acq: Tukey HSD pairwise comparison result.\n",
    "    - emm_df: DataFrame with estimated marginal means.\n",
    "\n",
    "    Returns:\n",
    "    - summary_df: APA-style summary table as a DataFrame.\n",
    "    \"\"\"\n",
    "    # ANOVA (LMM fixed effect) statistics\n",
    "    anova_data = {\n",
    "        'Statistic': ['F', 'df', 'p-value', 'Marginal R²'],\n",
    "        'Value': []\n",
    "    }\n",
    "    if lmm_result is not None:\n",
    "        # Compute F-test via likelihood ratio test\n",
    "        try:\n",
    "            # Fit reduced model without acq\n",
    "            reduced_model = smf.mixedlm(\"beta ~ 1\", df_long_clean, groups=df_long_clean[\"subject\"])\n",
    "            reduced_result = reduced_model.fit()\n",
    "            # Likelihood ratio test\n",
    "            lr_stat = 2 * (lmm_result.llf - reduced_result.llf)\n",
    "            df_num = len(acq_params) - 1\n",
    "            df_den = lmm_result.df_resid if hasattr(lmm_result, 'df_resid') else len(df_long_clean) - df_num - 1\n",
    "            p_val = chi2.sf(lr_stat, df_num)\n",
    "            # Approximate F-statistic: LR statistic / df_num\n",
    "            f_stat = lr_stat / df_num if df_num > 0 else np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"Likelihood ratio test failed: {e}\")\n",
    "            f_stat = np.nan\n",
    "            p_val = np.nan\n",
    "            df_num = len(acq_params) - 1\n",
    "            df_den = lmm_result.df_resid if hasattr(lmm_result, 'df_resid') else np.nan\n",
    "        # Marginal R²: variance of fixed effects / (fixed + random + residual)\n",
    "        if hasattr(lmm_result, 'scale') and hasattr(lmm_result, 'cov_re'):\n",
    "            fixed_params = lmm_result.params[1:]  # Exclude intercept\n",
    "            sigma_f = np.sum(fixed_params**2) if len(fixed_params) > 0 else 0\n",
    "            sigma_r = lmm_result.cov_re.iloc[0, 0] if not lmm_result.cov_re.empty else 0\n",
    "            sigma_e = lmm_result.scale\n",
    "            total_var = sigma_f + sigma_r + sigma_e\n",
    "            r2_marginal = sigma_f / total_var if total_var != 0 else np.nan\n",
    "        else:\n",
    "            r2_marginal = np.nan\n",
    "        anova_data['Value'] = [f\"{f_stat:.2f}\", f\"{df_num}, {df_den:.1f}\", f\"{p_val:.3f}\", f\"{r2_marginal:.2f}\"]\n",
    "    else:\n",
    "        anova_data['Value'] = [\"N/A\", \"N/A\", \"N/A\", \"N/A\"]\n",
    "\n",
    "    # Descriptive statistics and EMMs\n",
    "    desc_data = {\n",
    "        'Acquisition': [],\n",
    "        'N': [],\n",
    "        'Mean (SD)': [],\n",
    "        'Range': [],\n",
    "        'EMM (SE)': []\n",
    "    }\n",
    "    for i, acq in enumerate(acq_params):\n",
    "        acq_data = df_long_clean[df_long_clean['acq'] == acq]\n",
    "        n = len(acq_data)\n",
    "        mean = acq_data['beta'].mean()\n",
    "        sd = acq_data['beta'].std()\n",
    "        min_val = acq_data['beta'].min()\n",
    "        max_val = acq_data['beta'].max()\n",
    "        # Match EMMs using integer index (1-based from R)\n",
    "        emm_row = emm_df[emm_df['acq'] == str(i+1)] if emm_df is not None else pd.DataFrame()\n",
    "        emm = emm_row['emmean'].iloc[0] if not emm_row.empty else np.nan\n",
    "        se = emm_row['SE'].iloc[0] if not emm_row.empty else np.nan\n",
    "        \n",
    "        desc_data['Acquisition'].append(acq)\n",
    "        desc_data['N'].append(n)\n",
    "        desc_data['Mean (SD)'].append(f\"{mean:.2f} ({sd:.2f})\" if not np.isnan(mean) else \"N/A\")\n",
    "        desc_data['Range'].append(f\"[{min_val:.2f}, {max_val:.2f}]\" if not np.isnan(min_val) else \"N/A\")\n",
    "        desc_data['EMM (SE)'].append(f\"{emm:.2f} ({se:.2f})\" if not np.isnan(emm) else \"N/A\")\n",
    "\n",
    "    # Pairwise comparisons (all pairs for completeness)\n",
    "    pairwise_data = {\n",
    "        'Comparison': [],\n",
    "        'Mean Difference': [],\n",
    "        '95% CI': [],\n",
    "        'p-value': []\n",
    "    }\n",
    "    if tukey_acq is not None:\n",
    "        tukey_df = pd.DataFrame(tukey_acq._results_table.data[1:], columns=tukey_acq._results_table.data[0])\n",
    "        for _, row in tukey_df.iterrows():\n",
    "            pairwise_data['Comparison'].append(f\"{row['group1']} vs. {row['group2']}\")\n",
    "            pairwise_data['Mean Difference'].append(f\"{row['meandiff']:.2f}\")\n",
    "            pairwise_data['95% CI'].append(f\"[{row['lower']:.2f}, {row['upper']:.2f}]\")\n",
    "            pairwise_data['p-value'].append(f\"{row['p-adj']:.3f}\")\n",
    "\n",
    "    # Combine into a single table with sections\n",
    "    summary_df = pd.DataFrame()\n",
    "    if anova_data['Value']:\n",
    "        anova_df = pd.DataFrame(anova_data)\n",
    "        anova_df.insert(0, 'Section', 'ANOVA')\n",
    "        summary_df = pd.concat([summary_df, anova_df], ignore_index=True)\n",
    "    \n",
    "    desc_df = pd.DataFrame(desc_data)\n",
    "    desc_df.insert(0, 'Section', 'Descriptive and EMM')\n",
    "    summary_df = pd.concat([summary_df, desc_df], ignore_index=True)\n",
    "    \n",
    "    if pairwise_data['Comparison']:\n",
    "        pairwise_df = pd.DataFrame(pairwise_data)\n",
    "        pairwise_df.insert(0, 'Section', 'Pairwise Comparisons (Tukey HSD)')\n",
    "        summary_df = pd.concat([summary_df, pairwise_df], ignore_index=True)\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "def process_and_visualize(base_dir, acq_params, type_value, img_value, mask_value, denoise_value, output_dir=\"../derivatives/plots\"):\n",
    "    \"\"\"\n",
    "    Full pipeline to extract, process, visualize data, and perform statistical analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - base_dir: Path to data files.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    - type_value, img_value, mask_value, denoise_value: Filtering criteria.\n",
    "    - output_dir: Directory to save outputs.\n",
    "\n",
    "    Returns:\n",
    "    - df: Processed DataFrame.\n",
    "    - fig: Bar plot figure.\n",
    "    - emm_fig: EMM plot figure.\n",
    "    - lmm_result: Linear mixed-effects model result.\n",
    "    - summary_table: APA-style summary table.\n",
    "    \"\"\"\n",
    "    print(f\"Processing files with parameters: type={type_value}, img={img_value}, mask={mask_value}, denoise={denoise_value}\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    data_by_subject = extract_file_data(base_dir, acq_params, type_value, img_value, mask_value, denoise_value)\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return pd.DataFrame(columns=['subject'] + acq_params), plt.figure(), plt.figure(), None, pd.DataFrame()\n",
    "    \n",
    "    df = create_dataframe(data_by_subject, acq_params)\n",
    "    output_file = os.path.join(output_dir, f\"multiecho_data_{type_value}_{img_value}_{mask_value}_{denoise_value}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    print(f\"Missing values per column:\\n{df.isnull().sum()}\")\n",
    "\n",
    "    df_long = pd.melt(\n",
    "        df, \n",
    "        id_vars=['subject'], \n",
    "        value_vars=acq_params,\n",
    "        var_name='acq', \n",
    "        value_name=img_value\n",
    "    )\n",
    "    df_long['acq'] = pd.Categorical(df_long['acq'], categories=acq_params, ordered=True)\n",
    "\n",
    "    print(f\"\\nRunning statistical analysis for {mask_value} ({img_value})...\")\n",
    "    df_long_clean = df_long.dropna(subset=[img_value])\n",
    "    lmm_result, tukey_acq = None, None\n",
    "    if len(df_long_clean) < 2:\n",
    "        print(f\"Insufficient data for LMM after removing NaNs: {len(df_long_clean)} observations\")\n",
    "    else:\n",
    "        try:\n",
    "            model = smf.mixedlm(f\"{img_value} ~ acq\", df_long_clean, groups=df_long_clean[\"subject\"])\n",
    "            lmm_result = model.fit()\n",
    "            print(lmm_result.summary())\n",
    "            \n",
    "            print(f\"\\nPairwise comparisons for acquisition parameters:\")\n",
    "            tukey_acq = pairwise_tukeyhsd(endog=df_long_clean[img_value], groups=df_long_clean['acq'], alpha=0.05)\n",
    "            print(tukey_acq)\n",
    "        except Exception as e:\n",
    "            print(f\"LMM failed: {e}\")\n",
    "            print(f\"Shape of df_long_clean: {df_long_clean.shape}\")\n",
    "            print(f\"Missing values in df_long_clean:\\n{df_long_clean.isnull().sum()}\")\n",
    "\n",
    "    print(f\"\\nRunning R-based EMM analysis for {mask_value} ({img_value})...\")\n",
    "    emm_df, emm_fig = None, None\n",
    "    if len(df_long_clean) >= 2:\n",
    "        try:\n",
    "            rdf = pandas2ri.py2rpy(df_long_clean)\n",
    "            ro.globalenv['rdf'] = rdf\n",
    "            ro.globalenv['img_value'] = img_value\n",
    "            ro.globalenv['acq_levels'] = ro.StrVector(acq_params)\n",
    "            \n",
    "            ro.r('''\n",
    "            library(lme4)\n",
    "            library(emmeans)\n",
    "            \n",
    "            rdf$subject <- as.factor(rdf$subject)\n",
    "            rdf$acq <- factor(rdf$acq, levels = acq_levels)\n",
    "            \n",
    "            formula_str <- paste(img_value, \"~ acq + (1 | subject)\")\n",
    "            model <- lmer(as.formula(formula_str), data = rdf)\n",
    "            \n",
    "            emm <- emmeans(model, ~ acq)\n",
    "            emm_df <- as.data.frame(emm)\n",
    "            ''')\n",
    "            \n",
    "            emm_df = pandas2ri.rpy2py(ro.globalenv['emm_df'])\n",
    "            print(f\"Debug: emm_df shape: {emm_df.shape}\")\n",
    "            print(f\"Debug: emm_df columns: {emm_df.columns.tolist()}\")\n",
    "            print(f\"Debug: emm_df head:\\n{emm_df.head()}\")\n",
    "            \n",
    "            emm_fig = create_emm_line_plot(emm_df, mask_value, output_dir, type_value, img_value, denoise_value)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"R-based EMM analysis failed: {e}\")\n",
    "\n",
    "    print(\"\\nGenerating APA-style summary table...\")\n",
    "    summary_table = generate_summary_table(df_long_clean, acq_params, lmm_result, tukey_acq, emm_df)\n",
    "    table_file = os.path.join(output_dir, f\"summary_stats_{type_value}_{img_value}_{mask_value}_{denoise_value}.csv\")\n",
    "    summary_table.to_csv(table_file, index=False)\n",
    "    print(f\"Summary table saved to {table_file}\")\n",
    "    print(\"\\nAPA-style Summary Table:\")\n",
    "    print(summary_table.to_string(index=False))\n",
    "\n",
    "    print(\"\\nCreating bar plot...\")\n",
    "    plot_data = prepare_plot_data(df, acq_params)\n",
    "    fig = create_bar_plot(plot_data, acq_params, f\"SP Subjects (n={plot_data['count']})\", f'{mask_value}, {img_value}')\n",
    "\n",
    "    plot_file = os.path.join(output_dir, f\"multiecho_plots_{type_value}_{img_value}_{mask_value}_{denoise_value}.png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Bar plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig, emm_fig, lmm_result, summary_table\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    ACQ_PARAMS = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "    \n",
    "    df, fig, emm_fig, lmm_result, summary_table = process_and_visualize(\n",
    "        base_dir=BASE_DIR, \n",
    "        acq_params=ACQ_PARAMS, \n",
    "        type_value=\"act\", \n",
    "        img_value=\"beta\", \n",
    "        mask_value=\"VSconstrained\", \n",
    "        denoise_value=\"base\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd71d3-8f31-43bc-b87e-2ba2980a4aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
