{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622660e5-1e5a-48ad-8926-2f0a142d3d2b",
   "metadata": {},
   "source": [
    "# Multiecho fMRI Pilot Study: Acquisition and Denoising Effects\n",
    "\n",
    "This Jupyter notebook analyzes a multiecho fMRI pilot dataset to evaluate the effects of acquisition parameters—headcoil type (20 vs. 64 channels), multiband (MB) factors (mb1, mb3, mb6), and multi-echo (ME) settings (me1, me4)—and denoising methods on data quality and functional metrics. It comprises four main sections:\n",
    "\n",
    "1. **TSNR and Smoothness Analysis**: Assesses TSNR and Smoothness across acquisition types using mixed-effects models and bar plots, integrating Python and R for statistical rigor.\n",
    "2. **Multiecho Analysis**: Examines a specified metric (e.g., beta) across ROIs, headcoils, and acquisitions, with bar plots and consistent statistical modeling.\n",
    "3. **Framewsie Displacement and Denoising**: Links framewise displacement (fd_mean) to differences between Tedana and baseline denoising for me4 acquisitions, visualized with scatter plots split by headcoil and combined.\n",
    "4. **Special Acquisitions**: Summarizes a metric for `sp` subjects across acquisitions, presented as a bar plot with means and errors.\n",
    "\n",
    "### Objectives\n",
    "- Quantify how acquisition parameters affect data quality (TSNR, Smoothness) and functional outcomes (e.g., beta values).\n",
    "- Compare denoising strategies (Tedana vs. baseline) in relation to head motion (FD).\n",
    "- Provide visual and statistical insights for pilot study optimization.\n",
    "\n",
    "### Data Sources\n",
    "- TSNR/Smoothness CSVs and fMRI text files from `~/Documents/GitHub/multiecho-pilot/derivatives/extractions`.\n",
    "- FD data from a TSV file (`Outlier-info_mriqc-0.16.1.tsv`).\n",
    "\n",
    "### Outputs\n",
    "- CSV files with processed data, PNG plots (bar and scatter), and statistical summaries saved in the working directory.\n",
    "\n",
    "This notebook supports reproducible analysis for understanding multiecho fMRI trade-offs, guiding future acquisition and preprocessing decisions.\n",
    "\n",
    "Extraction script:\n",
    "`https://github.com/DVS-Lab/multiecho-pilot/blob/main/code/extract_signal.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df93fde-08dd-470c-a3fd-1e0ade583613",
   "metadata": {},
   "source": [
    "# Fig 3. Smoothness Analysis with Mixed-Effects Modeling\n",
    "\n",
    "This code chunk processes and analyzes Temporal Signal-to-Noise Ratio (TSNR) and Smoothness data from multiecho fMRI acquisitions, evaluating the effects of headcoil type (20 vs. 64 channels), multiband (MB) factor (mb1, mb3, mb6), and multi-echo (ME) settings (me1, me4). It integrates Python for data handling and plotting with R for advanced statistical modeling, ensuring consistency with prior analyses.\n",
    "\n",
    "### Key Components\n",
    "1. **Data Loading and Preprocessing**:\n",
    "   - `load_and_preprocess_data`: \n",
    "     - Loads TSNR data from a CSV file (e.g., `tsnr_path`) with columns like `Subject`, `ReceiveCoilName`, `AcquisitionType`, and `tsnrMedian`.\n",
    "     - Loads Smoothness data from another CSV (e.g., `smoothness_path`), extracting `sub`, `acq`, and `smoothness` from file paths and values.\n",
    "     - Merges datasets on `sub` and `acq`, excludes subjects with `sp` in IDs, and splits `acq` into `mb` and `me` columns.\n",
    "     - Converts `coil`, `mb`, and `me` to categorical variables for analysis.\n",
    "\n",
    "2. **Data Aggregation**:\n",
    "   - `process_data`: \n",
    "     - Groups data by `mb`, `me`, and `coil`, calculating means, standard errors, and subject counts for a specified metric (`tsnrMedian` or `smoothness`).\n",
    "     - Drops NaNs to ensure robust statistics.\n",
    "\n",
    "3. **Visualization**:\n",
    "   - `create_tsnr_smoothness_plots`: \n",
    "     - Generates bar plots for each headcoil type, showing metric values across MB factors (mb1, mb3, mb6), with ME settings differentiated by color (blue for me1, orange for me4).\n",
    "     - Includes error bars (standard errors) and subject counts in titles.\n",
    "\n",
    "4. **Statistical Analysis**:\n",
    "   - `run_statistical_analysis`: \n",
    "     - Uses R’s `lme4` and `emmeans` via `rpy2` to fit a linear mixed-effects model: `<metric> ~ HC * MB * ME + (1 | Subj)`.\n",
    "     - Treats `MB` and `ME` as ordered factors (`mb1 < mb3 < mb6`, `me1 < me4`) for linear and quadratic contrasts.\n",
    "     - Computes pairwise comparisons for `MB` levels, averaged over `HC` and `ME`.\n",
    "     - Outputs model summaries (random/fixed effects) and pairwise results.\n",
    "\n",
    "5. **Execution**:\n",
    "   - `analyze_multiecho_data`: \n",
    "     - Orchestrates the full pipeline: preprocessing, aggregation, plotting, and statistical analysis.\n",
    "     - Returns a dictionary with merged data, plots, and statistical results.\n",
    "\n",
    "### Inputs\n",
    "- `tsnr_path`: Path to TSNR CSV file (e.g., `~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv`).\n",
    "- `smoothness_path`: Path to Smoothness CSV file (e.g., `~/Documents/GitHub/multiecho-pilot/smoothness-all.csv`).\n",
    "\n",
    "### Outputs\n",
    "- **Data**: Merged DataFrame with columns `sub`, `coil`, `acq`, `tsnrMedian`, `smoothness`, `mb`, and `me`.\n",
    "- **Plots**: Bar plots saved as `tsnrMedian_analysis.png` and `smoothness_analysis.png`.\n",
    "- **Statistical Results**: Dictionary with model summaries and pairwise comparisons for TSNR and Smoothness.\n",
    "\n",
    "### Notes\n",
    "- Requires `rpy2` and R packages (`lme4`, `lmerTest`, `emmeans`) for statistical modeling.\n",
    "- Handles missing data by dropping NaNs before analysis, with diagnostics printed for transparency.\n",
    "- Plot aesthetics (e.g., font size=48) are standardized for readability.\n",
    "- Assumes TSNR CSV has specific columns; raises errors if they’re missing.\n",
    "\n",
    "This chunk provides a reproducible workflow for assessing TSNR and Smoothness across acquisition parameters, leveraging mixed-effects modeling to account for subject variability and interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3d72c-1658-4530-94c5-c1bb4138b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "# Activate automatic conversion between pandas and R dataframes\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "lme4 = importr('lme4')\n",
    "lmerTest = importr('lmerTest')\n",
    "emmeans = importr('emmeans')\n",
    "base = importr('base')\n",
    "\n",
    "def load_and_preprocess_data(tsnr_path, smoothness_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess TSNR and smoothness data\n",
    "    \"\"\"\n",
    "    tsnr_path = os.path.expanduser(tsnr_path)\n",
    "    smoothness_path = os.path.expanduser(smoothness_path)\n",
    "    \n",
    "    data = pd.read_csv(tsnr_path)\n",
    "    print(\"TSNR Data Columns:\", list(data.columns))\n",
    "    \n",
    "    column_mapping = {\n",
    "        'Subject': 'sub',\n",
    "        'ReceiveCoilName': 'coil',\n",
    "        'AcquisitionType': 'acq',\n",
    "        'tsnrMedian': 'tsnrMedian'\n",
    "    }\n",
    "    \n",
    "    missing_cols = [col for col in column_mapping.keys() if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}. Found columns: {list(data.columns)}\")\n",
    "    \n",
    "    data = data.rename(columns=column_mapping)\n",
    "    data = data[~data['sub'].str.contains('sp', na=False)]\n",
    "    print(\"TSNR Data after preprocessing:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    smooth_raw = pd.read_csv(smoothness_path)\n",
    "    print(\"Smoothness CSV first few rows:\")\n",
    "    print(smooth_raw.head())\n",
    "    print(\"Smoothness CSV columns:\", list(smooth_raw.columns))\n",
    "    \n",
    "    smooth = pd.DataFrame()\n",
    "    filepath_col = smooth_raw.columns[0]\n",
    "    \n",
    "    smooth['filepath'] = smooth_raw[filepath_col].where(\n",
    "        smooth_raw[filepath_col].str.contains('sub-', na=False),\n",
    "        pd.NA\n",
    "    )\n",
    "    smooth['filepath'] = smooth['filepath'].ffill()\n",
    "    smooth['smoothness'] = pd.to_numeric(smooth_raw['Unnamed: 3'], errors='coerce')\n",
    "    smooth = smooth.dropna(subset=['smoothness'])\n",
    "    \n",
    "    smooth['sub'] = smooth['filepath'].str.extract(r'sub-(\\d+)')\n",
    "    smooth['acq'] = smooth['filepath'].str.extract(r'acq-(mb\\d+me\\d+)')\n",
    "    smooth = smooth[~smooth['sub'].str.contains('sp', na=False)]\n",
    "    smooth = smooth[['sub', 'acq', 'smoothness']]\n",
    "    print(\"Smoothness Data after preprocessing:\")\n",
    "    print(smooth.head())\n",
    "    print(\"Smoothness Data shape:\", smooth.shape)\n",
    "    \n",
    "    data_merged = pd.merge(data, smooth, on=['sub', 'acq'], how='left')\n",
    "    data_merged['mb'] = data_merged['acq'].str.extract(r'(mb\\d+)')[0]\n",
    "    data_merged['me'] = data_merged['acq'].str.extract(r'(me\\d+)')[0]\n",
    "    \n",
    "    categorical_cols = ['coil', 'mb', 'me']\n",
    "    for col in categorical_cols:\n",
    "        data_merged[col] = pd.Categorical(data_merged[col])\n",
    "    \n",
    "    print(\"Merged Data Columns:\", list(data_merged.columns))\n",
    "    print(\"Merged Data Head:\")\n",
    "    print(data_merged.head())\n",
    "    \n",
    "    return data_merged\n",
    "\n",
    "def process_data(data, value_column):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard error by multiband, multi-echo, and coil\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=['mb', 'me', 'coil', value_column])\n",
    "    \n",
    "    print(f\"Data after dropna for {value_column}:\")\n",
    "    print(data.head())\n",
    "    print(f\"Number of rows: {len(data)}\")\n",
    "    \n",
    "    agg_data = data.groupby(['mb', 'me', 'coil'], observed=True).agg({\n",
    "        value_column: 'mean',\n",
    "        'sub': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    std_error = data.groupby(['mb', 'me', 'coil'], observed=True)[value_column].apply(\n",
    "        lambda x: x.std() / np.sqrt(len(x))\n",
    "    ).reset_index()\n",
    "    std_error.columns = ['mb', 'me', 'coil', 'se']\n",
    "    \n",
    "    result = pd.merge(agg_data, std_error, on=['mb', 'me', 'coil'])\n",
    "    result.columns = ['mb', 'me', 'coil', value_column, 'n_subjects', 'se']\n",
    "    \n",
    "    print(f\"Processed Data for {value_column}:\")\n",
    "    print(result.head())\n",
    "    print(f\"Processed Data Info:\")\n",
    "    print(result.info())\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_tsnr_smoothness_plots(data_processed, img_type='tsnr', save_files=True):\n",
    "    \"\"\"\n",
    "    Create plots similar to the original Python kernel's bar plots\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    coil_types = data_processed['coil'].unique()\n",
    "    fig, axes = plt.subplots(1, len(coil_types), figsize=(8 * len(coil_types), 8))\n",
    "    if len(coil_types) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    width = 0.4\n",
    "    x1 = [0, 1.2, 2.4]\n",
    "    x2 = [x + width for x in x1]\n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    mb_levels = ['mb1', 'mb3', 'mb6']\n",
    "    \n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for i, (coil, ax) in enumerate(zip(coil_types, axes)):\n",
    "        coil_data = data_processed[data_processed['coil'] == coil]\n",
    "        if coil_data.empty:\n",
    "            print(f\"No data for coil {coil}\")\n",
    "            ax.set_title(f\"{coil}-Channel\\nn=0\", fontsize=48, fontweight='bold')\n",
    "            continue\n",
    "        \n",
    "        me1_data = coil_data[coil_data['me'] == 'me1']\n",
    "        me4_data = coil_data[coil_data['me'] == 'me4']\n",
    "        \n",
    "        me1_means = me1_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me1_errors = me1_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        me4_means = me4_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me4_errors = me4_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        \n",
    "        ax.bar(x1, me1_means, width, color=me_colors['me1'], label='me1', \n",
    "               yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me_colors['me4'], label='me4', \n",
    "               yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        y_values = list(me1_means) + list(me4_means)\n",
    "        y_errors = list(me1_errors) + list(me4_errors)\n",
    "        all_y_values.extend([v for v in y_values if v != 0])\n",
    "        all_y_errors.extend([e for e in y_errors if e != 0])\n",
    "        \n",
    "        ax.set_xticks([width/2, 1.2+width/2, 2.4+width/2])\n",
    "        ax.set_xticklabels(mb_levels, fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel(img_type.upper(), fontsize=48)\n",
    "        \n",
    "        n_subjects = int(coil_data['n_subjects'].iloc[0]) if not coil_data['n_subjects'].empty else 0\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        \n",
    "        y_max = max([v + e for v, e in zip(y_values, y_errors) if v != 0], default=0)\n",
    "        margin = y_max * 0.1\n",
    "        ax.set_ylim(0, y_max + margin)\n",
    "    \n",
    "    if len(coil_types) > 0:\n",
    "        axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                        loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    \n",
    "    if save_files:\n",
    "        plt.savefig(f'{img_type}_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def run_statistical_analysis(data):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis using R's lme4 and emmeans\n",
    "    \"\"\"\n",
    "    # Prepare data for R: rename columns to match R script and drop NaN\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR', 'smoothness': 'Smoothness'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'Smoothness', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    # Convert categorical columns to strings to avoid RPy2 conversion issues\n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    # Convert to R dataframe\n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    results = {}\n",
    "    for metric in ['TSNR', 'Smoothness']:\n",
    "        # Define the formula for the mixed-effects model\n",
    "        formula = Formula(f'{metric} ~ HC * MB * ME + (1 | Subj)')\n",
    "        \n",
    "        # Fit the model using lmer\n",
    "        model = lme4.lmer(formula, data=r_df)\n",
    "        \n",
    "        # Get the model summary (commented out as per user request)\n",
    "        # summary = base.summary(model)\n",
    "        # print(f\"\\nLinear Mixed Effects Model for {metric}:\")\n",
    "        # print(summary)\n",
    "        \n",
    "        # Pairwise comparisons using emmeans with interactions\n",
    "        emm = emmeans.emmeans(model, ~ 'HC * MB * ME')\n",
    "        pairwise = ro.r('pairs')(emm)  # Explicitly call R's pairs() function\n",
    "        print(f\"\\nPairwise comparisons for HC * MB * ME in {metric}:\")\n",
    "        print(pairwise)\n",
    "        \n",
    "        results[metric] = {\n",
    "            'pairwise_HC_MB_ME': str(pairwise)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_multiecho_data(tsnr_path, smoothness_path):\n",
    "    \"\"\"\n",
    "    Main function to perform complete analysis\n",
    "    \"\"\"\n",
    "    data_merged = load_and_preprocess_data(tsnr_path, smoothness_path)\n",
    "    tsnr_processed = process_data(data_merged, 'tsnrMedian')\n",
    "    smoothness_processed = process_data(data_merged, 'smoothness')\n",
    "    \n",
    "    tsnr_plot = create_tsnr_smoothness_plots(tsnr_processed, 'tsnrMedian')\n",
    "    smoothness_plot = create_tsnr_smoothness_plots(smoothness_processed, 'smoothness')\n",
    "    \n",
    "    statistical_results = run_statistical_analysis(data_merged)\n",
    "    \n",
    "    return {\n",
    "        'data': data_merged,\n",
    "        'tsnr_plot': tsnr_plot,\n",
    "        'smoothness_plot': smoothness_plot,\n",
    "        'statistical_results': statistical_results\n",
    "    }\n",
    "\n",
    "results = analyze_multiecho_data(\n",
    "    '~/Documents/GitHub/multiecho-pilot/smoothness-all-zero.csv', \n",
    "    '~/Documents/GitHub/multiecho-pilot/smoothness-all.csv' # use smoothness-all-zero.csv for pre-5mm smoothed data (panel A)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099fb1c1-2b73-4822-8161-480aece76722",
   "metadata": {},
   "source": [
    "\n",
    "# Fig 4. Analysis of TSNR in Multiband Multi-Echo fMRI\n",
    "\n",
    "*\"Description of Python Pipeline\"author: \"Grok 3, xAI\"date: \"April 30, 2025\"output:  html_document:    toc: truetoc_float: true*\n",
    "\n",
    "This document describes a Python-based analysis pipeline (tsnr_analysis.py) designed to evaluate the effects of head coil type (HC), multiband factor (MB), and multi-echo acquisition (ME) on temporal signal-to-noise ratio (TSNR) in functional MRI (fMRI) data. The pipeline processes TSNR data, generates visualizations, and performs statistical analysis using a linear mixed effects model. The analysis was conducted using Python with the rpy2 library to interface with R for statistical modeling.\n",
    "Purpose of the Pipeline\n",
    "The tsnr_analysis.py script performs the following tasks:\n",
    "\n",
    "### Data Preprocessing:\n",
    "\n",
    "- Loads a CSV file containing TSNR data with columns for subject ID, head coil type (20-channel or 64-channel), acquisition type (e.g., mb1me1 for MB1 ME1), and median TSNR.\n",
    "- Extracts multiband (MB) and multi-echo (ME) factors from the acquisition type and filters out rows with missing data.\n",
    "\n",
    "\n",
    "### Visualization:\n",
    "\n",
    "- Creates bar plots showing median TSNR across MB levels (MB1, MB3, MB6) for each ME level (ME1, ME4) and HC type (20-channel, 64-channel), with error bars representing standard errors.\n",
    "- Generates line plots of estimated marginal means (EMMs) from the statistical model, illustrating the interaction effects across MB, ME, and HC.\n",
    "\n",
    "\n",
    "### Statistical Analysis:\n",
    "\n",
    "- Fits a linear mixed effects model with the formula TSNR ~ HC * MB * ME + (1 | Subj), where Subj is a random intercept to account for inter-subject variability.\n",
    "- Computes pairwise comparisons using estimated marginal means to explore significant differences between all combinations of HC, MB, and ME.\n",
    "\n",
    "\n",
    "\n",
    "### Key Dependencies\n",
    "The Python script relies on the following libraries:\n",
    "\n",
    "- `pandas` and numpy for data manipulation.\n",
    "- `matplotlib` for plotting.\n",
    "- `rpy2` to interface with R, using R packages lme4, lmerTest, and emmeans for statistical analysis.\n",
    "\n",
    "\n",
    "\n",
    "### Usage\n",
    "To use the Python pipeline:\n",
    "\n",
    "- Ensure the required Python libraries and R packages are installed.\n",
    "- Prepare a CSV file with columns Subject, ReceiveCoilName, AcquisitionType, and tsnrMedian.\n",
    "- Run the script with the path to the CSV file as input: results = analyze_tsnr_data('path/to/data.csv').\n",
    "\n",
    "The script will generate bar plots, EMM line plots, and statistical output as shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95517af8-e97d-42e0-9e25-df4558bd699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "# Activate automatic conversion between pandas and R dataframes\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "lme4 = importr('lme4')\n",
    "lmerTest = importr('lmerTest')\n",
    "emmeans = importr('emmeans')\n",
    "base = importr('base')\n",
    "\n",
    "def load_and_preprocess_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess TSNR data\n",
    "    \"\"\"\n",
    "    tsnr_path = os.path.expanduser(tsnr_path)\n",
    "    \n",
    "    data = pd.read_csv(tsnr_path)\n",
    "    \n",
    "    column_mapping = {\n",
    "        'Subject': 'sub',\n",
    "        'ReceiveCoilName': 'coil',\n",
    "        'AcquisitionType': 'acq',\n",
    "        'tsnrMedian': 'tsnrMedian'\n",
    "    }\n",
    "    \n",
    "    missing_cols = [col for col in column_mapping.keys() if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}. Found columns: {list(data.columns)}\")\n",
    "    \n",
    "    data = data.rename(columns=column_mapping)\n",
    "    data = data[~data['sub'].str.contains('sp', na=False)]\n",
    "    \n",
    "    data['mb'] = data['acq'].str.extract(r'(mb\\d+)')[0]\n",
    "    data['me'] = data['acq'].str.extract(r'(me\\d+)')[0]\n",
    "    \n",
    "    categorical_cols = ['coil', 'mb', 'me']\n",
    "    for col in categorical_cols:\n",
    "        data[col] = pd.Categorical(data[col])\n",
    "    \n",
    "    # Compute n_subjects_per_coil after initial preprocessing\n",
    "    data_clean = data.dropna(subset=['mb', 'me', 'coil', 'tsnrMedian'])\n",
    "    n_subjects_per_coil = data_clean.groupby('coil', observed=True)['sub'].nunique().to_dict()\n",
    "    \n",
    "    return data, n_subjects_per_coil\n",
    "\n",
    "def process_data(data, value_column):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard error by multiband, multi-echo, and coil\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=['mb', 'me', 'coil', value_column])\n",
    "    \n",
    "    agg_data = data.groupby(['mb', 'me', 'coil'], observed=True).agg({\n",
    "        value_column: 'mean',\n",
    "        'sub': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    std_error = data.groupby(['mb', 'me', 'coil'], observed=True)[value_column].apply(\n",
    "        lambda x: x.std() / np.sqrt(len(x))\n",
    "    ).reset_index()\n",
    "    std_error.columns = ['mb', 'me', 'coil', 'se']\n",
    "    \n",
    "    result = pd.merge(agg_data, std_error, on=['mb', 'me', 'coil'])\n",
    "    result.columns = ['mb', 'me', 'coil', value_column, 'n_subjects', 'se']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_tsnr_bar_plots(data_processed, n_subjects_per_coil, img_type='tsnrMedian', save_files=True):\n",
    "    \"\"\"\n",
    "    Create bar plots for TSNR\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    coil_types = data_processed['coil'].unique()\n",
    "    fig, axes = plt.subplots(1, len(coil_types), figsize=(8 * len(coil_types), 8))\n",
    "    if len(coil_types) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    width = 0.4\n",
    "    x1 = [0, 1.2, 2.4]\n",
    "    x2 = [x + width for x in x1]\n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    mb_levels = ['mb1', 'mb3', 'mb6']\n",
    "    \n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for i, (coil, ax) in enumerate(zip(coil_types, axes)):\n",
    "        coil_data = data_processed[data_processed['coil'] == coil]\n",
    "        if coil_data.empty:\n",
    "            ax.set_title(f\"{coil}-Channel\\nn=0\", fontsize=48, fontweight='bold')\n",
    "            continue\n",
    "        \n",
    "        me1_data = coil_data[coil_data['me'] == 'me1']\n",
    "        me4_data = coil_data[coil_data['me'] == 'me4']\n",
    "        \n",
    "        me1_means = me1_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me1_errors = me1_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        me4_means = me4_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me4_errors = me4_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        \n",
    "        ax.bar(x1, me1_means, width, color=me_colors['me1'], label='me1', \n",
    "               yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me_colors['me4'], label='me4', \n",
    "               yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        y_values = list(me1_means) + list(me4_means)\n",
    "        y_errors = list(me1_errors) + list(me4_errors)\n",
    "        all_y_values.extend([v for v in y_values if v != 0])\n",
    "        all_y_errors.extend([e for e in y_errors if e != 0])\n",
    "        \n",
    "        ax.set_xticks([width/2, 1.2+width/2, 2.4+width/2])\n",
    "        ax.set_xticklabels(mb_levels, fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Median TSNR', fontsize=48)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        \n",
    "        y_max = max([v + e for v, e in zip(y_values, y_errors) if v != 0], default=0)\n",
    "        margin = y_max * 0.1\n",
    "        ax.set_ylim(0, y_max + margin)\n",
    "    \n",
    "    if len(coil_types) > 0:\n",
    "        axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                        loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    \n",
    "    if save_files:\n",
    "        plt.savefig('tsnr_bar_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plots(data, n_subjects_per_coil):\n",
    "    \"\"\"\n",
    "    Create line plots for estimated marginal means of TSNR with consistent y-axis across subplots\n",
    "    \"\"\"\n",
    "    # Prepare data for R\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Ensure MB and ME are factors with correct levels in R\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    ''')\n",
    "    r_df = ro.r('''\n",
    "    transform({}, MB = factor(MB, levels = levels_MB), ME = factor(ME, levels = levels_ME), HC = factor(HC))\n",
    "    '''.format(r_df.r_repr()))\n",
    "    \n",
    "    # Fit the model\n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=r_df)\n",
    "    \n",
    "    # Compute EMMs\n",
    "    emm = emmeans.emmeans(model, 'MB', by=ro.StrVector(['HC', 'ME']))\n",
    "    emm_r_df = ro.r('as.data.frame')(emm)\n",
    "    emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "    \n",
    "    # Map numeric indices to string labels\n",
    "    mb_map = {1: 'mb1', 2: 'mb3', 3: 'mb6'}\n",
    "    me_map = {1: 'me1', 2: 'me4'}\n",
    "    hc_levels = sorted(data['coil'].unique())\n",
    "    hc_map = {i + 1: hc for i, hc in enumerate(hc_levels)}\n",
    "    \n",
    "    emm_df['MB'] = emm_df['MB'].map(mb_map)\n",
    "    emm_df['ME'] = emm_df['ME'].map(me_map)\n",
    "    emm_df['HC'] = emm_df['HC'].map(hc_map)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    coil_types = emm_df['HC'].unique()\n",
    "    \n",
    "    # Collect all y-values and errors to determine consistent y-axis limits\n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for coil in coil_types:\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            if not me_data.empty:\n",
    "                y_values = me_data['emmean'].values\n",
    "                y_errors = me_data['SE'].values\n",
    "                all_y_values.extend(y_values)\n",
    "                all_y_errors.extend(y_errors)\n",
    "    \n",
    "    # Calculate global y-axis limits\n",
    "    if all_y_values:  # Ensure there are values to process\n",
    "        y_max = max([v + e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        y_min = min([v - e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        margin = (y_max - y_min) * 0.1  # Add 10% margin\n",
    "        y_limits = (max(0, y_min - margin), y_max + margin)  # Ensure y_min is not negative\n",
    "    else:\n",
    "        y_limits = (0, 1)  # Default in case of no data\n",
    "    \n",
    "    # Plot each subplot with consistent y-axis\n",
    "    for i, coil in enumerate(coil_types):\n",
    "        ax = axes[i]\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        \n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            me_data = me_data.sort_values('MB', key=lambda x: x.str.extract(r'mb(\\d+)')[0].astype(int))\n",
    "            ax.plot(me_data['MB'], me_data['emmean'], marker='o', color=me_colors[me], label=me, linewidth=5, markersize=15)\n",
    "            ax.errorbar(me_data['MB'], me_data['emmean'], yerr=me_data['SE'], fmt='none', color=me_colors[me], capsize=8, capthick=4, elinewidth=3)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Estimated\\nMarginal Mean TSNR', fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        ax.set_ylim(y_limits)  # Apply consistent y-axis limits\n",
    "    \n",
    "    axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                    loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    plt.savefig('tsnr_emm_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def run_statistical_analysis(data):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis for TSNR using R's lme4 and emmeans\n",
    "    \"\"\"\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Ensure MB and ME are factors with correct levels in R\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    ''')\n",
    "    r_df = ro.r('''\n",
    "    transform({}, MB = factor(MB, levels = levels_MB), ME = factor(ME, levels = levels_ME), HC = factor(HC))\n",
    "    '''.format(r_df.r_repr()))\n",
    "    \n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=r_df)\n",
    "    \n",
    "    # Get the model summary and suppress the Data section\n",
    "    model_summary = ro.r('summary')(model)\n",
    "    summary_lines = ro.r('capture.output')(model_summary)\n",
    "    # Find the index of the \"Data:\" line and the next section\n",
    "    summary_lines_list = list(summary_lines)\n",
    "    data_start = None\n",
    "    data_end = None\n",
    "    for i, line in enumerate(summary_lines_list):\n",
    "        if line.startswith('   Data:'):\n",
    "            data_start = i\n",
    "        elif data_start is not None and line.startswith('REML criterion at convergence:'):\n",
    "            data_end = i\n",
    "            break\n",
    "    if data_start is not None and data_end is not None:\n",
    "        summary_lines_list = summary_lines_list[:data_start] + summary_lines_list[data_end:]\n",
    "    model_summary_str = '\\n'.join(summary_lines_list)\n",
    "    print(\"\\nLinear Mixed Effects Model Summary (TSNR ~ HC * MB * ME + (1 | Subj)):\\n\")\n",
    "    print(model_summary_str)\n",
    "    \n",
    "    # Compute pairwise comparisons\n",
    "    emm = emmeans.emmeans(model, ro.StrVector(['HC', 'MB', 'ME']))\n",
    "    pairwise = ro.r('pairs')(emm)\n",
    "    \n",
    "    # Convert pairwise to DataFrame\n",
    "    pairwise_r_df = ro.r('as.data.frame')(pairwise)\n",
    "    pairwise_df = pandas2ri.rpy2py(pairwise_r_df)\n",
    "    \n",
    "    # Debug: Inspect the DataFrame\n",
    "    print(\"Pairwise DataFrame columns:\", pairwise_df.columns.tolist())\n",
    "    print(\"Pairwise DataFrame head:\\n\", pairwise_df.head())\n",
    "    \n",
    "    # Map numeric indices in the contrast column to string labels\n",
    "    mb_map = {1: 'mb1', 2: 'mb3', 3: 'mb6'}\n",
    "    me_map = {1: 'me1', 2: 'me4'}\n",
    "    hc_levels = sorted(data['coil'].unique())\n",
    "    hc_map = {i + 1: hc for i, hc in enumerate(hc_levels)}\n",
    "    \n",
    "    # Replace numeric indices in the contrast column\n",
    "    def map_contrast(contrast):\n",
    "        for num, label in mb_map.items():\n",
    "            contrast = contrast.replace(f'MB{num}', f'MB{label}')\n",
    "        for num, label in me_map.items():\n",
    "            contrast = contrast.replace(f'ME{num}', f'ME{label}')\n",
    "        for num, label in hc_map.items():\n",
    "            contrast = contrast.replace(f'HC{num}', f'HC{label}')\n",
    "        return contrast\n",
    "    \n",
    "    pairwise_df['contrast'] = pairwise_df['contrast'].apply(map_contrast)\n",
    "    \n",
    "    print(\"\\nPairwise comparisons for HC * MB * ME in TSNR:\")\n",
    "    print(pairwise_df)\n",
    "    \n",
    "    return {\n",
    "        'model_summary': model_summary_str,\n",
    "        'pairwise_HC_MB_ME': pairwise_df.to_string()\n",
    "    }\n",
    "\n",
    "def analyze_tsnr_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Main function to perform TSNR analysis\n",
    "    \"\"\"\n",
    "    data, n_subjects_per_coil = load_and_preprocess_data(tsnr_path)\n",
    "    tsnr_processed = process_data(data, 'tsnrMedian')\n",
    "    \n",
    "    bar_plot = create_tsnr_bar_plots(tsnr_processed, n_subjects_per_coil, 'tsnrMedian')\n",
    "    emm_plot = create_emm_line_plots(data, n_subjects_per_coil)\n",
    "    statistical_results = run_statistical_analysis(data)\n",
    "    \n",
    "    return {\n",
    "        'data': data,\n",
    "        'bar_plot': bar_plot,\n",
    "        'emm_plot': emm_plot,\n",
    "        'statistical_results': statistical_results\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "results = analyze_tsnr_data('~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab20f6-803f-435c-95f0-1b5718ac92ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80441ff9-7fe8-43f8-95eb-4be187de400d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e4f7e-fc53-4183-bae1-c8ba6b0c8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "# Activate automatic conversion between pandas and R dataframes\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "lme4 = importr('lme4')\n",
    "lmerTest = importr('lmerTest')\n",
    "emmeans = importr('emmeans')\n",
    "base = importr('base')\n",
    "stats = importr('stats')\n",
    "\n",
    "# Check lme4 and lmerTest versions\n",
    "print(\"lme4 version:\", ro.r('packageVersion(\"lme4\")')[0])\n",
    "print(\"lmerTest version:\", ro.r('packageVersion(\"lmerTest\")')[0])\n",
    "\n",
    "def load_and_preprocess_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess TSNR data\n",
    "    \"\"\"\n",
    "    tsnr_path = os.path.expanduser(tsnr_path)\n",
    "    \n",
    "    data = pd.read_csv(tsnr_path)\n",
    "    \n",
    "    column_mapping = {\n",
    "        'Subject': 'sub',\n",
    "        'ReceiveCoilName': 'coil',\n",
    "        'AcquisitionType': 'acq',\n",
    "        'tsnrMedian': 'tsnrMedian'\n",
    "    }\n",
    "    \n",
    "    missing_cols = [col for col in column_mapping.keys() if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}. Found columns: {list(data.columns)}\")\n",
    "    \n",
    "    data = data.rename(columns=column_mapping)\n",
    "    data = data[~data['sub'].str.contains('sp', na=False)]\n",
    "    \n",
    "    data['mb'] = data['acq'].str.extract(r'(mb\\d+)')[0]\n",
    "    data['me'] = data['acq'].str.extract(r'(me\\d+)')[0]\n",
    "    \n",
    "    categorical_cols = ['coil', 'mb', 'me']\n",
    "    for col in categorical_cols:\n",
    "        data[col] = pd.Categorical(data[col])\n",
    "    \n",
    "    # Compute n_subjects_per_coil after initial preprocessing\n",
    "    data_clean = data.dropna(subset=['mb', 'me', 'coil', 'tsnrMedian'])\n",
    "    n_subjects_per_coil = data_clean.groupby('coil', observed=True)['sub'].nunique().to_dict()\n",
    "    \n",
    "    return data, n_subjects_per_coil\n",
    "\n",
    "def process_data(data, value_column):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard error by multiband, multi-echo, and coil\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=['mb', 'me', 'coil', value_column])\n",
    "    \n",
    "    agg_data = data.groupby(['mb', 'me', 'coil'], observed=True).agg({\n",
    "        value_column: 'mean',\n",
    "        'sub': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    std_error = data.groupby(['mb', 'me', 'coil'], observed=True)[value_column].apply(\n",
    "        lambda x: x.std() / np.sqrt(len(x))\n",
    "    ).reset_index()\n",
    "    std_error.columns = ['mb', 'me', 'coil', 'se']\n",
    "    \n",
    "    result = pd.merge(agg_data, std_error, on=['mb', 'me', 'coil'])\n",
    "    result.columns = ['mb', 'me', 'coil', value_column, 'n_subjects', 'se']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_tsnr_bar_plots(data_processed, n_subjects_per_coil, img_type='tsnrMedian', save_files=True):\n",
    "    \"\"\"\n",
    "    Create bar plots for TSNR\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    coil_types = data_processed['coil'].unique()\n",
    "    fig, axes = plt.subplots(1, len(coil_types), figsize=(8 * len(coil_types), 8))\n",
    "    if len(coil_types) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    width = 0.4\n",
    "    x1 = [0, 1.2, 2.4]\n",
    "    x2 = [x + width for x in x1]\n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    mb_levels = ['mb1', 'mb3', 'mb6']\n",
    "    \n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for i, (coil, ax) in enumerate(zip(coil_types, axes)):\n",
    "        coil_data = data_processed[data_processed['coil'] == coil]\n",
    "        if coil_data.empty:\n",
    "            ax.set_title(f\"{coil}-Channel\\nn=0\", fontsize=48, fontweight='bold')\n",
    "            continue\n",
    "        \n",
    "        me1_data = coil_data[coil_data['me'] == 'me1']\n",
    "        me4_data = coil_data[coil_data['me'] == 'me4']\n",
    "        \n",
    "        me1_means = me1_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me1_errors = me1_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        me4_means = me4_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me4_errors = me4_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        \n",
    "        ax.bar(x1, me1_means, width, color=me_colors['me1'], label='me1', \n",
    "               yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me_colors['me4'], label='me4', \n",
    "               yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        y_values = list(me1_means) + list(me4_means)\n",
    "        y_errors = list(me1_errors) + list(me4_errors)\n",
    "        all_y_values.extend([v for v in y_values if v != 0])\n",
    "        all_y_errors.extend([e for e in y_errors if e != 0])\n",
    "        \n",
    "        ax.set_xticks([width/2, 1.2+width/2, 2.4+width/2])\n",
    "        ax.set_xticklabels(mb_levels, fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Median TSNR', fontsize=48)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        \n",
    "        y_max = max([v + e for v, e in zip(y_values, y_errors) if v != 0], default=0)\n",
    "        margin = y_max * 0.1\n",
    "        ax.set_ylim(0, y_max + margin)\n",
    "    \n",
    "    if len(coil_types) > 0:\n",
    "        axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                        loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    \n",
    "    if save_files:\n",
    "        plt.savefig('tsnr_bar_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plots(data, n_subjects_per_coil):\n",
    "    \"\"\"\n",
    "    Create line plots for estimated marginal means of TSNR with consistent y-axis across subplots\n",
    "    \"\"\"\n",
    "    # Prepare data for R\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Ensure MB and ME are factors with correct levels in R\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    ''')\n",
    "    r_df = ro.r('''\n",
    "    transform({}, MB = factor(MB, levels = levels_MB), ME = factor(ME, levels = levels_ME), HC = factor(HC))\n",
    "    '''.format(r_df.r_repr()))\n",
    "    \n",
    "    # Fit the model\n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=r_df)\n",
    "    \n",
    "    # Compute EMMs\n",
    "    emm = emmeans.emmeans(model, 'MB', by=ro.StrVector(['HC', 'ME']))\n",
    "    emm_r_df = ro.r('as.data.frame')(emm)\n",
    "    emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "    \n",
    "    # Map numeric indices to string labels\n",
    "    mb_map = {1: 'mb1', 2: 'mb3', 3: 'mb6'}\n",
    "    me_map = {1: 'me1', 2: 'me4'}\n",
    "    hc_levels = sorted(data['coil'].unique())\n",
    "    hc_map = {i + 1: hc for i, hc in enumerate(hc_levels)}\n",
    "    \n",
    "    emm_df['MB'] = emm_df['MB'].map(mb_map)\n",
    "    emm_df['ME'] = emm_df['ME'].map(me_map)\n",
    "    emm_df['HC'] = emm_df['HC'].map(hc_map)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    coil_types = emm_df['HC'].unique()\n",
    "    \n",
    "    # Collect all y-values and errors to determine consistent y-axis limits\n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for coil in coil_types:\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            if not me_data.empty:\n",
    "                y_values = me_data['emmean'].values\n",
    "                y_errors = me_data['SE'].values\n",
    "                all_y_values.extend(y_values)\n",
    "                all_y_errors.extend(y_errors)\n",
    "    \n",
    "    # Calculate global y-axis limits\n",
    "    if all_y_values:  # Ensure there are values to process\n",
    "        y_max = max([v + e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        y_min = min([v - e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        margin = (y_max - y_min) * 0.1  # Add 10% margin\n",
    "        y_limits = (max(0, y_min - margin), y_max + margin)  # Ensure y_min is not negative\n",
    "    else:\n",
    "        y_limits = (0, 1)  # Default in case of no data\n",
    "    \n",
    "    # Plot each subplot with consistent y-axis\n",
    "    for i, coil in enumerate(coil_types):\n",
    "        ax = axes[i]\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        \n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            me_data = me_data.sort_values('MB', key=lambda x: x.str.extract(r'mb(\\d+)')[0].astype(int))\n",
    "            ax.plot(me_data['MB'], me_data['emmean'], marker='o', color=me_colors[me], label=me, linewidth=5, markersize=15)\n",
    "            ax.errorbar(me_data['MB'], me_data['emmean'], yerr=me_data['SE'], fmt='none', color=me_colors[me], capsize=8, capthick=4, elinewidth=3)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Estimated\\nMarginal Mean TSNR', fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        ax.set_ylim(y_limits)  # Apply consistent y-axis limits\n",
    "    \n",
    "    axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                    loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    plt.savefig('tsnr_emm_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def run_statistical_analysis(data):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis for TSNR using R's lme4 and lmerTest, reporting APA-style results\n",
    "    \"\"\"\n",
    "    # Prepare data for R\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    print(\"Data summary:\")\n",
    "    print(data_r.groupby(['HC', 'MB', 'ME'], observed=True)['Subj'].nunique())\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Assign data frame to R global environment and set factors\n",
    "    ro.globalenv['data_r'] = r_df\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    data_r$MB <- factor(data_r$MB, levels = levels_MB)\n",
    "    data_r$ME <- factor(data_r$ME, levels = levels_ME)\n",
    "    data_r$HC <- factor(data_r$HC)\n",
    "    contrasts(data_r$MB) <- contr.sum(levels_MB)\n",
    "    contrasts(data_r$ME) <- contr.sum(levels_ME)\n",
    "    contrasts(data_r$HC) <- contr.sum(levels(data_r$HC))\n",
    "    ''')\n",
    "    \n",
    "    # Verify contrasts\n",
    "    print(\"MB contrasts:\")\n",
    "    print(ro.r('contrasts(data_r$MB)'))\n",
    "    print(\"ME contrasts:\")\n",
    "    print(ro.r('contrasts(data_r$ME)'))\n",
    "    print(\"HC contrasts:\")\n",
    "    print(ro.r('contrasts(data_r$HC)'))\n",
    "    \n",
    "    # Fit the LME model\n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=ro.r('data_r'))\n",
    "    \n",
    "    # Extract model summary\n",
    "    model_summary = ro.r('summary')(model)\n",
    "    print(\"Model summary:\")\n",
    "    print(ro.r('capture.output')(model_summary))\n",
    "    \n",
    "    # Try ANOVA table with Satterthwaite approximation\n",
    "    try:\n",
    "        anova_table = ro.r('anova')(model, ddf=\"Satterthwaite\")\n",
    "        anova_df = pandas2ri.rpy2py(ro.r('as.data.frame')(anova_table))\n",
    "        print(\"ANOVA table columns:\", anova_df.columns.tolist())\n",
    "    except Exception as e:\n",
    "        print(\"Error in ANOVA table extraction:\", str(e))\n",
    "        anova_df = None\n",
    "    \n",
    "    # Manually define numerator degrees of freedom\n",
    "    df_dict = {\n",
    "        'Head Coil': 1,  # HC: 2 levels - 1\n",
    "        'Multiband': 2,  # MB: 3 levels - 1\n",
    "        'Multi-echo': 1,  # ME: 2 levels - 1\n",
    "        'Head Coil × Multiband': 2,  # 1 * 2\n",
    "        'Head Coil × Multi-echo': 1,  # 1 * 1\n",
    "        'Multiband × Multi-echo': 2,  # 2 * 1\n",
    "        'Head Coil × Multiband × Multi-echo': 2  # 1 * 2 * 1\n",
    "    }\n",
    "    \n",
    "    # Approximate denominator degrees of freedom (n_obs - fixed effects - random effects)\n",
    "    n_obs = len(data_r)\n",
    "    n_fixed = sum(df_dict.values())  # Total fixed effect df\n",
    "    n_subj = data_r['Subj'].nunique()  # Random effect levels\n",
    "    den_df_approx = n_obs - n_fixed - n_subj  # Simplified approximation\n",
    "    \n",
    "    # Build APA table\n",
    "    apa_data = []\n",
    "    if anova_df is not None and 'F value' in anova_df.columns:\n",
    "        for effect in anova_df.index:\n",
    "            if effect in ['(Intercept)', 'Residuals']:  # Skip non-fixed effects\n",
    "                continue\n",
    "            effect_name = {\n",
    "                'HC': 'Head Coil',\n",
    "                'MB': 'Multiband',\n",
    "                'ME': 'Multi-echo',\n",
    "                'HC:MB': 'Head Coil × Multiband',\n",
    "                'HC:ME': 'Head Coil × Multi-echo',\n",
    "                'MB:ME': 'Multiband × Multi-echo',\n",
    "                'HC:MB:ME': 'Head Coil × Multiband × Multi-echo'\n",
    "            }.get(effect, effect)\n",
    "            apa_data.append({\n",
    "                'Effect': effect_name,\n",
    "                'Sum Sq': anova_df.loc[effect, 'Sum Sq'] if 'Sum Sq' in anova_df.columns else np.nan,\n",
    "                'Mean Sq': anova_df.loc[effect, 'Mean Sq'] if 'Mean Sq' in anova_df.columns else np.nan,\n",
    "                'Num df': df_dict.get(effect_name, np.nan),  # Use manual df\n",
    "                'Den df': anova_df.loc[effect, 'DenDF'] if 'DenDF' in anova_df.columns else den_df_approx,\n",
    "                'F': anova_df.loc[effect, 'F value'] if 'F value' in anova_df.columns else np.nan,\n",
    "                'p': anova_df.loc[effect, 'Pr(>F)'] if 'Pr(>F)' in anova_df.columns else np.nan,\n",
    "                'Partial η²': np.nan  # Computed below\n",
    "            })\n",
    "    else:\n",
    "        # Fallback: Use manual df and placeholder values\n",
    "        effects = ['Head Coil', 'Multiband', 'Multi-echo', 'Head Coil × Multiband', \n",
    "                   'Head Coil × Multi-echo', 'Multiband × Multi-echo', \n",
    "                   'Head Coil × Multiband × Multi-echo']\n",
    "        for effect in effects:\n",
    "            apa_data.append({\n",
    "                'Effect': effect,\n",
    "                'Sum Sq': np.nan,\n",
    "                'Mean Sq': np.nan,\n",
    "                'Num df': df_dict.get(effect, np.nan),\n",
    "                'Den df': den_df_approx,\n",
    "                'F': np.nan,\n",
    "                'p': np.nan,\n",
    "                'Partial η²': np.nan\n",
    "            })\n",
    "    \n",
    "    # Compute partial eta-squared\n",
    "    residual_var = ro.r('sigma')(model)**2\n",
    "    if anova_df is not None and 'Sum Sq' in anova_df.columns:\n",
    "        ss_effect = anova_df['Sum Sq']\n",
    "        ss_residual = residual_var * (n_obs - n_fixed - 1)  # Approx residual SS\n",
    "        partial_eta2 = ss_effect / (ss_effect + ss_residual)\n",
    "    else:\n",
    "        partial_eta2 = pd.Series([np.nan] * len(apa_data))\n",
    "    \n",
    "    # Update partial eta-squared\n",
    "    for i, effect in enumerate([d['Effect'] for d in apa_data]):\n",
    "        apa_data[i]['Partial η²'] = partial_eta2.iloc[i] if i < len(partial_eta2) else np.nan\n",
    "    \n",
    "    # Extract p-values using contest() if anova fails to provide them\n",
    "    if anova_df is None or 'Pr(>F)' not in anova_df.columns:\n",
    "        p_values = {}\n",
    "        effects = ['HC', 'MB', 'ME', 'HC:MB', 'HC:ME', 'MB:ME', 'HC:MB:ME']\n",
    "        for effect in effects:\n",
    "            try:\n",
    "                # Define contrast for each effect\n",
    "                contrast = ro.r('list({} = 1)'.format(effect))\n",
    "                contest_result = ro.r('contest')(model, contrast, ddf=\"Satterthwaite\")\n",
    "                contest_df = pandas2ri.rpy2py(ro.r('as.data.frame')(contest_result))\n",
    "                p_values[effect] = contest_df['Pr(>F)'][0] if 'Pr(>F)' in contest_df.columns else np.nan\n",
    "            except Exception as e:\n",
    "                print(f\"Error computing p-value for {effect}: {str(e)}\")\n",
    "                p_values[effect] = np.nan\n",
    "        \n",
    "        # Map p-values to APA table\n",
    "        effect_map = {\n",
    "            'HC': 'Head Coil',\n",
    "            'MB': 'Multiband',\n",
    "            'ME': 'Multi-echo',\n",
    "            'HC:MB': 'Head Coil × Multiband',\n",
    "            'HC:ME': 'Head Coil × Multi-echo',\n",
    "            'MB:ME': 'Multiband × Multi-echo',\n",
    "            'HC:MB:ME': 'Head Coil × Multiband × Multi-echo'\n",
    "        }\n",
    "        for i, apa_row in enumerate(apa_data):\n",
    "            effect = apa_row['Effect']\n",
    "            for k, v in effect_map.items():\n",
    "                if v == effect:\n",
    "                    apa_row['p'] = p_values.get(k, np.nan)\n",
    "                    break\n",
    "    \n",
    "    # Create APA-style table\n",
    "    apa_table = pd.DataFrame(apa_data)\n",
    "    apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "    apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "    apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)  # Integer with NA support\n",
    "    apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "    apa_table['F'] = apa_table['F'].round(2)\n",
    "    apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "    apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "    \n",
    "    print(\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model (TSNR ~ HC * MB * ME + (1 | Subj)):\\n\")\n",
    "    print(apa_table.to_string(index=False))\n",
    "    \n",
    "    # Save APA table to CSV\n",
    "    apa_table.to_csv('tsnr_lme_anova_table.csv', index=False)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'apa_table': apa_table\n",
    "    }\n",
    "\n",
    "def analyze_tsnr_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Main function to perform TSNR analysis\n",
    "    \"\"\"\n",
    "    data, n_subjects_per_coil = load_and_preprocess_data(tsnr_path)\n",
    "    tsnr_processed = process_data(data, 'tsnrMedian')\n",
    "    \n",
    "    bar_plot = create_tsnr_bar_plots(tsnr_processed, n_subjects_per_coil, 'tsnrMedian')\n",
    "    emm_plot = create_emm_line_plots(data, n_subjects_per_coil)\n",
    "    statistical_results = run_statistical_analysis(data)\n",
    "    \n",
    "    return {\n",
    "        'data': data,\n",
    "        'bar_plot': bar_plot,\n",
    "        'emm_plot': emm_plot,\n",
    "        'statistical_results': statistical_results\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "results = analyze_tsnr_data('~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b78cd8-70c4-4c7a-a4ad-96110c76c7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8784b-b2ea-4e6c-b2d1-cd5a485a5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "# Activate automatic conversion between pandas and R dataframes\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "lme4 = importr('lme4')\n",
    "lmerTest = importr('lmerTest')\n",
    "emmeans = importr('emmeans')\n",
    "base = importr('base')\n",
    "stats = importr('stats')\n",
    "\n",
    "# Check lme4 and lmerTest versions\n",
    "print(\"lme4 version:\", ro.r('packageVersion(\"lme4\")')[0])\n",
    "print(\"lmerTest version:\", ro.r('packageVersion(\"lmerTest\")')[0])\n",
    "\n",
    "def load_and_preprocess_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess TSNR data\n",
    "    \"\"\"\n",
    "    tsnr_path = os.path.expanduser(tsnr_path)\n",
    "    \n",
    "    data = pd.read_csv(tsnr_path)\n",
    "    \n",
    "    column_mapping = {\n",
    "        'Subject': 'sub',\n",
    "        'ReceiveCoilName': 'coil',\n",
    "        'AcquisitionType': 'acq',\n",
    "        'tsnrMedian': 'tsnrMedian'\n",
    "    }\n",
    "    \n",
    "    missing_cols = [col for col in column_mapping.keys() if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}. Found columns: {list(data.columns)}\")\n",
    "    \n",
    "    data = data.rename(columns=column_mapping)\n",
    "    data = data[~data['sub'].str.contains('sp', na=False)]\n",
    "    \n",
    "    data['mb'] = data['acq'].str.extract(r'(mb\\d+)')[0]\n",
    "    data['me'] = data['acq'].str.extract(r'(me\\d+)')[0]\n",
    "    \n",
    "    categorical_cols = ['coil', 'mb', 'me']\n",
    "    for col in categorical_cols:\n",
    "        data[col] = pd.Categorical(data[col])\n",
    "    \n",
    "    # Compute n_subjects_per_coil after initial preprocessing\n",
    "    data_clean = data.dropna(subset=['mb', 'me', 'coil', 'tsnrMedian'])\n",
    "    n_subjects_per_coil = data_clean.groupby('coil', observed=True)['sub'].nunique().to_dict()\n",
    "    \n",
    "    return data, n_subjects_per_coil\n",
    "\n",
    "def process_data(data, value_column):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard error by multiband, multi-echo, and coil\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=['mb', 'me', 'coil', value_column])\n",
    "    \n",
    "    agg_data = data.groupby(['mb', 'me', 'coil'], observed=True).agg({\n",
    "        value_column: 'mean',\n",
    "        'sub': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    std_error = data.groupby(['mb', 'me', 'coil'], observed=True)[value_column].apply(\n",
    "        lambda x: x.std() / np.sqrt(len(x))\n",
    "    ).reset_index()\n",
    "    std_error.columns = ['mb', 'me', 'coil', 'se']\n",
    "    \n",
    "    result = pd.merge(agg_data, std_error, on=['mb', 'me', 'coil'])\n",
    "    result.columns = ['mb', 'me', 'coil', value_column, 'n_subjects', 'se']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_tsnr_bar_plots(data_processed, n_subjects_per_coil, img_type='tsnrMedian', save_files=True):\n",
    "    \"\"\"\n",
    "    Create bar plots for TSNR\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    coil_types = data_processed['coil'].unique()\n",
    "    fig, axes = plt.subplots(1, len(coil_types), figsize=(8 * len(coil_types), 8))\n",
    "    if len(coil_types) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    width = 0.4\n",
    "    x1 = [0, 1.2, 2.4]\n",
    "    x2 = [x + width for x in x1]\n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    mb_levels = ['mb1', 'mb3', 'mb6']\n",
    "    \n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for i, (coil, ax) in enumerate(zip(coil_types, axes)):\n",
    "        coil_data = data_processed[data_processed['coil'] == coil]\n",
    "        if coil_data.empty:\n",
    "            ax.set_title(f\"{coil}-Channel\\nn=0\", fontsize=48, fontweight='bold')\n",
    "            continue\n",
    "        \n",
    "        me1_data = coil_data[coil_data['me'] == 'me1']\n",
    "        me4_data = coil_data[coil_data['me'] == 'me4']\n",
    "        \n",
    "        me1_means = me1_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me1_errors = me1_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        me4_means = me4_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me4_errors = me4_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        \n",
    "        ax.bar(x1, me1_means, width, color=me_colors['me1'], label='me1', \n",
    "               yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me_colors['me4'], label='me4', \n",
    "               yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        y_values = list(me1_means) + list(me4_means)\n",
    "        y_errors = list(me1_errors) + list(me4_errors)\n",
    "        all_y_values.extend([v for v in y_values if v != 0])\n",
    "        all_y_errors.extend([e for e in y_errors if e != 0])\n",
    "        \n",
    "        ax.set_xticks([width/2, 1.2+width/2, 2.4+width/2])\n",
    "        ax.set_xticklabels(mb_levels, fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Median TSNR', fontsize=48)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        \n",
    "        y_max = max([v + e for v, e in zip(y_values, y_errors) if v != 0], default=0)\n",
    "        margin = y_max * 0.1\n",
    "        ax.set_ylim(0, y_max + margin)\n",
    "    \n",
    "    if len(coil_types) > 0:\n",
    "        axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                        loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    \n",
    "    if save_files:\n",
    "        plt.savefig('tsnr_bar_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plots(data, n_subjects_per_coil):\n",
    "    \"\"\"\n",
    "    Create line plots for estimated marginal means of TSNR with consistent y-axis across subplots\n",
    "    \"\"\"\n",
    "    # Prepare data for R\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Ensure MB and ME are factors with correct levels in R\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    ''')\n",
    "    r_df = ro.r('''\n",
    "    transform({}, MB = factor(MB, levels = levels_MB), ME = factor(ME, levels = levels_ME), HC = factor(HC))\n",
    "    '''.format(r_df.r_repr()))\n",
    "    \n",
    "    # Fit the model\n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=r_df)\n",
    "    \n",
    "    # Compute EMMs\n",
    "    emm = emmeans.emmeans(model, 'MB', by=ro.StrVector(['HC', 'ME']))\n",
    "    emm_r_df = ro.r('as.data.frame')(emm)\n",
    "    emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "    \n",
    "    # Map numeric indices to string labels\n",
    "    mb_map = {1: 'mb1', 2: 'mb3', 3: 'mb6'}\n",
    "    me_map = {1: 'me1', 2: 'me4'}\n",
    "    hc_levels = sorted(data['coil'].unique())\n",
    "    hc_map = {i + 1: hc for i, hc in enumerate(hc_levels)}\n",
    "    \n",
    "    emm_df['MB'] = emm_df['MB'].map(mb_map)\n",
    "    emm_df['ME'] = emm_df['ME'].map(me_map)\n",
    "    emm_df['HC'] = emm_df['HC'].map(hc_map)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    coil_types = emm_df['HC'].unique()\n",
    "    \n",
    "    # Collect all y-values and errors to determine consistent y-axis limits\n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for coil in coil_types:\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            if not me_data.empty:\n",
    "                y_values = me_data['emmean'].values\n",
    "                y_errors = me_data['SE'].values\n",
    "                all_y_values.extend(y_values)\n",
    "                all_y_errors.extend(y_errors)\n",
    "    \n",
    "    # Calculate global y-axis limits\n",
    "    if all_y_values:  # Ensure there are values to process\n",
    "        y_max = max([v + e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        y_min = min([v - e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        margin = (y_max - y_min) * 0.1  # Add 10% margin\n",
    "        y_limits = (max(0, y_min - margin), y_max + margin)  # Ensure y_min is not negative\n",
    "    else:\n",
    "        y_limits = (0, 1)  # Default in case of no data\n",
    "    \n",
    "    # Plot each subplot with consistent y-axis\n",
    "    for i, coil in enumerate(coil_types):\n",
    "        ax = axes[i]\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        \n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            me_data = me_data.sort_values('MB', key=lambda x: x.str.extract(r'mb(\\d+)')[0].astype(int))\n",
    "            ax.plot(me_data['MB'], me_data['emmean'], marker='o', color=me_colors[me], label=me, linewidth=5, markersize=15)\n",
    "            ax.errorbar(me_data['MB'], me_data['emmean'], yerr=me_data['SE'], fmt='none', color=me_colors[me], capsize=8, capthick=4, elinewidth=3)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Estimated\\nMarginal Mean TSNR', fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        ax.set_ylim(y_limits)  # Apply consistent y-axis limits\n",
    "    \n",
    "    axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                    loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    plt.savefig('tsnr_emm_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def run_statistical_analysis(data):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis for TSNR using R's lme4 and lmerTest, reporting APA-style results\n",
    "    \"\"\"\n",
    "    # Prepare data for R\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    print(\"Data summary:\")\n",
    "    print(data_r.groupby(['HC', 'MB', 'ME'], observed=True)['Subj'].nunique())\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Assign data frame to R global environment and set factors\n",
    "    ro.globalenv['data_r'] = r_df\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    data_r$MB <- factor(data_r$MB, levels = levels_MB)\n",
    "    data_r$ME <- factor(data_r$ME, levels = levels_ME)\n",
    "    data_r$HC <- factor(data_r$HC)\n",
    "    contrasts(data_r$MB) <- contr.sum(levels_MB)\n",
    "    contrasts(data_r$ME) <- contr.sum(levels_ME)\n",
    "    contrasts(data_r$HC) <- contr.sum(levels(data_r$HC))\n",
    "    ''')\n",
    "    \n",
    "    # Verify contrasts\n",
    "    print(\"MB contrasts:\")\n",
    "    print(ro.r('contrasts(data_r$MB)'))\n",
    "    print(\"ME contrasts:\")\n",
    "    print(ro.r('contrasts(data_r$ME)'))\n",
    "    print(\"HC contrasts:\")\n",
    "    print(ro.r('contrasts(data_r$HC)'))\n",
    "    \n",
    "    # Fit the LME model\n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=ro.r('data_r'))\n",
    "    \n",
    "    # Extract model summary, filtering out data structure\n",
    "    model_summary = ro.r('summary')(model)\n",
    "    summary_lines = ro.r('capture.output')(model_summary)\n",
    "    filtered_summary = [line for line in summary_lines \n",
    "                       if not line.startswith('   Data: structure(')]\n",
    "    print(\"Model summary:\")\n",
    "    print(\"\\n\".join(filtered_summary))\n",
    "    \n",
    "    # Try ANOVA table with Satterthwaite approximation\n",
    "    try:\n",
    "        anova_table = ro.r('lmerTest::anova')(model, ddf=\"Satterthwaite\")\n",
    "        anova_df = pandas2ri.rpy2py(ro.r('as.data.frame')(anova_table))\n",
    "        print(\"ANOVA table columns:\", anova_df.columns.tolist())\n",
    "    except Exception as e:\n",
    "        print(\"Error in ANOVA table extraction:\", str(e))\n",
    "        anova_df = None\n",
    "    \n",
    "    # Manually define numerator degrees of freedom\n",
    "    df_dict = {\n",
    "        'Head Coil': 1,  # HC: 2 levels - 1\n",
    "        'Multiband': 2,  # MB: 3 levels - 1\n",
    "        'Multi-echo': 1,  # ME: 2 levels - 1\n",
    "        'Head Coil × Multiband': 2,  # 1 * 2\n",
    "        'Head Coil × Multi-echo': 1,  # 1 * 1\n",
    "        'Multiband × Multi-echo': 2,  # 2 * 1\n",
    "        'Head Coil × Multiband × Multi-echo': 2  # 1 * 2 * 1\n",
    "    }\n",
    "    \n",
    "    # Approximate denominator degrees of freedom (n_obs - fixed effects - random effects)\n",
    "    n_obs = len(data_r)\n",
    "    n_fixed = sum(df_dict.values())  # Total fixed effect df\n",
    "    n_subj = data_r['Subj'].nunique()  # Random effect levels\n",
    "    den_df_approx = n_obs - n_fixed - n_subj  # Simplified approximation\n",
    "    \n",
    "    # Build APA table\n",
    "    apa_data = []\n",
    "    if anova_df is not None and 'F value' in anova_df.columns:\n",
    "        for effect in anova_df.index:\n",
    "            if effect in ['(Intercept)', 'Residuals']:  # Skip non-fixed effects\n",
    "                continue\n",
    "            effect_name = {\n",
    "                'HC': 'Head Coil',\n",
    "                'MB': 'Multiband',\n",
    "                'ME': 'Multi-echo',\n",
    "                'HC:MB': 'Head Coil × Multiband',\n",
    "                'HC:ME': 'Head Coil × Multi-echo',\n",
    "                'MB:ME': 'Multiband × Multi-echo',\n",
    "                'HC:MB:ME': 'Head Coil × Multiband × Multi-echo'\n",
    "            }.get(effect, effect)\n",
    "            apa_data.append({\n",
    "                'Effect': effect_name,\n",
    "                'Sum Sq': anova_df.loc[effect, 'Sum Sq'] if 'Sum Sq' in anova_df.columns else np.nan,\n",
    "                'Mean Sq': anova_df.loc[effect, 'Mean Sq'] if 'Mean Sq' in anova_df.columns else np.nan,\n",
    "                'Num df': df_dict.get(effect_name, np.nan),  # Use manual df\n",
    "                'Den df': anova_df.loc[effect, 'DenDF'] if 'DenDF' in anova_df.columns else den_df_approx,\n",
    "                'F': anova_df.loc[effect, 'F value'] if 'F value' in anova_df.columns else np.nan,\n",
    "                'p': anova_df.loc[effect, 'Pr(>F)'] if 'Pr(>F)' in anova_df.columns else np.nan,\n",
    "                'Partial η²': np.nan  # Computed below\n",
    "            })\n",
    "    else:\n",
    "        # Fallback: Use manual df and placeholder values\n",
    "        effects = ['Head Coil', 'Multiband', 'Multi-echo', 'Head Coil × Multiband', \n",
    "                   'Head Coil × Multi-echo', 'Multiband × Multi-echo', \n",
    "                   'Head Coil × Multiband × Multi-echo']\n",
    "        for effect in effects:\n",
    "            apa_data.append({\n",
    "                'Effect': effect,\n",
    "                'Sum Sq': np.nan,\n",
    "                'Mean Sq': np.nan,\n",
    "                'Num df': df_dict.get(effect, np.nan),\n",
    "                'Den df': den_df_approx,\n",
    "                'F': np.nan,\n",
    "                'p': np.nan,\n",
    "                'Partial η²': np.nan\n",
    "            })\n",
    "    \n",
    "    # Compute partial eta-squared\n",
    "    residual_var = ro.r('sigma')(model)**2\n",
    "    if anova_df is not None and 'Sum Sq' in anova_df.columns:\n",
    "        ss_effect = anova_df['Sum Sq']\n",
    "        ss_residual = residual_var * (n_obs - n_fixed - 1)  # Approx residual SS\n",
    "        partial_eta2 = ss_effect / (ss_effect + ss_residual)\n",
    "    else:\n",
    "        partial_eta2 = pd.Series([np.nan] * len(apa_data))\n",
    "    \n",
    "    # Update partial eta-squared\n",
    "    for i, effect in enumerate([d['Effect'] for d in apa_data]):\n",
    "        apa_data[i]['Partial η²'] = partial_eta2.iloc[i] if i < len(partial_eta2) else np.nan\n",
    "    \n",
    "    # Extract p-values using emmeans::test if anova fails to provide them\n",
    "    if anova_df is None or 'Pr(>F)' not in anova_df.columns:\n",
    "        p_values = {}\n",
    "        effects = ['HC', 'MB', 'ME', 'HC:MB', 'HC:ME', 'MB:ME', 'HC:MB:ME']\n",
    "        for effect in effects:\n",
    "            try:\n",
    "                # Use emmeans to compute p-values\n",
    "                if ':' in effect:\n",
    "                    # For interactions, split and create pairwise contrasts\n",
    "                    factors = effect.split(':')\n",
    "                    specs = ro.StrVector(factors)\n",
    "                    emm = emmeans.emmeans(model, specs)\n",
    "                    test_result = ro.r('test')(emm, adjust=\"none\")\n",
    "                    test_df = pandas2ri.rpy2py(ro.r('as.data.frame')(test_result))\n",
    "                    p_values[effect] = test_df['p.value'].iloc[0] if 'p.value' in test_df.columns else np.nan\n",
    "                else:\n",
    "                    # For main effects\n",
    "                    emm = emmeans.emmeans(model, effect)\n",
    "                    test_result = ro.r('test')(emm, adjust=\"none\")\n",
    "                    test_df = pandas2ri.rpy2py(ro.r('as.data.frame')(test_result))\n",
    "                    p_values[effect] = test_df['p.value'].iloc[0] if 'p.value' in test_df.columns else np.nan\n",
    "            except Exception as e:\n",
    "                print(f\"Error computing p-value for {effect}: {str(e)}\")\n",
    "                p_values[effect] = np.nan\n",
    "        \n",
    "        # Map p-values to APA table\n",
    "        effect_map = {\n",
    "            'HC': 'Head Coil',\n",
    "            'MB': 'Multiband',\n",
    "            'ME': 'Multi-echo',\n",
    "            'HC:MB': 'Head Coil × Multiband',\n",
    "            'HC:ME': 'Head Coil × Multi-echo',\n",
    "            'MB:ME': 'Multiband × Multi-echo',\n",
    "            'HC:MB:ME': 'Head Coil × Multiband × Multi-echo'\n",
    "        }\n",
    "        for i, apa_row in enumerate(apa_data):\n",
    "            effect = apa_row['Effect']\n",
    "            for k, v in effect_map.items():\n",
    "                if v == effect:\n",
    "                    apa_row['p'] = p_values.get(k, np.nan)\n",
    "                    break\n",
    "    \n",
    "    # Create APA-style table\n",
    "    apa_table = pd.DataFrame(apa_data)\n",
    "    apa_table['Sum Sq'] = apa_table['Sum Sq'].round(2)\n",
    "    apa_table['Mean Sq'] = apa_table['Mean Sq'].round(2)\n",
    "    apa_table['Num df'] = apa_table['Num df'].astype('Int64').fillna(pd.NA)  # Integer with NA support\n",
    "    apa_table['Den df'] = apa_table['Den df'].round(2)\n",
    "    apa_table['F'] = apa_table['F'].round(2)\n",
    "    apa_table['Partial η²'] = apa_table['Partial η²'].round(3)\n",
    "    apa_table['p'] = apa_table['p'].apply(lambda x: '< .001' if pd.notna(x) and x < 0.001 else f'{x:.3f}' if pd.notna(x) else 'N/A')\n",
    "    \n",
    "    print(\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model (TSNR ~ HC * MB * ME + (1 | Subj)):\\n\")\n",
    "    print(apa_table.to_string(index=False))\n",
    "    \n",
    "    # Save APA table to CSV\n",
    "    apa_table.to_csv('tsnr_lme_anova_table.csv', index=False)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'apa_table': apa_table\n",
    "    }\n",
    "\n",
    "def analyze_tsnr_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Main function to perform TSNR analysis\n",
    "    \"\"\"\n",
    "    data, n_subjects_per_coil = load_and_preprocess_data(tsnr_path)\n",
    "    tsnr_processed = process_data(data, 'tsnrMedian')\n",
    "    \n",
    "    bar_plot = create_tsnr_bar_plots(tsnr_processed, n_subjects_per_coil, 'tsnrMedian')\n",
    "    emm_plot = create_emm_line_plots(data, n_subjects_per_coil)\n",
    "    statistical_results = run_statistical_analysis(data)\n",
    "    \n",
    "    return {\n",
    "        'data': data,\n",
    "        'bar_plot': bar_plot,\n",
    "        'emm_plot': emm_plot,\n",
    "        'statistical_results': statistical_results\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "results = analyze_tsnr_data('~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643c3e4-c97d-4bc5-8b2b-e498951a4bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c8cdf-ead2-44c4-9133-0ee2956fd7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0591e-69f4-4118-8c80-9d84889bd186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b2420-ec9f-4bc2-90c5-a9a200dbbe19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d289d27-4525-4514-bbe1-41930023396e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d84bb-fc60-40ae-96f1-14a6f1c67d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b2a69-7d7d-4f94-aa1a-120f1ca52a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e90dc-2f90-4771-9900-dd32ba012cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740b031-33d3-4ad0-a1b0-7dc0d3342a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fffe94-fd1a-402f-877e-12b1cf3e5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f7c0e-d965-468e-9345-0b4336139137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf329ea-27ad-4d86-830f-3689e86ff4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6adde79-9f56-46c2-970c-285bf0105684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8ecfa-6d05-4c43-84b3-6897f0d37c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a5b4c-90aa-442a-ba32-002b12105777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ce900-f691-4e0e-a212-7e1357f55580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c05b18-7178-4111-b3ed-53505895c5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af639a18-9c82-4c72-858d-c6b55e65b481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fad0c5-09a2-4f8e-b576-332680b7984d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7f41a-aa5a-478a-98cd-c9cd9ec6fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "# Activate automatic conversion between pandas and R dataframes\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "lme4 = importr('lme4')\n",
    "lmerTest = importr('lmerTest')\n",
    "emmeans = importr('emmeans')\n",
    "base = importr('base')\n",
    "stats = importr('stats')  # Added for anova table extraction\n",
    "\n",
    "def load_and_preprocess_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess TSNR data\n",
    "    \"\"\"\n",
    "    tsnr_path = os.path.expanduser(tsnr_path)\n",
    "    \n",
    "    data = pd.read_csv(tsnr_path)\n",
    "    \n",
    "    column_mapping = {\n",
    "        'Subject': 'sub',\n",
    "        'ReceiveCoilName': 'coil',\n",
    "        'AcquisitionType': 'acq',\n",
    "        'tsnrMedian': 'tsnrMedian'\n",
    "    }\n",
    "    \n",
    "    missing_cols = [col for col in column_mapping.keys() if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}. Found columns: {list(data.columns)}\")\n",
    "    \n",
    "    data = data.rename(columns=column_mapping)\n",
    "    data = data[~data['sub'].str.contains('sp', na=False)]\n",
    "    \n",
    "    data['mb'] = data['acq'].str.extract(r'(mb\\d+)')[0]\n",
    "    data['me'] = data['acq'].str.extract(r'(me\\d+)')[0]\n",
    "    \n",
    "    categorical_cols = ['coil', 'mb', 'me']\n",
    "    for col in categorical_cols:\n",
    "        data[col] = pd.Categorical(data[col])\n",
    "    \n",
    "    # Compute n_subjects_per_coil after initial preprocessing\n",
    "    data_clean = data.dropna(subset=['mb', 'me', 'coil', 'tsnrMedian'])\n",
    "    n_subjects_per_coil = data_clean.groupby('coil', observed=True)['sub'].nunique().to_dict()\n",
    "    \n",
    "    return data, n_subjects_per_coil\n",
    "\n",
    "def process_data(data, value_column):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard error by multiband, multi-echo, and coil\n",
    "    \"\"\"\n",
    "    data = data.dropna(subset=['mb', 'me', 'coil', value_column])\n",
    "    \n",
    "    agg_data = data.groupby(['mb', 'me', 'coil'], observed=True).agg({\n",
    "        value_column: 'mean',\n",
    "        'sub': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    std_error = data.groupby(['mb', 'me', 'coil'], observed=True)[value_column].apply(\n",
    "        lambda x: x.std() / np.sqrt(len(x))\n",
    "    ).reset_index()\n",
    "    std_error.columns = ['mb', 'me', 'coil', 'se']\n",
    "    \n",
    "    result = pd.merge(agg_data, std_error, on=['mb', 'me', 'coil'])\n",
    "    result.columns = ['mb', 'me', 'coil', value_column, 'n_subjects', 'se']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_tsnr_bar_plots(data_processed, n_subjects_per_coil, img_type='tsnrMedian', save_files=True):\n",
    "    \"\"\"\n",
    "    Create bar plots for TSNR\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    coil_types = data_processed['coil'].unique()\n",
    "    fig, axes = plt.subplots(1, len(coil_types), figsize=(8 * len(coil_types), 8))\n",
    "    if len(coil_types) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    width = 0.4\n",
    "    x1 = [0, 1.2, 2.4]\n",
    "    x2 = [x + width for x in x1]\n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    mb_levels = ['mb1', 'mb3', 'mb6']\n",
    "    \n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for i, (coil, ax) in enumerate(zip(coil_types, axes)):\n",
    "        coil_data = data_processed[data_processed['coil'] == coil]\n",
    "        if coil_data.empty:\n",
    "            ax.set_title(f\"{coil}-Channel\\nn=0\", fontsize=48, fontweight='bold')\n",
    "            continue\n",
    "        \n",
    "        me1_data = coil_data[coil_data['me'] == 'me1']\n",
    "        me4_data = coil_data[coil_data['me'] == 'me4']\n",
    "        \n",
    "        me1_means = me1_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me1_errors = me1_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        me4_means = me4_data.set_index('mb')[img_type].reindex(mb_levels).fillna(0)\n",
    "        me4_errors = me4_data.set_index('mb')['se'].reindex(mb_levels).fillna(0)\n",
    "        \n",
    "        ax.bar(x1, me1_means, width, color=me_colors['me1'], label='me1', \n",
    "               yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me_colors['me4'], label='me4', \n",
    "               yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        y_values = list(me1_means) + list(me4_means)\n",
    "        y_errors = list(me1_errors) + list(me4_errors)\n",
    "        all_y_values.extend([v for v in y_values if v != 0])\n",
    "        all_y_errors.extend([e for e in y_errors if e != 0])\n",
    "        \n",
    "        ax.set_xticks([width/2, 1.2+width/2, 2.4+width/2])\n",
    "        ax.set_xticklabels(mb_levels, fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Median TSNR', fontsize=48)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        \n",
    "        y_max = max([v + e for v, e in zip(y_values, y_errors) if v != 0], default=0)\n",
    "        margin = y_max * 0.1\n",
    "        ax.set_ylim(0, y_max + margin)\n",
    "    \n",
    "    if len(coil_types) > 0:\n",
    "        axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                        loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    \n",
    "    if save_files:\n",
    "        plt.savefig('tsnr_bar_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plots(data, n_subjects_per_coil):\n",
    "    \"\"\"\n",
    "    Create line plots for estimated marginal means of TSNR with consistent y-axis across subplots\n",
    "    \"\"\"\n",
    "    # Prepare data for R\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Ensure MB and ME are factors with correct levels in R\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    ''')\n",
    "    r_df = ro.r('''\n",
    "    transform({}, MB = factor(MB, levels = levels_MB), ME = factor(ME, levels = levels_ME), HC = factor(HC))\n",
    "    '''.format(r_df.r_repr()))\n",
    "    \n",
    "    # Fit the model\n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=r_df)\n",
    "    \n",
    "    # Compute EMMs\n",
    "    emm = emmeans.emmeans(model, 'MB', by=ro.StrVector(['HC', 'ME']))\n",
    "    emm_r_df = ro.r('as.data.frame')(emm)\n",
    "    emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "    \n",
    "    # Map numeric indices to string labels\n",
    "    mb_map = {1: 'mb1', 2: 'mb3', 3: 'mb6'}\n",
    "    me_map = {1: 'me1', 2: 'me4'}\n",
    "    hc_levels = sorted(data['coil'].unique())\n",
    "    hc_map = {i + 1: hc for i, hc in enumerate(hc_levels)}\n",
    "    \n",
    "    emm_df['MB'] = emm_df['MB'].map(mb_map)\n",
    "    emm_df['ME'] = emm_df['ME'].map(me_map)\n",
    "    emm_df['HC'] = emm_df['HC'].map(hc_map)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    coil_types = emm_df['HC'].unique()\n",
    "    \n",
    "    # Collect all y-values and errors to determine consistent y-axis limits\n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for coil in coil_types:\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            if not me_data.empty:\n",
    "                y_values = me_data['emmean'].values\n",
    "                y_errors = me_data['SE'].values\n",
    "                all_y_values.extend(y_values)\n",
    "                all_y_errors.extend(y_errors)\n",
    "    \n",
    "    # Calculate global y-axis limits\n",
    "    if all_y_values:  # Ensure there are values to process\n",
    "        y_max = max([v + e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        y_min = min([v - e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        margin = (y_max - y_min) * 0.1  # Add 10% margin\n",
    "        y_limits = (max(0, y_min - margin), y_max + margin)  # Ensure y_min is not negative\n",
    "    else:\n",
    "        y_limits = (0, 1)  # Default in case of no data\n",
    "    \n",
    "    # Plot each subplot with consistent y-axis\n",
    "    for i, coil in enumerate(coil_types):\n",
    "        ax = axes[i]\n",
    "        coil_data = emm_df[emm_df['HC'] == coil]\n",
    "        \n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['ME'] == me]\n",
    "            me_data = me_data.sort_values('MB', key=lambda x: x.str.extract(r'mb(\\d+)')[0].astype(int))\n",
    "            ax.plot(me_data['MB'], me_data['emmean'], marker='o', color=me_colors[me], label=me, linewidth=5, markersize=15)\n",
    "            ax.errorbar(me_data['MB'], me_data['emmean'], yerr=me_data['SE'], fmt='none', color=me_colors[me], capsize=8, capthick=4, elinewidth=3)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Estimated\\nMarginal Mean TSNR', fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        ax.set_ylim(y_limits)  # Apply consistent y-axis limits\n",
    "    \n",
    "    axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                    loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    plt.savefig('tsnr_emm_plot.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def run_statistical_analysis(data):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis for TSNR using R's lme4 and lmerTest, reporting APA-style results\n",
    "    \"\"\"\n",
    "    # Prepare data for R\n",
    "    data_r = data.rename(columns={'sub': 'Subj', 'coil': 'HC', 'mb': 'MB', 'me': 'ME', \n",
    "                                  'tsnrMedian': 'TSNR'})\n",
    "    data_r = data_r.dropna(subset=['TSNR', 'MB', 'ME', 'HC', 'Subj'])\n",
    "    \n",
    "    data_r['Subj'] = data_r['Subj'].astype(str)\n",
    "    data_r['MB'] = data_r['MB'].astype(str)\n",
    "    data_r['ME'] = data_r['ME'].astype(str)\n",
    "    data_r['HC'] = data_r['HC'].astype(str)\n",
    "    \n",
    "    r_df = pandas2ri.py2rpy(data_r)\n",
    "    \n",
    "    # Ensure MB and ME are factors with correct levels in R\n",
    "    ro.r('''\n",
    "    levels_MB <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_ME <- c(\"me1\", \"me4\")\n",
    "    ''')\n",
    "    r_df = ro.r('''\n",
    "    transform({}, MB = factor(MB, levels = levels_MB), ME = factor(ME, levels = levels_ME), HC = factor(HC))\n",
    "    '''.format(r_df.r_repr()))\n",
    "    \n",
    "    # Fit the LME model\n",
    "    formula = Formula('TSNR ~ HC * MB * ME + (1 | Subj)')\n",
    "    model = lme4.lmer(formula, data=r_df)\n",
    "    \n",
    "    # Extract ANOVA table with F-statistics and p-values\n",
    "    anova_table = ro.r('anova')(model, ddf='Satterthwaite')\n",
    "    anova_df = pandas2ri.rpy2py(ro.r('as.data.frame')(anova_table))\n",
    "    \n",
    "    # Compute partial eta-squared for effect sizes\n",
    "    # Partial eta-squared = SS_effect / (SS_effect + SS_residual)\n",
    "    # Residual SS is approximated from model deviance or variance components\n",
    "    model_summary = ro.r('summary')(model)\n",
    "    # Extract variance components (approximate residual variance)\n",
    "    varcor = ro.r('VarCorr')(model)\n",
    "    residual_var = ro.r('sigma')(model)**2  # Residual variance\n",
    "    # Sum of squares from ANOVA table\n",
    "    ss_effect = anova_df['Sum Sq']\n",
    "    ss_total = ss_effect + residual_var * anova_df['Den Df']  # Approximate total SS\n",
    "    partial_eta2 = ss_effect / ss_total\n",
    "    \n",
    "    # Format APA-style table\n",
    "    apa_table = pd.DataFrame({\n",
    "        'Effect': anova_df.index,\n",
    "        'Sum Sq': anova_df['Sum Sq'].round(2),\n",
    "        'Mean Sq': anova_df['Mean Sq'].round(2),\n",
    "        'Num df': anova_df['NumDF'].astype(int),\n",
    "        'Den df': anova_df['DenDF'].round(2),\n",
    "        'F': anova_df['F value'].round(2),\n",
    "        'p': anova_df['Pr(>F)'].apply(lambda x: '< .001' if x < 0.001 else f'{x:.3f}'),\n",
    "        'Partial η²': partial_eta2.round(3)\n",
    "    })\n",
    "    \n",
    "    # Adjust effect names for clarity\n",
    "    apa_table['Effect'] = apa_table['Effect'].replace({\n",
    "        'HC': 'Head Coil',\n",
    "        'MB': 'Multiband',\n",
    "        'ME': 'Multi-echo',\n",
    "        'HC:MB': 'Head Coil × Multiband',\n",
    "        'HC:ME': 'Head Coil × Multi-echo',\n",
    "        'MB:ME': 'Multiband × Multi-echo',\n",
    "        'HC:MB:ME': 'Head Coil × Multiband × Multi-echo'\n",
    "    })\n",
    "    \n",
    "    print(\"\\nAPA-Style ANOVA Table for Linear Mixed Effects Model (TSNR ~ HC * MB * ME + (1 | Subj)):\\n\")\n",
    "    print(apa_table.to_string(index=False))\n",
    "    \n",
    "    # Save APA table to CSV for manuscript inclusion\n",
    "    apa_table.to_csv('tsnr_lme_anova_table.csv', index=False)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'apa_table': apa_table\n",
    "    }\n",
    "\n",
    "def analyze_tsnr_data(tsnr_path):\n",
    "    \"\"\"\n",
    "    Main function to perform TSNR analysis\n",
    "    \"\"\"\n",
    "    data, n_subjects_per_coil = load_and_preprocess_data(tsnr_path)\n",
    "    tsnr_processed = process_data(data, 'tsnrMedian')\n",
    "    \n",
    "    bar_plot = create_tsnr_bar_plots(tsnr_processed, n_subjects_per_coil, 'tsnrMedian')\n",
    "    emm_plot = create_emm_line_plots(data, n_subjects_per_coil)\n",
    "    statistical_results = run_statistical_analysis(data)\n",
    "    \n",
    "    return {\n",
    "        'data': data,\n",
    "        'bar_plot': bar_plot,\n",
    "        'emm_plot': emm_plot,\n",
    "        'statistical_results': statistical_results\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "results = analyze_tsnr_data('~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba41a80-d19d-4637-966f-ceecb6510642",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_multiecho_data(\n",
    "    '~/Documents/GitHub/multiecho-pilot/code/combined_tsnr_coil_output.csv', \n",
    "    '~/Documents/GitHub/multiecho-pilot/smoothness-all.csv' # use smoothness-all-zero.csv for pre-5mm smoothed data (panel A)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345b551-a43f-4a18-b7a3-4d80fdede530",
   "metadata": {},
   "source": [
    "# Figs 5-7. Analysis of Multiecho fMRI Data with Mixed-Effects Modeling\n",
    "\n",
    "This code chunk defines a set of Python functions to process, analyze, and visualize multiecho fMRI data extracted from text files, focusing on the effects of headcoil type (20 vs. 64 channels), multiband (MB) factor (mb1, mb3, mb6), and multi-echo (ME) settings (me1, me4) on a specified imaging metric (e.g., beta values). The analysis mirrors a prior TSNR/Smoothness study, ensuring consistency in statistical methodology.\n",
    "\n",
    "### Key Components\n",
    "1. **Data Extraction and Preparation**:\n",
    "   - `extract_file_data`: Parses text files in a specified directory (e.g., `~/Documents/GitHub/multiecho-pilot/derivatives/extractions`) matching a regex pattern, extracting metric values for each subject and acquisition type (e.g., `mb1me1`, `mb3me4`).\n",
    "   - `create_dataframe`: Builds a wide-format DataFrame with subjects, headcoil assignments (20 or 64, based on a predefined list), and acquisition-specific metric values.\n",
    "\n",
    "2. **Visualization**:\n",
    "   - `prepare_plot_data`: Computes means and standard errors of the metric for each acquisition, split by headcoil.\n",
    "   - `create_bar_plots`: Generates side-by-side bar plots (20-channel vs. 64-channel) showing the metric across MB factors, with ME settings differentiated by color (blue for me1, orange for me4).\n",
    "\n",
    "3. **Statistical Analysis**:\n",
    "   - `process_mask`: Orchestrates the workflow for a given mask (e.g., `VSconstrained`):\n",
    "     - Reshapes data into long format with `mb` (multiband) and `me` (multi-echo) as separate columns.\n",
    "     - Treats `mb` and `me` as ordered categorical variables (`mb1 < mb3 < mb6`, `me1 < me4`) to enable linear (`.L`) and quadratic (`.Q`) contrasts.\n",
    "     - Fits a linear mixed-effects model: `<metric> ~ headcoil * mb * me + (1 | subject)`, capturing main effects and interactions with a random intercept for subjects.\n",
    "     - Performs pairwise Tukey HSD tests for `mb` levels, averaged over `headcoil` and `me`, to assess differences (e.g., mb1 vs. mb3).\n",
    "   - Outputs include model summaries (fixed/random effects) and pairwise comparison results.\n",
    "\n",
    "4. **Execution**:\n",
    "   - `run_analysis`: Runs the full pipeline across multiple masks, with options to save DataFrames and plots as CSV and PNG files.\n",
    "\n",
    "### Inputs\n",
    "- `base_dir`: Directory containing fMRI data files (default: `~/Documents/GitHub/multiecho-pilot/derivatives/extractions`).\n",
    "- `type_value`: Analysis type (e.g., `act` for activation).\n",
    "- `img_value`: Metric to analyze (e.g., `beta`).\n",
    "- `mask_values`: List of ROIs (e.g., `[\"VSconstrained\", \"rFFA\"]`).\n",
    "- `denoise_value`: Denoising method (e.g., `smooth`).\n",
    "- `headcoil_64_subjects`: List of subject IDs using the 64-channel headcoil.\n",
    "\n",
    "### Outputs\n",
    "- **DataFrames**: Saved as CSV files (e.g., `multiecho_data_act_beta_VSconstrained_smooth_RewgtPun.csv`).\n",
    "- **Plots**: Bar plots saved as PNG files (e.g., `multiecho_plots_act_beta_VSconstrained_smooth_RewgtPun.png`).\n",
    "- **Statistical Results**: Printed summaries of mixed-effects models and pairwise comparisons for each mask.\n",
    "\n",
    "### Notes\n",
    "- The code assumes text files contain a single float value per file and skips files with `sp` in the subject ID.\n",
    "- Missing data is handled by dropping NaNs before modeling, with diagnostics printed for debugging.\n",
    "- Plot aesthetics (e.g., font size, colors) are set via `initialize_plotting_engine` for consistency.\n",
    "\n",
    "This chunk establishes a reproducible framework for comparing acquisition parameters across ROIs, aligning statistical rigor with the TSNR/Smoothness analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68dccce-6b5b-44e6-8f90-cb86b15f002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for generating plots and statistical analysis\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Activate pandas-R conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "base = importr('base')\n",
    "lme4 = importr('lme4')\n",
    "emmeans = importr('emmeans')\n",
    "ggplot2 = importr('ggplot2')\n",
    "\n",
    "def initialize_plotting_engine():\n",
    "    \"\"\"Initialize the plotting environment with required settings\"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "\n",
    "def determine_contrast(mask_value):\n",
    "    \"\"\"Determine contrast based on mask value\"\"\"\n",
    "    if mask_value in [\"VSconstrained\", \"VMPFC\"]:\n",
    "        return \"Rew>Pun\"\n",
    "    elif mask_value == \"rFFA\":\n",
    "        return \"Str>Com\"\n",
    "    elif mask_value in [\"bilateralMotor\", \"bilateralCerebellum\"]:\n",
    "        return \"Avg (L>R, R>L)\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in headcoil_64_subjects else 20)\n",
    "    df['headcoil'] = df['headcoil'].astype(str)  # Convert headcoil to categorical\n",
    "    column_order = ['subject', 'headcoil'] + acq_params\n",
    "    df = df[column_order]\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_plot_data(df):\n",
    "    \"\"\"Prepare data for plotting by calculating means and errors by headcoil type\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    df_20 = df[df['headcoil'] == '20']\n",
    "    df_64 = df[df['headcoil'] == '64']\n",
    "    results = {}\n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        means = {acq: hc_df[acq].mean() for acq in acq_params}  # NaN-safe by default\n",
    "        errors = {acq: hc_df[acq].sem() for acq in acq_params}  # NaN-safe by default\n",
    "        results[hc_name] = {'means': means, 'errors': errors, 'count': len(hc_df)}\n",
    "    return results\n",
    "\n",
    "def create_bar_plots(plot_data, mask_value, contrast, is_first=False, is_last=False):\n",
    "    \"\"\"Create bar plots for the given data with consistent y-axis limits within each ROI\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    width = 0.4\n",
    "    x1 = [0, 1.2, 2.4]\n",
    "    x2 = [0+width, 1.2+width, 2.4+width]\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        all_y_values.extend([v for v in y_values if not np.isnan(v)])  # Filter NaNs\n",
    "        all_y_errors.extend([e for e in y_errors if not np.isnan(e)])  # Filter NaNs\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f\"{mask_value}\", fontsize=36)\n",
    "        if is_first:\n",
    "            ax.set_title(f\"{title}\\nn={count}\", fontsize=56, fontweight='bold')\n",
    "        ax.set_xticks([width/2, 1.2+width/2, 2.4+width/2])\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=56)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=56)\n",
    "        ax.set_xlabel(\"Multiband Factor\", fontsize=36)\n",
    "        if is_first and i == 1:\n",
    "            legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=112)\n",
    "            legend.get_title().set_fontsize(112)\n",
    "            ax.legend(loc='upper right')\n",
    "    \n",
    "    if all_y_values and all_y_errors:\n",
    "        y_min = min([v - e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        y_max = max([v + e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax1.set_ylim(y_min - margin, y_max + margin)\n",
    "        ax2.set_ylim(y_min - margin, y_max + margin)\n",
    "    else:\n",
    "        print(f\"Warning: No valid data for plotting y-limits in {mask_value}\")\n",
    "    \n",
    "    if is_last:\n",
    "        fig.text(0.5, -0.05, 'Multiband Factor', ha='center', fontsize=56)\n",
    "    plt.tight_layout(pad=1.0)\n",
    "    if is_last:\n",
    "        plt.subplots_adjust(bottom=0.2)\n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plots(emm_df, n_subjects_per_coil, mask_value, contrast, output_dir, type_value, img_value, denoise_value):\n",
    "    \"\"\"Create line plots for estimated marginal means with consistent y-axis limits and save as PNG\"\"\"\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Define colors for me1 and me4\n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    coil_types = sorted(emm_df['headcoil'].unique())  # Ensure order: '20', '64'\n",
    "    \n",
    "    # Plot data for each coil in its respective subplot\n",
    "    for i, coil in enumerate(coil_types):\n",
    "        ax = axes[i]  # Assign subplot based on coil index\n",
    "        coil_data = emm_df[emm_df['headcoil'] == coil]\n",
    "        \n",
    "        # Plot for each me value within the current coil\n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['me'] == me]\n",
    "            if not me_data.empty:\n",
    "                me_data = me_data.sort_values('mb')\n",
    "                ax.plot(me_data['mb'], me_data['emmean'], marker='o', color=me_colors[me], linewidth=5, markersize=15)\n",
    "                ax.errorbar(me_data['mb'], me_data['emmean'], yerr=me_data['SE'], fmt='none', color=me_colors[me], capsize=8, capthick=4, elinewidth=3)\n",
    "        \n",
    "        # Set title and labels\n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=56, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f\"{mask_value} EMMs\", fontsize=56)\n",
    "        ax.set_xticks(['mb1', 'mb3', 'mb6'])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=56)\n",
    "        ax.set_xlabel(\"Multiband Factor\", fontsize=36)\n",
    "        \n",
    "        # Set y-limits based on this subplot's data\n",
    "        y_values = []\n",
    "        y_errors = []\n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['me'] == me]\n",
    "            if not me_data.empty:\n",
    "                y_values.extend(me_data['emmean'].values)\n",
    "                y_errors.extend(me_data['SE'].values)\n",
    "        if y_values:\n",
    "            y_max = max([v + e for v, e in zip(y_values, y_errors)])\n",
    "            y_min = min([v - e for v, e in zip(y_values, y_errors)])\n",
    "            margin = (y_max - y_min) * 0.1\n",
    "            ax.set_ylim(max(0, y_min - margin), y_max + margin)\n",
    "        else:\n",
    "            ax.set_ylim(0, 1)  # Default if no data\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.supxlabel('Multiband Factor', fontsize=56, y=-0.05)\n",
    "    if output_dir:\n",
    "        plot_file = os.path.join(output_dir, f\"emm_plot_{type_value}_{img_value}_{mask_value}_{denoise_value}_{contrast.replace('>', 'gt').replace(' ', '_').replace(',', '')}.png\")\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"EMM plot saved as '{plot_file}'\")\n",
    "    plt.close()  # Close the figure to prevent rendering in the notebook\n",
    "    return fig\n",
    "\n",
    "def process_mask(base_dir, type_value, img_value, mask_value, denoise_value, headcoil_64_subjects, \n",
    "                 is_first=False, is_last=False, save_files=True, output_dir=\"../derivatives/plots\"):\n",
    "    \"\"\"Process a single mask, create and save both bar and EMM plots, and run statistical analysis\"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    contrast = determine_contrast(mask_value)\n",
    "    print(f\"\\nProcessing files with parameters: type={type_value}, img={img_value}, mask={mask_value}, denoise={denoise_value}\")\n",
    "    print(f\"Using contrast: {contrast}\")\n",
    "    \n",
    "    # Extract data\n",
    "    data_by_subject = extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value)\n",
    "    if not data_by_subject:\n",
    "        print(f\"No matching files found for mask: {mask_value}\")\n",
    "        return None\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject, headcoil_64_subjects)\n",
    "    \n",
    "    if save_files:\n",
    "        output_file = os.path.join(output_dir, f\"multiecho_data_{type_value}_{img_value}_{mask_value}_{denoise_value}_{contrast.replace('>', 'gt').replace(' ', '_').replace(',', '')}.csv\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get('64', 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get('20', 0)}\")\n",
    "    print(f\"Missing values per column:\\n{df.isnull().sum()}\")  # Added diagnostic\n",
    "    \n",
    "    # Reshape data for statistical analysis\n",
    "    df_long = pd.melt(\n",
    "        df, \n",
    "        id_vars=['subject', 'headcoil'], \n",
    "        value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "        var_name='acq', \n",
    "        value_name=img_value\n",
    "    )\n",
    "    df_long['mb'] = df_long['acq'].str[:3]  # Extract 'mb1', 'mb3', 'mb6'\n",
    "    df_long['me'] = df_long['acq'].str[3:]  # Extract 'me1', 'me4'\n",
    "    df_long = df_long.drop(columns=['acq'])\n",
    "    \n",
    "    # Set ordered factors for mb and me (like MB.L, MB.Q, ME.L)\n",
    "    df_long['mb'] = pd.Categorical(df_long['mb'], categories=['mb1', 'mb3', 'mb6'], ordered=True)\n",
    "    df_long['me'] = pd.Categorical(df_long['me'], categories=['me1', 'me4'], ordered=True)\n",
    "    df_long['headcoil'] = df_long['headcoil'].astype(str)  # Ensure headcoil is categorical\n",
    "    \n",
    "    # Compute n_subjects_per_coil for EMM plot titles\n",
    "    n_subjects_per_coil = df.groupby('headcoil')['subject'].nunique().to_dict()\n",
    "    \n",
    "    # Run Python-based linear mixed-effects model with NaN handling\n",
    "    print(f\"\\nRunning statistical analysis for {mask_value} ({img_value})...\")\n",
    "    df_long_clean = df_long.dropna(subset=[img_value])  # Drop NaNs before LMM\n",
    "    if len(df_long_clean) < 2:  # Minimum observations for LMM\n",
    "        print(f\"Insufficient data for LMM after removing NaNs: {len(df_long_clean)} observations\")\n",
    "        result = None\n",
    "    else:\n",
    "        try:\n",
    "            model = smf.mixedlm(f\"{img_value} ~ headcoil * mb * me\", df_long_clean, groups=df_long_clean[\"subject\"])\n",
    "            result = model.fit()\n",
    "            print(result.summary())\n",
    "            \n",
    "            # Pairwise comparisons for mb (averaged over headcoil and me)\n",
    "            print(f\"\\nPairwise comparisons for mb (averaged over headcoil and me):\")\n",
    "            tukey_mb = pairwise_tukeyhsd(endog=df_long_clean[img_value], groups=df_long_clean['mb'], alpha=0.05)\n",
    "            print(tukey_mb)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"LMM failed: {e}\")\n",
    "            print(f\"Shape of df_long_clean: {df_long_clean.shape}\")\n",
    "            print(f\"Missing values in df_long_clean:\\n{df_long_clean.isnull().sum()}\")\n",
    "            result = None\n",
    "    \n",
    "    # Run R-based analysis with emmeans for EMMs and 3-way interaction\n",
    "    print(f\"\\nRunning R-based EMM analysis for {mask_value} ({img_value})...\")\n",
    "    if len(df_long_clean) >= 2:\n",
    "        try:\n",
    "            # Convert to R dataframe\n",
    "            rdf = pandas2ri.py2rpy(df_long_clean)\n",
    "            ro.globalenv['rdf'] = rdf\n",
    "            \n",
    "            # Pass mask_value, headcoil counts, and img_value to R\n",
    "            ro.globalenv['roi'] = mask_value\n",
    "            ro.globalenv['n_20'] = headcoil_counts.get('20', 0)\n",
    "            ro.globalenv['n_64'] = headcoil_counts.get('64', 0)\n",
    "            ro.globalenv['img_value'] = img_value\n",
    "            \n",
    "            # Fit model and compute EMMs in R\n",
    "            ro.r('''\n",
    "            library(lme4)\n",
    "            library(emmeans)\n",
    "            \n",
    "            rdf$subject <- as.factor(rdf$subject)\n",
    "            rdf$mb <- factor(rdf$mb, levels = c(\"mb1\", \"mb3\", \"mb6\"))\n",
    "            rdf$me <- factor(rdf$me, levels = c(\"me1\", \"me4\"))\n",
    "            rdf$headcoil <- as.factor(rdf$headcoil)\n",
    "            \n",
    "            # Dynamically construct the formula using img_value\n",
    "            formula_str <- paste(img_value, \"~ headcoil * mb * me + (1 | subject)\")\n",
    "            model <- lmer(as.formula(formula_str), data = rdf)\n",
    "            \n",
    "            # Joint test for 3-way interaction\n",
    "            cat(\"\\\\n===== Joint Tests for 3-Way Interaction =====\\\\n\")\n",
    "            print(joint_tests(emmeans(model, ~ headcoil * mb * me)))\n",
    "            \n",
    "            # Extract EMMs and return to Python\n",
    "            emm <- emmeans(model, ~ mb * me * headcoil)\n",
    "            emm_df <- as.data.frame(emm)\n",
    "            ''')\n",
    "            \n",
    "            # Retrieve EMM data from R\n",
    "            emm_r_df = ro.globalenv['emm_df']\n",
    "            emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "            \n",
    "            # Map numeric factor levels to strings\n",
    "            mb_map = {1: 'mb1', 2: 'mb3', 3: 'mb6'}\n",
    "            me_map = {1: 'me1', 2: 'me4'}\n",
    "            headcoil_map = {1: '20', 2: '64'}  # Based on df_long headcoil assignment\n",
    "            emm_df['mb'] = emm_df['mb'].map(mb_map)\n",
    "            emm_df['me'] = emm_df['me'].map(me_map)\n",
    "            emm_df['headcoil'] = emm_df['headcoil'].map(headcoil_map)\n",
    "            \n",
    "            # Verify the mapping\n",
    "            print(f\"Debug: After mapping, emm_df shape: {emm_df.shape}\")\n",
    "            print(f\"Debug: After mapping, emm_df columns: {emm_df.columns.tolist()}\")\n",
    "            print(f\"Debug: After mapping, emm_df head:\\n{emm_df.head()}\")\n",
    "            \n",
    "            # Create EMM line plots\n",
    "            emm_fig = create_emm_line_plots(emm_df, n_subjects_per_coil, mask_value, contrast, output_dir, type_value, img_value, denoise_value)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"R-based EMM analysis failed: {e}\")\n",
    "    \n",
    "    # Prepare plot data and create bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    fig = create_bar_plots(plot_data, mask_value, contrast, is_first, is_last)\n",
    "    if save_files:\n",
    "        plot_file = os.path.join(output_dir, f\"multiecho_plots_{type_value}_{img_value}_{mask_value}_{denoise_value}_{contrast.replace('>', 'gt').replace(' ', '_').replace(',', '')}.png\")\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Bar plot saved as '{plot_file}'\")\n",
    "    plt.show()  # Display bar plot in Jupyter\n",
    "    \n",
    "    return {\n",
    "        'dataframe': df,\n",
    "        'figure': fig,\n",
    "        'emm_figure': emm_fig if 'emm_fig' in locals() else None,\n",
    "        'contrast': contrast,\n",
    "        'plot_data': plot_data,\n",
    "        'lmm_result': result\n",
    "    }\n",
    "\n",
    "def run_analysis(type_value, img_value, mask_values, denoise_value, base_dir=None, save_files=True, output_dir=\"../derivatives/plots\"):\n",
    "    \"\"\"Run the full analysis for the given parameters\"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    headcoil_64_subjects = [\n",
    "        \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "        \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "        \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "        \"10186\", \"10188\", \"10221\"\n",
    "    ]\n",
    "    initialize_plotting_engine()\n",
    "    print(f\"\\nAnalysis Parameters: TYPE_VALUE={type_value.upper()}, IMG_VALUE={img_value.capitalize()}\")\n",
    "    results = {}\n",
    "    for i, mask_value in enumerate(mask_values):\n",
    "        is_first = (i == 0)\n",
    "        is_last = (i == len(mask_values) - 1)\n",
    "        result = process_mask(\n",
    "            base_dir=base_dir,\n",
    "            type_value=type_value,\n",
    "            img_value=img_value, \n",
    "            mask_value=mask_value,\n",
    "            denoise_value=denoise_value,\n",
    "            headcoil_64_subjects=headcoil_64_subjects,\n",
    "            is_first=is_first,\n",
    "            is_last=is_last,\n",
    "            save_files=save_files,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        if result:\n",
    "            results[mask_value] = result\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b222215-d964-44f0-8d96-3d547f8620d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe434cc0-7635-43a9-8bf4-7ee1fd614b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b0170-0864-4c4b-9411-90d3846c9e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62282682-c706-4411-947f-c228a4f7e015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c37570-26f9-49ed-ac4e-0ae8cd1ee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for generating plots and statistical analysis\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Activate pandas-R conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "base = importr('base')\n",
    "lme4 = importr('lme4')\n",
    "lmerTest = importr('lmerTest')\n",
    "emmeans = importr('emmeans')\n",
    "\n",
    "def initialize_plotting_engine():\n",
    "    \"\"\"Initialize the plotting environment with required settings\"\"\"\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "\n",
    "def determine_contrast(mask_value):\n",
    "    \"\"\"Determine contrast based on mask value\"\"\"\n",
    "    if mask_value in [\"VSconstrained\", \"VMPFC\"]:\n",
    "        return \"Rew>Pun\"\n",
    "    elif mask_value == \"rFFA\":\n",
    "        return \"Str>Com\"\n",
    "    elif mask_value in [\"bilateralMotor\", \"bilateralCerebellum\"]:\n",
    "        return \"Avg (L>R, R>L)\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"Extract data from files matching the given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-((?:act|ppi_seed-VS_thr5))_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    data_by_subject = {}\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value \n",
    "                and mask == mask_value and denoise == denoise_value):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, headcoil_64_subjects):\n",
    "    \"\"\"Create a DataFrame from the collected data\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: '64' if x in headcoil_64_subjects else '20')\n",
    "    column_order = ['subject', 'headcoil'] + acq_params\n",
    "    df = df[column_order]\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_plot_data(df):\n",
    "    \"\"\"Prepare data for plotting by calculating means and errors by headcoil type\"\"\"\n",
    "    acq_params = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    df_20 = df[df['headcoil'] == '20']\n",
    "    df_64 = df[df['headcoil'] == '64']\n",
    "    results = {}\n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        means = {acq: hc_df[acq].mean() for acq in acq_params}\n",
    "        errors = {acq: hc_df[acq].sem() for acq in acq_params}\n",
    "        results[hc_name] = {'means': means, 'errors': errors, 'count': len(hc_df)}\n",
    "    return results\n",
    "\n",
    "def create_bar_plots(plot_data, mask_value, contrast, title_prefix=\"\"):\n",
    "    \"\"\"Create bar plots for the given data with consistent y-axis limits within each ROI\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    width = 0.4\n",
    "    x1 = [0, 1.2, 2.4]\n",
    "    x2 = [x + width for x in x1]\n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    mb_levels = ['mb1', 'mb3', 'mb6']\n",
    "    \n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for i, (hc, ax) in enumerate([('20', ax1), ('64', ax2)]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        ax.bar(x1, me1_means, width, color=me_colors['me1'], label='me1', \n",
    "               yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me_colors['me4'], label='me4', \n",
    "               yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        all_y_values.extend([v for v in y_values if not np.isnan(v)])\n",
    "        all_y_errors.extend([e for e in y_errors if not np.isnan(e)])\n",
    "        \n",
    "        ax.set_xticks([x + width/2 for x in x1])\n",
    "        ax.set_xticklabels(mb_levels, fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{title_prefix}{mask_value}', fontsize=48)\n",
    "        \n",
    "        ax.set_title(f\"{hc}-Channel\\nn={count}\", fontsize=48, fontweight='bold')\n",
    "    \n",
    "    # Set consistent y-limits\n",
    "    if all_y_values and all_y_errors:\n",
    "        y_max = max([v + e for v, e in zip(all_y_values, all_y_errors) if not np.isnan(v)])\n",
    "        y_min = min([v - e for v, e in zip(all_y_values, all_y_errors) if not np.isnan(v)])\n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax1.set_ylim(max(0, y_min - margin), y_max + margin)\n",
    "        ax2.set_ylim(max(0, y_min - margin), y_max + margin)\n",
    "    \n",
    "    # Add legend\n",
    "    axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                    loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plots(emm_df, n_subjects_per_coil, mask_value, title_prefix=\"\"):\n",
    "    \"\"\"Create line plots for estimated marginal means with consistent y-axis limits\"\"\"\n",
    "    plt.rcParams.update({'font.size': 48})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    me_colors = {'me1': 'royalblue', 'me4': 'darkorange'}\n",
    "    coil_types = sorted(emm_df['headcoil'].unique())\n",
    "    \n",
    "    # Collect all y-values and errors to determine consistent y-axis limits\n",
    "    all_y_values = []\n",
    "    all_y_errors = []\n",
    "    \n",
    "    for coil in coil_types:\n",
    "        coil_data = emm_df[emm_df['headcoil'] == coil]\n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['me'] == me]\n",
    "            if not me_data.empty:\n",
    "                y_values = me_data['emmean'].values\n",
    "                y_errors = me_data['SE'].values\n",
    "                all_y_values.extend(y_values)\n",
    "                all_y_errors.extend(y_errors)\n",
    "    \n",
    "    # Calculate global y-axis limits\n",
    "    if all_y_values:\n",
    "        y_max = max([v + e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        y_min = min([v - e for v, e in zip(all_y_values, all_y_errors)])\n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        y_limits = (max(0, y_min - margin), y_max + margin)\n",
    "    else:\n",
    "        y_limits = (0, 1)\n",
    "    \n",
    "    for i, coil in enumerate(coil_types):\n",
    "        ax = axes[i]\n",
    "        coil_data = emm_df[emm_df['headcoil'] == coil]\n",
    "        \n",
    "        for me in ['me1', 'me4']:\n",
    "            me_data = coil_data[coil_data['me'] == me]\n",
    "            if not me_data.empty:\n",
    "                me_data = me_data.sort_values('mb')\n",
    "                ax.plot(me_data['mb'], me_data['emmean'], marker='o', color=me_colors[me], \n",
    "                        label=me, linewidth=5, markersize=15)\n",
    "                ax.errorbar(me_data['mb'], me_data['emmean'], yerr=me_data['SE'], \n",
    "                            fmt='none', color=me_colors[me], capsize=8, capthick=4, elinewidth=3)\n",
    "        \n",
    "        n_subjects = n_subjects_per_coil.get(coil, 0)\n",
    "        ax.set_title(f\"{coil}-Channel\\nn={n_subjects}\", fontsize=48, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'Estimated\\nMarginal Mean {title_prefix}{mask_value}', fontsize=48)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=48)\n",
    "        ax.set_ylim(y_limits)\n",
    "    \n",
    "    axes[-1].legend(title='Multi-echo', fontsize=36, title_fontsize=36, \n",
    "                    loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.supxlabel('Multiband Factor', fontsize=48, y=-0.05)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def run_statistical_analysis(df_long, img_value, mask_value):\n",
    "    \"\"\"Run statistical analysis using R's lme4 and emmeans\"\"\"\n",
    "    df_long_clean = df_long.dropna(subset=[img_value])\n",
    "    \n",
    "    if len(df_long_clean) < 2:\n",
    "        print(f\"Insufficient data for LMM after removing NaNs: {len(df_long_clean)} observations\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to R dataframe\n",
    "    r_df = pandas2ri.py2rpy(df_long_clean)\n",
    "    \n",
    "    # Ensure factors are properly set in R\n",
    "    ro.r('''\n",
    "    levels_mb <- c(\"mb1\", \"mb3\", \"mb6\")\n",
    "    levels_me <- c(\"me1\", \"me4\")\n",
    "    ''')\n",
    "    r_df = ro.r('''\n",
    "    transform({}, \n",
    "              subject = factor(subject),\n",
    "              mb = factor(mb, levels = levels_mb), \n",
    "              me = factor(me, levels = levels_me), \n",
    "              headcoil = factor(headcoil))\n",
    "    '''.format(r_df.r_repr()))\n",
    "    \n",
    "    # Fit the model\n",
    "    formula = Formula(f'{img_value} ~ headcoil * mb * me + (1 | subject)')\n",
    "    model = lme4.lmer(formula, data=r_df)\n",
    "    \n",
    "    # Get model summary\n",
    "    model_summary = ro.r('summary')(model)\n",
    "    summary_lines = ro.r('capture.output')(model_summary)\n",
    "    summary_lines_list = list(summary_lines)\n",
    "    # Remove the Data section as in the TSNR kernel\n",
    "    data_start = None\n",
    "    data_end = None\n",
    "    for i, line in enumerate(summary_lines_list):\n",
    "        if line.startswith('   Data:'):\n",
    "            data_start = i\n",
    "        elif data_start is not None and line.startswith('REML criterion at convergence:'):\n",
    "            data_end = i\n",
    "            break\n",
    "    if data_start is not None and data_end is not None:\n",
    "        summary_lines_list = summary_lines_list[:data_start] + summary_lines_list[data_end:]\n",
    "    model_summary_str = '\\n'.join(summary_lines_list)\n",
    "    \n",
    "    print(f\"\\nLinear Mixed Effects Model Summary ({img_value} ~ headcoil * mb * me + (1 | subject)):\\n\")\n",
    "    print(model_summary_str)\n",
    "    \n",
    "    # Compute pairwise comparisons\n",
    "    emm = emmeans.emmeans(model, ro.StrVector(['headcoil', 'mb', 'me']))\n",
    "    pairwise = ro.r('pairs')(emm)\n",
    "    pairwise_r_df = ro.r('as.data.frame')(pairwise)\n",
    "    pairwise_df = pandas2ri.rpy2py(pairwise_r_df)\n",
    "    \n",
    "    # Extract EMMs for plotting\n",
    "    emm_r_df = ro.r('as.data.frame')(emm)\n",
    "    emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "    \n",
    "    # Map numeric indices to string labels\n",
    "    mb_map = {1: 'mb1', 2: 'mb3', 3: 'mb6'}\n",
    "    me_map = {1: 'me1', 2: 'me4'}\n",
    "    headcoil_map = {1: '20', 2: '64'}\n",
    "    \n",
    "    emm_df['mb'] = emm_df['mb'].map(mb_map)\n",
    "    emm_df['me'] = emm_df['me'].map(me_map)\n",
    "    emm_df['headcoil'] = emm_df['headcoil'].map(headcoil_map)\n",
    "    \n",
    "    # Map pairwise comparisons\n",
    "    def map_contrast(contrast):\n",
    "        for num, label in mb_map.items():\n",
    "            contrast = contrast.replace(f'mb{num}', f'mb{label}')\n",
    "        for num, label in me_map.items():\n",
    "            contrast = contrast.replace(f'me{num}', f'me{label}')\n",
    "        for num, label in headcoil_map.items():\n",
    "            contrast = contrast.replace(f'headcoil{num}', f'headcoil{label}')\n",
    "        return contrast\n",
    "    \n",
    "    pairwise_df['contrast'] = pairwise_df['contrast'].apply(map_contrast)\n",
    "    \n",
    "    print(f\"\\nPairwise comparisons for headcoil * mb * me in {mask_value}:\")\n",
    "    print(pairwise_df)\n",
    "    \n",
    "    return {\n",
    "        'model_summary': model_summary_str,\n",
    "        'pairwise_df': pairwise_df,\n",
    "        'emm_df': emm_df\n",
    "    }\n",
    "\n",
    "def process_mask(base_dir, type_value, img_value, mask_value, denoise_value, headcoil_64_subjects, \n",
    "                 save_files=True, output_dir=\"../derivatives/plots\"):\n",
    "    \"\"\"Process a single mask, create and display plots, and run statistical analysis\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    contrast = determine_contrast(mask_value)\n",
    "    print(f\"\\nProcessing files with parameters: type={type_value}, img={img_value}, mask={mask_value}, denoise={denoise_value}\")\n",
    "    print(f\"Using contrast: {contrast}\")\n",
    "    \n",
    "    # Extract data\n",
    "    data_by_subject = extract_file_data(base_dir, type_value, img_value, mask_value, denoise_value)\n",
    "    if not data_by_subject:\n",
    "        print(f\"No matching files found for mask: {mask_value}\")\n",
    "        return None\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject, headcoil_64_subjects)\n",
    "    \n",
    "    if save_files:\n",
    "        output_file = os.path.join(output_dir, \n",
    "                                   f\"multiecho_data_{type_value}_{img_value}_{mask_value}_{denoise_value}_{contrast.replace('>', 'gt').replace(' ', '_').replace(',', '')}.csv\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get('64', 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get('20', 0)}\")\n",
    "    \n",
    "    # Prepare plot data and create bar plots\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Determine title prefix based on img_value\n",
    "    title_prefix = \"\"\n",
    "    if img_value == \"tsnr\":\n",
    "        title_prefix = \"Median TSNR\\n\"\n",
    "    elif img_value == \"beta\":\n",
    "        title_prefix = \"Beta\\n\"\n",
    "    elif img_value == \"zstat\":\n",
    "        title_prefix = \"Z-stat\\n\"\n",
    "    \n",
    "    bar_fig = create_bar_plots(plot_data, mask_value, contrast, title_prefix)\n",
    "    \n",
    "    if save_files:\n",
    "        plot_file = os.path.join(output_dir, \n",
    "                                f\"bar_plot_{type_value}_{img_value}_{mask_value}_{denoise_value}_{contrast.replace('>', 'gt').replace(' ', '_').replace(',', '')}.png\")\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Bar plot saved as '{plot_file}'\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Reshape data for statistical analysis\n",
    "    df_long = pd.melt(\n",
    "        df, \n",
    "        id_vars=['subject', 'headcoil'], \n",
    "        value_vars=['mb1me1', 'mb3me1', 'mb6me1', 'mb1me4', 'mb3me4', 'mb6me4'],\n",
    "        var_name='acq', \n",
    "        value_name=img_value\n",
    "    )\n",
    "    df_long['mb'] = df_long['acq'].str[:3]\n",
    "    df_long['me'] = df_long['acq'].str[3:]\n",
    "    df_long = df_long.drop(columns=['acq'])\n",
    "    \n",
    "    df_long['mb'] = pd.Categorical(df_long['mb'], categories=['mb1', 'mb3', 'mb6'], ordered=True)\n",
    "    df_long['me'] = pd.Categorical(df_long['me'], categories=['me1', 'me4'], ordered=True)\n",
    "    \n",
    "    # Compute n_subjects_per_coil for EMM plot titles\n",
    "    n_subjects_per_coil = df.groupby('headcoil')['subject'].nunique().to_dict()\n",
    "    \n",
    "    # Run statistical analysis\n",
    "    stats_results = run_statistical_analysis(df_long, img_value, mask_value)\n",
    "    \n",
    "    # Create and display EMM plots if statistical analysis successful\n",
    "    emm_fig = None\n",
    "    if stats_results and 'emm_df' in stats_results:\n",
    "        emm_df = stats_results['emm_df']\n",
    "        emm_fig = create_emm_line_plots(emm_df, n_subjects_per_coil, mask_value, title_prefix)\n",
    "        \n",
    "        if save_files:\n",
    "            emm_plot_file = os.path.join(output_dir, \n",
    "                                        f\"emm_plot_{type_value}_{img_value}_{mask_value}_{denoise_value}_{contrast.replace('>', 'gt').replace(' ', '_').replace(',', '')}.png\")\n",
    "            plt.savefig(emm_plot_file, dpi=300, bbox_inches='tight')\n",
    "            print(f\"EMM plot saved as '{emm_plot_file}'\")\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'dataframe': df,\n",
    "        'bar_figure': bar_fig,\n",
    "        'emm_figure': emm_fig,\n",
    "        'contrast': contrast,\n",
    "        'plot_data': plot_data,\n",
    "        'statistical_results': stats_results\n",
    "    }\n",
    "\n",
    "def run_analysis(type_value, img_value, mask_values, denoise_value, base_dir=None, save_files=True, output_dir=\"../derivatives/plots\"):\n",
    "    \"\"\"Run the full analysis for the given parameters\"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    \n",
    "    headcoil_64_subjects = [\n",
    "        \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "        \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "        \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "        \"10186\", \"10188\", \"10221\"\n",
    "    ]\n",
    "    \n",
    "    initialize_plotting_engine()\n",
    "    print(f\"\\nAnalysis Parameters: TYPE_VALUE={type_value.upper()}, IMG_VALUE={img_value.capitalize()}\")\n",
    "    \n",
    "    results = {}\n",
    "    for mask_value in mask_values:\n",
    "        result = process_mask(\n",
    "            base_dir=base_dir,\n",
    "            type_value=type_value,\n",
    "            img_value=img_value, \n",
    "            mask_value=mask_value,\n",
    "            denoise_value=denoise_value,\n",
    "            headcoil_64_subjects=headcoil_64_subjects,\n",
    "            save_files=save_files,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        if result:\n",
    "            results[mask_value] = result\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a938c8-3208-4283-a1e8-e1d3793c415f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Figure 5. TSNR for each acquisition in each ROI\n",
    "TYPE_VALUE = \"act\" # \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"tsnr\" # \"tsnr\" \"beta\" \"zstat\"\n",
    "MASK_VALUES = [\"VSconstrained\", \"rFFA\", \"bilateralMotor\"] # \"VSconstrained\", \"VMPFC\", \"rFFA\", \"bilateralMotor\", \"bilateralCerebellum\"\n",
    "DENOISE_VALUE = \"base\" # \"base\" \"tedana\"\n",
    "\n",
    "# Run the analysis with the new parameters\n",
    "results = run_analysis(TYPE_VALUE, IMG_VALUE, MASK_VALUES, DENOISE_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707829b-834f-4587-8b33-da2ec1810e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6. Beta estimates for activation for each acquisition in each ROI\n",
    "TYPE_VALUE = \"act\" # \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\" # \"tsnr\" \"beta\" \"zstat\"\n",
    "MASK_VALUES = [\"VSconstrained\", \"rFFA\", \"bilateralMotor\"] # \"VSconstrained\", \"VMPFC\", \"rFFA\", \"bilateralMotor\", \"bilateralCerebellum\"\n",
    "DENOISE_VALUE = \"base\" # \"base\" \"tedana\"\n",
    "\n",
    "# Run the analysis with the new parameters\n",
    "results = run_analysis(TYPE_VALUE, IMG_VALUE, MASK_VALUES, DENOISE_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502363ed-f6ab-44f9-b27e-66aef704183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supp. Figure 6. zstats for activation for each acquisition in each ROI\n",
    "TYPE_VALUE = \"act\" # \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"zstat\" # \"tsnr\" \"beta\" \"zstat\"\n",
    "MASK_VALUES = [\"VSconstrained\", \"VMPFC\", \"rFFA\", \"bilateralMotor\", \"bilateralCerebellum\"] # \"VSconstrained\", \"VMPFC\", \"rFFA\", \"bilateralMotor\", \"bilateralCerebellum\"\n",
    "DENOISE_VALUE = \"base\" # \"base\" \"tedana\"\n",
    "\n",
    "# Run the analysis with the new parameters\n",
    "results = run_analysis(TYPE_VALUE, IMG_VALUE, MASK_VALUES, DENOISE_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9bb38-3a04-4c15-bd9c-a695b492f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LME: ME\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\" # \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\" # \"tsnr\" \"beta\" \"zstat\"\n",
    "MASK_VALUES = [\"MEbonf\"] # \"VSconstrained\", \"VMPFC\", \"rFFA\", \"bilateralMotor\", \"bilateralCerebellum\"\n",
    "DENOISE_VALUE = \"base\" # \"base\" \"tedana\"\n",
    "\n",
    "# Run the analysis with the new parameters\n",
    "results = run_analysis(TYPE_VALUE, IMG_VALUE, MASK_VALUES, DENOISE_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0c420-76b3-49d5-8945-a8bf3d0875eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LME: HC x ME\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\" # \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\" # \"tsnr\" \"beta\" \"zstat\"\n",
    "MASK_VALUES = [\"HCxMEbonf\"] # \"VSconstrained\", \"VMPFC\", \"rFFA\", \"bilateralMotor\", \"bilateralCerebellum\"\n",
    "DENOISE_VALUE = \"base\" # \"base\" \"tedana\"\n",
    "\n",
    "# Run the analysis with the new parameters\n",
    "results = run_analysis(TYPE_VALUE, IMG_VALUE, MASK_VALUES, DENOISE_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f74cf1-8bc2-4e67-ad68-e9f6f9a0e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LME: 3way\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\" # \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\" # \"tsnr\" \"beta\" \"zstat\"\n",
    "MASK_VALUES = [\"3waybonf\"] # \"VSconstrained\", \"VMPFC\", \"rFFA\", \"bilateralMotor\", \"bilateralCerebellum\"\n",
    "DENOISE_VALUE = \"base\" # \"base\" \"tedana\"\n",
    "\n",
    "# Run the analysis with the new parameters\n",
    "results = run_analysis(TYPE_VALUE, IMG_VALUE, MASK_VALUES, DENOISE_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43fb2a4-b97c-4f73-8c72-6482b9877870",
   "metadata": {},
   "source": [
    "# Fig 8. Analysis of Tedana vs. Base Denoising Effects with Framewise Displacement\n",
    "\n",
    "This combined code chunk processes framewise displacement (FD) data and fMRI metric differences between two denoising methods (Tedana and a baseline) across multiecho acquisitions (mb1me4, mb3me4, mb6me4), then visualizes the relationship between FD and denoising effects using scatter plots. It consists of two parts: (1) calculating average FD values per subject and acquisition, and (2) extracting, processing, and plotting the denoising differences with FD.\n",
    "\n",
    "### Key Components\n",
    "1. **FD Preprocessing (Part 1)**:\n",
    "   - Loads a TSV file containing FD data (e.g., `Task-sharedreward_Level-Acq_Outlier-info_mriqc-0.16.1.tsv`).\n",
    "   - Filters out subjects ending in `sp` and acquisitions with `me1`, retaining only `me4` data.\n",
    "   - Saves filtered data as `fd_mean_values.csv`.\n",
    "   - Groups data by subject and acquisition (e.g., `mb1me4`), computes mean `fd_mean` values, and saves results to `fd_mean_averages.xlsx`.\n",
    "\n",
    "2. **Data Extraction and Difference Calculation (Part 2)**:\n",
    "   - `extract_file_data_with_difference`: \n",
    "     - Parses text files in a directory (e.g., `~/Documents/GitHub/multiecho-pilot/derivatives/extractions`) matching a regex pattern.\n",
    "     - Extracts metric values (e.g., beta) for specified denoising methods (`denoise_tedana`, `denoise_base`) across acquisitions (mb1me4, mb3me4, mb6me4).\n",
    "     - Computes differences (`tedana - base`) per subject and acquisition, handling missing data with NaNs.\n",
    "\n",
    "3. **Data Merging (Part 2)**:\n",
    "   - `create_dataframe_with_fd`: \n",
    "     - Constructs a DataFrame from difference data, adding headcoil assignments (20 or 64 channels) based on a predefined subject list.\n",
    "     - Merges with FD data from `fd_mean_values.csv`, aligning on subject and acquisition.\n",
    "     - Reshapes to long format with columns: `subject`, `headcoil`, `acq`, `tedana_minus_base`, and `fd_mean`.\n",
    "\n",
    "4. **Visualization (Part 2)**:\n",
    "   - `create_scatter_plots`: \n",
    "     - Generates two sets of scatter plots (one per acquisition):\n",
    "       - **Set 1**: Splits by headcoil (red for 20, green for 64), with regression lines per headcoil.\n",
    "       - **Set 2**: Combines all data (blue dots), with a single regression line.\n",
    "     - X-axis: Mean FD; Y-axis: Tedana minus base difference; Subplots: One per acquisition.\n",
    "   - `initialize_plotting_engine`: Sets large fonts and a whitegrid style for readability.\n",
    "\n",
    "5. **Execution (Part 2)**:\n",
    "   - `process_and_visualize_tedana_difference`: \n",
    "     - Orchestrates the workflow: extracts differences, merges with FD, and creates plots.\n",
    "     - Saves merged data as CSV and plots as PNG if `save_files=True`.\n",
    "\n",
    "### Inputs\n",
    "- **Part 1**:\n",
    "  - `input_file`: TSV file with FD data (e.g., `~/.../Outlier-info_mriqc-0.16.1.tsv`).\n",
    "- **Part 2**:\n",
    "  - `base_dir`: Directory with fMRI text files (default: `~/.../extractions`).\n",
    "  - `type_value`: Analysis type (e.g., `act`).\n",
    "  - `img_value`: Metric (e.g., `beta`).\n",
    "  - `mask_value`: ROI (e.g., `VSconstrained`).\n",
    "  - `denoise_tedana`, `denoise_base`: Denoising methods (e.g., `tedana`, `smooth`).\n",
    "  - `fd_csv_path`: Path to FD CSV (default: `fd_mean_values.csv` from Part 1).\n",
    "  - `acq_params`: Acquisitions (default: `[\"mb1me4\", \"mb3me4\", \"mb6me4\"]`).\n",
    "  - `headcoil_64_subjects`: List of subjects with 64-channel headcoils.\n",
    "\n",
    "### Outputs\n",
    "- **Part 1**:\n",
    "  - `fd_mean_values.csv`: Filtered FD data.\n",
    "  - `fd_mean_averages.xlsx`: Averaged FD per subject and acquisition.\n",
    "- **Part 2**:\n",
    "  - **DataFrame**: Saved as `multiecho_tedana_minus_base_<type>_<img>_<mask>.csv`.\n",
    "  - **Plots**: Two PNG files (e.g., `tedana_minus_base_scatter_<type>_<img>_<mask>.png`) with headcoil-split and combined scatter plots.\n",
    "\n",
    "### Notes\n",
    "- Assumes `me4` acquisitions are the focus; `me1` data is excluded.\n",
    "- Handles missing data by skipping invalid files and reporting NaNs in merges.\n",
    "- Plot aesthetics (e.g., font size=56, dot size=300) are optimized for publication clarity.\n",
    "- The two parts are interdependent: Part 1 generates FD data used by Part 2.\n",
    "\n",
    "This workflow supports Figure 8 by linking head motion (FD) to denoising effects across acquisition types and headcoils, providing visual and tabular insights into data quality trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cab63-dbd8-4d3f-83b0-cae59f046c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8 Part 1, Generate avg fd_mean values for each ME acq\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "input_file = \"~/Documents/GitHub/multiecho-pilot/derivatives/Task-sharedreward_Level-Acq_Outlier-info_mriqc-0.16.1.tsv\"\n",
    "output_file = \"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\"\n",
    "\n",
    "# Load the TSV file\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Filter out subjects ending in 'sp' and acquisitions containing 'me1'\n",
    "df = df[~df['Sub'].str.endswith('sp')]\n",
    "df = df[~df['acq'].str.contains('me1', na=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "#print(\"Filtered data saved to:\", output_file)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your spreadsheet data\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Extract the base 'acq' substring (e.g., mb1me4, mb3me4, mb6me4) from the 'acq' column\n",
    "df['acq_base'] = df['acq'].str.extract(r'(mb\\dme4)')\n",
    "\n",
    "# Group by 'Sub' and 'acq_base' and calculate the average of 'fd_mean' for each group\n",
    "averages = df.groupby(['Sub', 'acq_base'])['fd_mean'].mean().reset_index()\n",
    "\n",
    "# Save the results to a new spreadsheet\n",
    "output_file_path = 'fd_mean_averages.xlsx'  # Replace with your desired output file path\n",
    "averages.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Optionally, print the averages to verify\n",
    "print(averages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494f63b-1ae1-41c3-9f77-541d51cb5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8 part 2, define function for Figure 8 plots\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "def initialize_plotting_engine():\n",
    "    \"\"\"Initialize the plotting environment with required settings\"\"\"\n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    # Significantly increase font size\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "\n",
    "def extract_file_data_with_difference(base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params):\n",
    "    \"\"\"Extract data and calculate differences between denoise methods for given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {base_dir}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in acq_params:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value and mask == mask_value and \n",
    "                denoise in [denoise_tedana, denoise_base]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in acq_params}\n",
    "                            for denoise in [denoise_tedana, denoise_base]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Subjects with data: {len(data_by_subject)}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in acq_params:\n",
    "            tedana_val = data[denoise_tedana].get(acq, np.nan)\n",
    "            base_val = data[denoise_base].get(acq, np.nan)\n",
    "            diff = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "            diff_by_subject[sub_id][acq] = diff\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects):\n",
    "    \"\"\"Create and merge DataFrame with framewise displacement data\"\"\"\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in headcoil_64_subjects else 20)\n",
    "    column_order = ['subject', 'headcoil'] + acq_params\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject', 'headcoil'], value_vars=acq_params, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(fd_csv_path)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me\\d)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    nan_count = df_merged['fd_mean'].isna().sum()\n",
    "    print(f\"\\nNumber of NaN fd_mean values after merge: {nan_count} out of {len(df_merged)} rows\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base):\n",
    "    \"\"\"Create two batches of scatter plots:\n",
    "       1. Split by headcoil (red for 20, green for 64)\n",
    "       2. No split by headcoil (blue dots)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(acq_params), figsize=(24, 8), sharey=True)\n",
    "\n",
    "    # Colors for headcoil scatter plots\n",
    "    colors = {20: 'red', 64: 'green'}\n",
    "    legend_handles = []\n",
    "\n",
    "    for i, acq in enumerate(acq_params):\n",
    "        ax = axes[i]\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "\n",
    "        # Scatter plot with headcoil split\n",
    "        scatter = sns.scatterplot(\n",
    "            data=acq_data, x='fd_mean', y='tedana_minus_base',\n",
    "            hue='headcoil', palette=colors, ax=ax, s=300  # Larger dots\n",
    "        )\n",
    "\n",
    "        # Capture legend handles for later use\n",
    "        if i == 0:\n",
    "            legend_handles = scatter.legend_.legendHandles\n",
    "\n",
    "        # Regression lines for each headcoil\n",
    "        for hc in [20, 64]:\n",
    "            hc_data = acq_data[acq_data['headcoil'] == hc]\n",
    "            if len(hc_data) > 1:  # Need at least 2 points for regression\n",
    "                sns.regplot(x='fd_mean', y='tedana_minus_base', data=hc_data,\n",
    "                            scatter=False, ax=ax, color=colors[hc], line_kws={'linewidth': 3})\n",
    "\n",
    "        # Set title for each subplot\n",
    "        ax.set_title(f'{acq}', fontsize=64, fontweight='bold')\n",
    "\n",
    "        # Only add y-label to the first subplot\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{mask_value}\\n{denoise_tedana} - {denoise_base}', fontsize=56)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "\n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=56)\n",
    "\n",
    "        # Remove individual legends\n",
    "        ax.legend().remove()\n",
    "\n",
    "        # Remove redundant x-labels (fd_mean under each plot)\n",
    "        ax.set_xlabel('')\n",
    "\n",
    "    # Fine-tuned x-axis label position (closer to ticks)\n",
    "    fig.text(0.5, -0.02, 'Mean Framewise Displacement', ha='center', fontsize=56)\n",
    "\n",
    "    # Adjust layout to make space for the legend\n",
    "    plt.subplots_adjust(right=0.8)\n",
    "\n",
    "    # Add a single legend outside the plots (with smaller text and simple labels)\n",
    "    fig.legend(legend_handles, ['20', '64'], title='Headcoil',\n",
    "               loc='center left', bbox_to_anchor=(1, 0.5), fontsize=28, title_fontsize=28)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create second batch of plots (no headcoil split, all dots blue)\n",
    "    fig2, axes2 = plt.subplots(1, len(acq_params), figsize=(24, 8), sharey=True)\n",
    "\n",
    "    for i, acq in enumerate(acq_params):\n",
    "        ax2 = axes2[i]\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "\n",
    "        # Scatter plot (all blue)\n",
    "        sns.scatterplot(\n",
    "            data=acq_data, x='fd_mean', y='tedana_minus_base',\n",
    "            color='blue', ax=ax2, s=300\n",
    "        )\n",
    "\n",
    "        # Regression line for all data points\n",
    "        if len(acq_data) > 1:\n",
    "            sns.regplot(x='fd_mean', y='tedana_minus_base', data=acq_data,\n",
    "                        scatter=False, ax=ax2, color='blue', line_kws={'linewidth': 3})\n",
    "\n",
    "        ax2.set_title(f'{acq}', fontsize=64, fontweight='bold')\n",
    "\n",
    "        # Only add y-label to the first subplot\n",
    "        if i == 0:\n",
    "            ax2.set_ylabel(f'{mask_value}\\n{denoise_tedana} - {denoise_base}', fontsize=56)\n",
    "        else:\n",
    "            ax2.set_ylabel('')\n",
    "\n",
    "        ax2.tick_params(axis='both', which='major', labelsize=56)\n",
    "\n",
    "        # Remove redundant x-labels\n",
    "        ax2.set_xlabel('')\n",
    "\n",
    "    # Fine-tuned x-axis label for second batch\n",
    "    fig2.text(0.5, -0.02, 'Mean Framewise Displacement', ha='center', fontsize=56)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, fig2\n",
    "\n",
    "\n",
    "def process_and_visualize_tedana_difference(type_value, img_value, mask_value, denoise_tedana, denoise_base, \n",
    "                                           base_dir=None, fd_csv_path=None, acq_params=None, \n",
    "                                           headcoil_64_subjects=None, save_files=True):\n",
    "    \"\"\"Run the full analysis for tedana-base difference visualization\"\"\"\n",
    "    # Define default values if not provided\n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    \n",
    "    if fd_csv_path is None:\n",
    "        fd_csv_path = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "    \n",
    "    if acq_params is None:\n",
    "        acq_params = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    \n",
    "    if headcoil_64_subjects is None:\n",
    "        headcoil_64_subjects = [\n",
    "            \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "            \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "            \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "            \"10186\", \"10188\", \"10221\"\n",
    "        ]\n",
    "    \n",
    "    # Initialize plotting environment\n",
    "    initialize_plotting_engine()\n",
    "    \n",
    "    print(f\"\\nProcessing files for tedana - base difference: type={type_value}, img={img_value}, mask={mask_value}\")\n",
    "    \n",
    "    # Extract data and calculate differences\n",
    "    diff_by_subject = extract_file_data_with_difference(\n",
    "        base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params\n",
    "    )\n",
    "    \n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return None\n",
    "    \n",
    "    # Create and merge DataFrame with FD data\n",
    "    df = create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects)\n",
    "    \n",
    "    if save_files:\n",
    "        # Save to CSV\n",
    "        output_file = f\"multiecho_tedana_minus_base_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Create scatter plots\n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig = create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base)\n",
    "    \n",
    "    if save_files:\n",
    "        # Save the plot\n",
    "        plot_file = f\"tedana_minus_base_scatter_{type_value}_{img_value}_{mask_value}.png\"\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return {\n",
    "        'dataframe': df,\n",
    "        'figure': fig\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6004a92-5c10-432b-a124-c536bbb86d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2c47b-c94b-4327-b382-9054db9731e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e66a52-03e0-4ae8-bae5-07a1f887bdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e836473-12da-4313-9900-fcf0c3075b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b57cd5-6dc6-4e93-9deb-9cb455ba2657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4151a3-23ab-4099-bd03-40d7ee59c7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc85361-9631-4fea-afb0-716a5ab5df8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b901a4-2ad3-43a0-a57a-af14c87940ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3568a-f940-43b4-8249-ef09a53a5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from uuid import uuid4\n",
    "\n",
    "def initialize_plotting_engine():\n",
    "    \"\"\"Initialize the plotting environment with required settings\"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "\n",
    "def process_fd_mean_data(input_file, output_csv, output_excel):\n",
    "    \"\"\"Process TSV file to compute average fd_mean values for each subject and acquisition\"\"\"\n",
    "    # Load the TSV file\n",
    "    df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "    \n",
    "    # Filter out subjects ending in 'sp' and acquisitions containing 'me1'\n",
    "    df = df[~df['Sub'].str.endswith('sp')]\n",
    "    df = df[~df['acq'].str.contains('me1', na=False)]\n",
    "    \n",
    "    # Save filtered data to CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    # Extract the base 'acq' substring (e.g., mb1me4, mb3me4, mb6me4)\n",
    "    df['acq_base'] = df['acq'].str.extract(r'(mb\\dme4)')\n",
    "    \n",
    "    # Group by 'Sub' and 'acq_base' and calculate the average of 'fd_mean'\n",
    "    averages = df.groupby(['Sub', 'acq_base'])['fd_mean'].mean().reset_index()\n",
    "    \n",
    "    # Save averages to Excel\n",
    "    averages.to_excel(output_excel, index=False)\n",
    "    \n",
    "    return averages\n",
    "\n",
    "def extract_file_data_with_difference(base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params):\n",
    "    \"\"\"Extract data and calculate differences between denoise methods for given parameters\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {base_dir}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in acq_params:\n",
    "                continue\n",
    "            if (file_type == type_value and img == img_value and mask == mask_value and \n",
    "                denoise in [denoise_tedana, denoise_base]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in acq_params}\n",
    "                            for denoise in [denoise_tedana, denoise_base]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Subjects with data: {len(data_by_subject)}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in acq_params:\n",
    "            tedana_val = data[denoise_tedana].get(acq, np.nan)\n",
    "            base_val = data[denoise_base].get(acq, np.nan)\n",
    "            diff = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "            diff_by_subject[sub_id][acq] = diff\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects):\n",
    "    \"\"\"Create and merge DataFrame with framewise displacement data\"\"\"\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in headcoil_64_subjects else 20)\n",
    "    column_order = ['subject', 'headcoil'] + acq_params\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject', 'headcoil'], value_vars=acq_params, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(fd_csv_path)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me\\d)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    nan_count = df_merged['fd_mean'].isna().sum()\n",
    "    print(f\"\\nNumber of NaN fd_mean values after merge: {nan_count} out of {len(df_merged)} rows\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base):\n",
    "    \"\"\"Create two batches of scatter plots: split by headcoil and no split\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(acq_params), figsize=(24, 8), sharey=True)\n",
    "    colors = {20: 'red', 64: 'green'}\n",
    "    legend_handles = []\n",
    "\n",
    "    for i, acq in enumerate(acq_params):\n",
    "        ax = axes[i]\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "        scatter = sns.scatterplot(\n",
    "            data=acq_data, x='fd_mean', y='tedana_minus_base',\n",
    "            hue='headcoil', palette=colors, ax=ax, s=300\n",
    "        )\n",
    "        if i == 0:\n",
    "            legend_handles = scatter.legend_.legendHandles\n",
    "        for hc in [20, 64]:\n",
    "            hc_data = acq_data[acq_data['headcoil'] == hc]\n",
    "            if len(hc_data) > 1:\n",
    "                sns.regplot(x='fd_mean', y='tedana_minus_base', data=hc_data,\n",
    "                            scatter=False, ax=ax, color=colors[hc], line_kws={'linewidth': 3})\n",
    "        ax.set_title(f'{acq}', fontsize=64, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(f'{mask_value}\\n{denoise_tedana} - {denoise_base}', fontsize=56)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.tick_params(axis='both', which='major', labelsize=56)\n",
    "        ax.legend().remove()\n",
    "        ax.set_xlabel('')\n",
    "    \n",
    "    fig.text(0.5, -0.02, 'Mean Framewise Displacement', ha='center', fontsize=56)\n",
    "    plt.subplots_adjust(right=0.8)\n",
    "    fig.legend(legend_handles, ['20', '64'], title='Headcoil',\n",
    "               loc='center left', bbox_to_anchor=(1, 0.5), fontsize=28, title_fontsize=28)\n",
    "    \n",
    "    fig2, axes2 = plt.subplots(1, len(acq_params), figsize=(24, 8), sharey=True)\n",
    "    for i, acq in enumerate(acq_params):\n",
    "        ax2 = axes2[i]\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "        sns.scatterplot(\n",
    "            data=acq_data, x='fd_mean', y='tedana_minus_base',\n",
    "            color='blue', ax=ax2, s=300\n",
    "        )\n",
    "        if len(acq_data) > 1:\n",
    "            sns.regplot(x='fd_mean', y='tedana_minus_base', data=acq_data,\n",
    "                        scatter=False, ax=ax2, color='blue', line_kws={'linewidth': 3})\n",
    "        ax2.set_title(f'{acq}', fontsize=64, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax2.set_ylabel(f'{mask_value}\\n{denoise_tedana} - {denoise_base}', fontsize=56)\n",
    "        else:\n",
    "            ax2.set_ylabel('')\n",
    "        ax2.tick_params(axis='both', which='major', labelsize=56)\n",
    "        ax2.set_xlabel('')\n",
    "    \n",
    "    fig2.text(0.5, -0.02, 'Mean Framewise Displacement', ha='center', fontsize=56)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, fig2\n",
    "\n",
    "def process_and_visualize_tedana_difference(type_value, img_value, mask_value, denoise_tedana, denoise_base, \n",
    "                                           base_dir=None, fd_csv_path=None, acq_params=None, \n",
    "                                           headcoil_64_subjects=None, save_files=True):\n",
    "    \"\"\"Run the full analysis for tedana-base difference visualization\"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    if fd_csv_path is None:\n",
    "        fd_csv_path = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "    if acq_params is None:\n",
    "        acq_params = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "    if headcoil_64_subjects is None:\n",
    "        headcoil_64_subjects = [\n",
    "            \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "            \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "            \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "            \"10186\", \"10188\", \"10221\"\n",
    "        ]\n",
    "    \n",
    "    # Process fd_mean data\n",
    "    input_file = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/Task-sharedreward_Level-Acq_Outlier-info_mriqc-0.16.1.tsv\")\n",
    "    output_csv = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "    output_excel = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_averages.xlsx\")\n",
    "    process_fd_mean_data(input_file, output_csv, output_excel)\n",
    "    \n",
    "    # Initialize plotting\n",
    "    initialize_plotting_engine()\n",
    "    \n",
    "    print(f\"\\nProcessing files for tedana - base difference: type={type_value}, img={img_value}, mask={mask_value}\")\n",
    "    \n",
    "    # Extract data and calculate differences\n",
    "    diff_by_subject = extract_file_data_with_difference(\n",
    "        base_dir, type_value, img_value, mask_value, denoise_tedana, denoise_base, acq_params\n",
    "    )\n",
    "    \n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return None\n",
    "    \n",
    "    # Create and merge DataFrame with FD data\n",
    "    df = create_dataframe_with_fd(diff_by_subject, fd_csv_path, acq_params, headcoil_64_subjects)\n",
    "    \n",
    "    if save_files:\n",
    "        output_file = f\"multiecho_tedana_minus_base_{type_value}_{img_value}_{mask_value}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved to {output_file}\")\n",
    "    \n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Create scatter plots\n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig, fig2 = create_scatter_plots(df, acq_params, mask_value, denoise_tedana, denoise_base)\n",
    "    \n",
    "    if save_files:\n",
    "        plot_file = f\"tedana_minus_base_scatter_{type_value}_{img_value}_{mask_value}.png\"\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return {\n",
    "        'dataframe': df,\n",
    "        'figure': (fig, fig2)\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example parameters (can be modified as needed)\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"zstat\"\n",
    "    MASK_VALUE = \"VSconstrained\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb8e06-bbfa-42a4-a751-4b6000c60a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8. VSconstrained\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters that can be changed to repurpose the script\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"zstat\"\n",
    "    MASK_VALUE = \"VSconstrained\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da57571-2f17-4127-b4a0-acbcdad242f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8. VMPFC\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters that can be changed to repurpose the script\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"zstat\"\n",
    "    MASK_VALUE = \"VMPFC\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16f0ec-819d-444f-8c1b-756be51cbaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8. rFFA\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters that can be changed to repurpose the script\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"zstat\"\n",
    "    MASK_VALUE = \"rFFA\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd53581-d892-494d-9fd8-39d72e5b23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8. bilateralMotor\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters that can be changed to repurpose the script\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"zstat\"\n",
    "    MASK_VALUE = \"bilateralMotor\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ed0fd-85ea-4f8c-85cd-d47335bd35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8. bilateralCerebellum\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters that can be changed to repurpose the script\n",
    "    TYPE_VALUE = \"act\"\n",
    "    IMG_VALUE = \"zstat\"\n",
    "    MASK_VALUE = \"bilateralCerebellum\"\n",
    "    DENOISE_TEDANA = \"tedana\"\n",
    "    DENOISE_BASE = \"base\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    result = process_and_visualize_tedana_difference(\n",
    "        TYPE_VALUE, IMG_VALUE, MASK_VALUE, DENOISE_TEDANA, DENOISE_BASE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9794dd1-c7eb-44a7-900c-89123c72c1b7",
   "metadata": {},
   "source": [
    "# Fig 9. Bar Plot Analysis of fMRI Metrics for Specific Subjects\n",
    "\n",
    "This code chunk defines functions to extract, process, and visualize fMRI metric data (e.g., beta values) from text files for a subset of subjects (those with `sp` in their IDs) across specified multiecho acquisition parameters (e.g., mb1me1, mb3me4). It generates a bar plot summarizing mean values and standard errors for a given region of interest (ROI) and metric, focusing on acquisition effects.\n",
    "\n",
    "### Key Components\n",
    "1. **Data Extraction**:\n",
    "   - `extract_file_data`: \n",
    "     - Scans a directory (e.g., `base_dir`) for text files matching a regex pattern (`ts_sub-<ID>_acq_<...>.txt`).\n",
    "     - Filters files by `type_value` (e.g., `act`), `img_value` (e.g., `beta`), `mask_value` (e.g., `VSconstrained`), `denoise_value` (e.g., `smooth`), and a list of `acq_params`.\n",
    "     - Extracts float values for subjects with `sp` in their IDs, storing data in a dictionary by subject and acquisition.\n",
    "\n",
    "2. **Data Structuring**:\n",
    "   - `create_dataframe`: \n",
    "     - Converts the extracted data into a wide-format DataFrame with columns: `subject` and the specified `acq_params`.\n",
    "     - Sorts by subject ID for consistency.\n",
    "\n",
    "3. **Data Aggregation**:\n",
    "   - `prepare_plot_data`: \n",
    "     - Computes means and standard errors of the metric for each acquisition parameter.\n",
    "     - Returns a dictionary with results and the total subject count.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - `create_bar_plot`: \n",
    "     - Generates a bar plot with lavender bars, showing mean metric values across acquisitions, with error bars (standard errors).\n",
    "     - Customizes aesthetics: large fonts (e.g., title=48, labels=40), rotated x-tick labels, and dynamic y-axis limits.\n",
    "   - Y-axis: Labeled with the ROI and metric (e.g., `VSconstrained, beta`); X-axis: Acquisition types.\n",
    "\n",
    "5. **Execution**:\n",
    "   - `process_and_visualize`: \n",
    "     - Runs the full pipeline: extracts data, creates a DataFrame, prepares plot data, and generates the bar plot.\n",
    "     - Saves the DataFrame as a CSV and the plot as a PNG with descriptive filenames.\n",
    "\n",
    "### Inputs\n",
    "- `base_dir`: Directory containing fMRI text files (e.g., `~/Documents/GitHub/multiecho-pilot/derivatives/extractions`).\n",
    "- `acq_params`: List of acquisitions (e.g., `[\"mb1me1\", \"mb3me4\", \"mb6me4\"]`).\n",
    "- `type_value`: Analysis type (e.g., `act` for activation).\n",
    "- `img_value`: Metric to analyze (e.g., `beta`).\n",
    "- `mask_value`: ROI (e.g., `VSconstrained`).\n",
    "- `denoise_value`: Denoising method (e.g., `smooth`).\n",
    "\n",
    "### Outputs\n",
    "- **DataFrame**: Saved as `multiecho_data_<type>_<img>_<mask>_<denoise>.csv`, with subject IDs and metric values per acquisition.\n",
    "- **Plot**: Bar plot saved as `multiecho_plots_<type>_<img>_<mask>_<denoise>.png`, showing means and errors across acquisitions.\n",
    "- **Returns**: Processed DataFrame and matplotlib figure object.\n",
    "\n",
    "### Notes\n",
    "- Only processes subjects with `sp` in their IDs (e.g., special pilot subjects), excluding others.\n",
    "- Handles missing or invalid files by skipping them and reporting errors, with NaNs for unmatched acquisitions.\n",
    "- Plot design (lavender bars, whitegrid style) is optimized for clarity and publication quality.\n",
    "- Assumes text files contain a single float value; errors are printed for debugging.\n",
    "\n",
    "This chunk supports Figure 9 by summarizing fMRI metrics for a specific subject group across acquisition types, providing a visual and tabular representation of data quality or effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f7b0ff-9d1d-4d6d-8813-23f0de688782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92cdba-bb11-4a7c-923a-1c86b859710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for Figure 9\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Activate pandas-R conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "base = importr('base')\n",
    "lme4 = importr('lme4')\n",
    "emmeans = importr('emmeans')\n",
    "ggplot2 = importr('ggplot2')\n",
    "\n",
    "def extract_file_data(base_dir, acq_params, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"\n",
    "    Extracts numerical data from text files matching specified parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_dir: Path to the directory containing text files.\n",
    "    - acq_params: List of acquisition parameters to include.\n",
    "    - type_value, img_value, mask_value, denoise_value: Filtering criteria for filenames.\n",
    "    \n",
    "    Returns:\n",
    "    - data_by_subject: Dictionary with subjects as keys and acquisition data as values.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+[a-zA-Z]*)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "\n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    matched_files = 0\n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' not in sub_id:\n",
    "                continue\n",
    "            if (file_type.lower() == type_value.lower() and \n",
    "                img.lower() == img_value.lower() and \n",
    "                mask.lower() == mask_value.lower() and \n",
    "                denoise.lower() == denoise_value.lower() and \n",
    "                acq in acq_params):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    matched_files += 1\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "    print(f\"Total matched files: {matched_files}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, acq_params):\n",
    "    \"\"\"\n",
    "    Converts extracted data into a structured DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data_by_subject: Dictionary with extracted numerical values.\n",
    "    - acq_params: List of acquisition parameters (column order).\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame with subject IDs and extracted values.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index').reset_index()\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    column_order = ['subject'] + acq_params\n",
    "    df = df[column_order].sort_values('subject')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_plot_data(df, acq_params):\n",
    "    \"\"\"\n",
    "    Computes means and standard errors for each acquisition parameter.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing extracted values.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "\n",
    "    Returns:\n",
    "    - results: Dictionary with mean values, errors, and subject count.\n",
    "    \"\"\"\n",
    "    means = {acq: df[acq].mean() for acq in acq_params}\n",
    "    errors = {acq: df[acq].sem() for acq in acq_params}\n",
    "    return {'means': means, 'errors': errors, 'count': len(df)}\n",
    "\n",
    "def create_bar_plot(plot_data, acq_params, title, y_label):\n",
    "    \"\"\"\n",
    "    Creates a formatted bar plot with error bars.\n",
    "\n",
    "    Parameters:\n",
    "    - plot_data: Dictionary with mean values, errors, and subject count.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    - title: Plot title.\n",
    "    - y_label: Y-axis label.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The created matplotlib figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "\n",
    "    means = [plot_data['means'][acq] for acq in acq_params]\n",
    "    errors = [plot_data['errors'][acq] for acq in acq_params]\n",
    "    \n",
    "    x_positions = np.arange(len(acq_params))\n",
    "    ax.bar(x_positions, means, color='lavender', yerr=errors, capsize=5, width=0.8)\n",
    "\n",
    "    ax.set_ylabel(y_label, fontsize=40)\n",
    "    ax.set_title(title, fontsize=48, fontweight='bold')\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(acq_params, fontsize=32, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Acquisition', fontsize=40)\n",
    "    ax.tick_params(axis='both', labelsize=32)\n",
    " \n",
    "    # Adjust y-axis limits dynamically\n",
    "    y_min = min([v - e for v, e in zip(means, errors) if not np.isnan(v)])\n",
    "    y_max = max([v + e for v, e in zip(means, errors) if not np.isnan(v)])\n",
    "    margin = (y_max - y_min) * 0.1\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plot(emm_df, mask_value, output_dir, type_value, img_value, denoise_value):\n",
    "    \"\"\"\n",
    "    Create a line plot for estimated marginal means and save as PNG.\n",
    "\n",
    "    Parameters:\n",
    "    - emm_df: DataFrame with EMM data.\n",
    "    - mask_value: Mask value for labeling.\n",
    "    - output_dir: Directory to save the plot.\n",
    "    - type_value, img_value, denoise_value: Parameters for filename.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The created matplotlib figure.\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Define colors for each acquisition parameter\n",
    "    # Define colors for each acquisition parameter\n",
    "    acq_params = sorted(emm_df['acq'].unique())\n",
    "    custom_labels = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "    lavender_color = '#800080'\n",
    "\n",
    "    # Plot EMMs for each acquisition parameter\n",
    "    for acq in acq_params:\n",
    "        acq_data = emm_df[emm_df['acq'] == acq]\n",
    "        if not acq_data.empty:\n",
    "            emmean = acq_data['emmean'].values[0]\n",
    "            se = acq_data['SE'].values[0]\n",
    "            x_pos = acq_params.index(acq)\n",
    "            ax.errorbar([x_pos], [emmean], yerr=[se], fmt='o', color=lavender_color, capsize=8, capthick=4, elinewidth=3, markersize=15)\n",
    "\n",
    "    # Connect points with a line\n",
    "    x_positions = np.arange(len(acq_params))\n",
    "    emmeans = [emm_df[emm_df['acq'] == acq]['emmean'].values[0] for acq in acq_params]\n",
    "    ax.plot(x_positions, emmeans, color=lavender_color, linewidth=5, linestyle='-')\n",
    "\n",
    "    # Set labels and ticks\n",
    "    ax.set_title(f\"SP Subjects (n={emm_df['df'].iloc[0]:.0f})\", fontsize=56, fontweight='bold')\n",
    "    ax.set_ylabel(f\"{mask_value} EMMs\", fontsize=56)\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(custom_labels, fontsize=32, rotation=45, ha='right')\n",
    "    ax.set_xlabel(\"Acquisition\", fontsize=40)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=32)\n",
    "\n",
    "    # Revised y-limit logic to prevent cutting off error bars\n",
    "    y_values = emm_df['emmean'].values\n",
    "    y_errors = emm_df['SE'].values\n",
    "    if y_values.size > 0:\n",
    "        y_upper = max(y_values + y_errors)\n",
    "        y_lower = min(y_values - y_errors)\n",
    "        padding = (y_upper - y_lower) * 0.1\n",
    "        ax.set_ylim(y_lower - padding, y_upper + padding)\n",
    "    else:\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if output_dir:\n",
    "        plot_file = os.path.join(output_dir, f\"emm_plot_{type_value}_{img_value}_{mask_value}_{denoise_value}.png\")\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"EMM plot saved as '{plot_file}'\")\n",
    "    plt.close()  # Close the figure to prevent rendering in the notebook\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize(base_dir, acq_params, type_value, img_value, mask_value, denoise_value, output_dir=\"../derivatives/plots\"):\n",
    "    \"\"\"\n",
    "    Full pipeline to extract, process, visualize data, and perform statistical analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - base_dir: Path to data files.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    - type_value, img_value, mask_value, denoise_value: Filtering criteria.\n",
    "    - output_dir: Directory to save outputs.\n",
    "\n",
    "    Returns:\n",
    "    - df: Processed DataFrame.\n",
    "    - fig: Bar plot figure.\n",
    "    - emm_fig: EMM plot figure.\n",
    "    - lmm_result: Linear mixed-effects model result.\n",
    "    \"\"\"\n",
    "    print(f\"Processing files with parameters: type={type_value}, img={img_value}, mask={mask_value}, denoise={denoise_value}\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract data\n",
    "    data_by_subject = extract_file_data(base_dir, acq_params, type_value, img_value, mask_value, denoise_value)\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return pd.DataFrame(columns=['subject'] + acq_params), plt.figure(), plt.figure(), None\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject, acq_params)\n",
    "    output_file = os.path.join(output_dir, f\"multiecho_data_{type_value}_{img_value}_{mask_value}_{denoise_value}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    print(f\"Missing values per column:\\n{df.isnull().sum()}\")\n",
    "\n",
    "    # Reshape data for statistical analysis\n",
    "    df_long = pd.melt(\n",
    "        df, \n",
    "        id_vars=['subject'], \n",
    "        value_vars=acq_params,\n",
    "        var_name='acq', \n",
    "        value_name=img_value\n",
    "    )\n",
    "    df_long['acq'] = pd.Categorical(df_long['acq'], categories=acq_params, ordered=True)\n",
    "\n",
    "    # Run Python-based linear mixed-effects model\n",
    "    print(f\"\\nRunning statistical analysis for {mask_value} ({img_value})...\")\n",
    "    df_long_clean = df_long.dropna(subset=[img_value])\n",
    "    if len(df_long_clean) < 2:\n",
    "        print(f\"Insufficient data for LMM after removing NaNs: {len(df_long_clean)} observations\")\n",
    "        result = None\n",
    "    else:\n",
    "        try:\n",
    "            model = smf.mixedlm(f\"{img_value} ~ acq\", df_long_clean, groups=df_long_clean[\"subject\"])\n",
    "            result = model.fit()\n",
    "            print(result.summary())\n",
    "            \n",
    "            # Pairwise comparisons for acq\n",
    "            print(f\"\\nPairwise comparisons for acquisition parameters:\")\n",
    "            tukey_acq = pairwise_tukeyhsd(endog=df_long_clean[img_value], groups=df_long_clean['acq'], alpha=0.05)\n",
    "            print(tukey_acq)\n",
    "        except Exception as e:\n",
    "            print(f\"LMM failed: {e}\")\n",
    "            print(f\"Shape of df_long_clean: {df_long_clean.shape}\")\n",
    "            print(f\"Missing values in df_long_clean:\\n{df_long_clean.isnull().sum()}\")\n",
    "            result = None\n",
    "\n",
    "    # Run R-based EMM analysis\n",
    "    print(f\"\\nRunning R-based EMM analysis for {mask_value} ({img_value})...\")\n",
    "    emm_fig = None\n",
    "    if len(df_long_clean) >= 2:\n",
    "        try:\n",
    "            # Convert to R dataframe\n",
    "            rdf = pandas2ri.py2rpy(df_long_clean)\n",
    "            ro.globalenv['rdf'] = rdf\n",
    "            ro.globalenv['img_value'] = img_value\n",
    "            \n",
    "            # Fit model and compute EMMs in R\n",
    "            ro.r('''\n",
    "            library(lme4)\n",
    "            library(emmeans)\n",
    "            \n",
    "            rdf$subject <- as.factor(rdf$subject)\n",
    "            rdf$acq <- factor(rdf$acq, levels = c(\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"))\n",
    "            \n",
    "            formula_str <- paste(img_value, \"~ acq + (1 | subject)\")\n",
    "            model <- lmer(as.formula(formula_str), data = rdf)\n",
    "            \n",
    "            emm <- emmeans(model, ~ acq)\n",
    "            emm_df <- as.data.frame(emm)\n",
    "            ''')\n",
    "            \n",
    "            # Retrieve EMM data\n",
    "            emm_r_df = ro.globalenv['emm_df']\n",
    "            emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "            \n",
    "            # Verify EMM data\n",
    "            print(f\"Debug: emm_df shape: {emm_df.shape}\")\n",
    "            print(f\"Debug: emm_df columns: {emm_df.columns.tolist()}\")\n",
    "            print(f\"Debug: emm_df head:\\n{emm_df.head()}\")\n",
    "            \n",
    "            # Create EMM line plot\n",
    "            emm_fig = create_emm_line_plot(emm_df, mask_value, output_dir, type_value, img_value, denoise_value)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"R-based EMM analysis failed: {e}\")\n",
    "\n",
    "    # Create bar plot\n",
    "    print(\"\\nCreating bar plot...\")\n",
    "    plot_data = prepare_plot_data(df, acq_params)\n",
    "    fig = create_bar_plot(plot_data, acq_params, f\"SP Subjects (n={plot_data['count']})\", f'{mask_value}, {img_value}')\n",
    "\n",
    "    plot_file = os.path.join(output_dir, f\"multiecho_plots_{type_value}_{img_value}_{mask_value}_{denoise_value}.png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Bar plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig, emm_fig, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87184f7a-2b0b-4299-ba34-c0e97321bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for Figure 9\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from rpy2.robjects import pandas2ri, Formula\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Activate pandas-R conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Import R packages\n",
    "base = importr('base')\n",
    "lme4 = importr('lme4')\n",
    "emmeans = importr('emmeans')\n",
    "ggplot2 = importr('ggplot2')\n",
    "\n",
    "def extract_file_data(base_dir, acq_params, type_value, img_value, mask_value, denoise_value):\n",
    "    \"\"\"\n",
    "    Extracts numerical data from text files matching specified parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - base_dir: Path to the directory containing text files.\n",
    "    - acq_params: List of acquisition parameters to include.\n",
    "    - type_value, img_value, mask_value, denoise_value: Filtering criteria for filenames.\n",
    "    \n",
    "    Returns:\n",
    "    - data_by_subject: Dictionary with subjects as keys and acquisition data as values.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+[a-zA-Z]*)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "\n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(base_dir, \"*.txt\"))\n",
    "    \n",
    "    matched_files = 0\n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' not in sub_id:\n",
    "                continue\n",
    "            if (file_type.lower() == type_value.lower() and \n",
    "                img.lower() == img_value.lower() and \n",
    "                mask.lower() == mask_value.lower() and \n",
    "                denoise.lower() == denoise_value.lower() and \n",
    "                acq in acq_params):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in acq_params}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    matched_files += 1\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "    print(f\"Total matched files: {matched_files}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject, acq_params):\n",
    "    \"\"\"\n",
    "    Converts extracted data into a structured DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data_by_subject: Dictionary with extracted numerical values.\n",
    "    - acq_params: List of acquisition parameters (column order).\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame with subject IDs and extracted values.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index').reset_index()\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    column_order = ['subject'] + acq_params\n",
    "    df = df[column_order].sort_values('subject')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_plot_data(df, acq_params):\n",
    "    \"\"\"\n",
    "    Computes means and standard errors for each acquisition parameter.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing extracted values.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "\n",
    "    Returns:\n",
    "    - results: Dictionary with mean values, errors, and subject count.\n",
    "    \"\"\"\n",
    "    means = {acq: df[acq].mean() for acq in acq_params}\n",
    "    errors = {acq: df[acq].sem() for acq in acq_params}\n",
    "    return {'means': means, 'errors': errors, 'count': len(df)}\n",
    "\n",
    "def create_bar_plot(plot_data, acq_params, title, y_label):\n",
    "    \"\"\"\n",
    "    Creates a formatted bar plot with error bars.\n",
    "\n",
    "    Parameters:\n",
    "    - plot_data: Dictionary with mean values, errors, and subject count.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    - title: Plot title.\n",
    "    - y_label: Y-axis label.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The created matplotlib figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "\n",
    "    means = [plot_data['means'][acq] for acq in acq_params]\n",
    "    errors = [plot_data['errors'][acq] for acq in acq_params]\n",
    "    \n",
    "    x_positions = np.arange(len(acq_params))\n",
    "    ax.bar(x_positions, means, color='lavender', yerr=errors, capsize=5, width=0.8)\n",
    "\n",
    "    ax.set_ylabel(y_label, fontsize=40)\n",
    "    ax.set_title(title, fontsize=48, fontweight='bold')\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(acq_params, fontsize=32, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Acquisition', fontsize=40)\n",
    "    ax.tick_params(axis='both', labelsize=32)\n",
    "\n",
    "    # Adjust y-axis limits dynamically\n",
    "    y_min = min([v - e for v, e in zip(means, errors) if not np.isnan(v)])\n",
    "    y_max = max([v + e for v, e in zip(means, errors) if not np.isnan(v)])\n",
    "    margin = (y_max - y_min) * 0.1\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def create_emm_line_plot(emm_df, mask_value, output_dir, type_value, img_value, denoise_value):\n",
    "    \"\"\"\n",
    "    Create a line plot for estimated marginal means and save as PNG.\n",
    "\n",
    "    Parameters:\n",
    "    - emm_df: DataFrame with EMM data.\n",
    "    - mask_value: Mask value for labeling.\n",
    "    - output_dir: Directory to save the plot.\n",
    "    - type_value, img_value, denoise_value: Parameters for filename.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The created matplotlib figure.\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({'font.size': 56})\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Define colors for each acquisition parameter\n",
    "    acq_params = sorted(emm_df['acq'].unique())\n",
    "    custom_labels = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "    lavender_color = '#800080'\n",
    "\n",
    "    # Plot EMMs for each acquisition parameter\n",
    "    for acq in acq_params:\n",
    "        acq_data = emm_df[emm_df['acq'] == acq]\n",
    "        if not acq_data.empty:\n",
    "            emmean = acq_data['emmean'].values[0]\n",
    "            se = acq_data['SE'].values[0]\n",
    "            x_pos = acq_params.index(acq)\n",
    "            ax.errorbar([x_pos], [emmean], yerr=[se], fmt='o', color=lavender_color, capsize=8, capthick=4, elinewidth=3, markersize=15)\n",
    "\n",
    "    # Connect points with a line\n",
    "    x_positions = np.arange(len(acq_params))\n",
    "    emmeans = [emm_df[emm_df['acq'] == acq]['emmean'].values[0] for acq in acq_params]\n",
    "    ax.plot(x_positions, emmeans, color=lavender_color, linewidth=5, linestyle='-')\n",
    "\n",
    "    # Set labels and ticks\n",
    "    #ax.set_title(f\"SP Subjects (n={emm_df['df'].iloc[0]:.0f})\", fontsize=56, fontweight='bold')\n",
    "    ax.set_ylabel(f\"{img_value} EMMs\", fontsize=56)\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(custom_labels, fontsize=32, rotation=45, ha='right')\n",
    "    ax.set_xlabel(\"Acquisition\", fontsize=40)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=32)\n",
    "\n",
    "    # Revised y-limit logic to prevent cutting off error bars\n",
    "    y_values = emm_df['emmean'].values\n",
    "    y_errors = emm_df['SE'].values\n",
    "    if y_values.size > 0:\n",
    "        y_upper = max(y_values + y_errors)\n",
    "        y_lower = min(y_values - y_errors)\n",
    "        padding = (y_upper - y_lower) * 0.1\n",
    "        ax.set_ylim(y_lower - padding, y_upper + padding)\n",
    "    else:\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if output_dir:\n",
    "        plot_file = os.path.join(output_dir, f\"emm_plot_{type_value}_{img_value}_{mask_value}_{denoise_value}.png\")\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"EMM plot saved as '{plot_file}'\")\n",
    "    plt.close()  # Close the figure to prevent rendering in the notebook\n",
    "    return fig\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if output_dir:\n",
    "        plot_file = os.path.join(output_dir, f\"emm_plot_{type_value}_{img_value}_{mask_value}_{denoise_value}.png\")\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"EMM plot saved as '{plot_file}'\")\n",
    "    plt.close()  # Close the figure to prevent rendering in the notebook\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize(base_dir, acq_params, type_value, img_value, mask_value, denoise_value, output_dir=\"../derivatives/plots\"):\n",
    "    \"\"\"\n",
    "    Full pipeline to extract, process, visualize data, and perform statistical analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - base_dir: Path to data files.\n",
    "    - acq_params: List of acquisition parameters.\n",
    "    - type_value, img_value, mask_value, denoise_value: Filtering criteria.\n",
    "    - output_dir: Directory to save outputs.\n",
    "\n",
    "    Returns:\n",
    "    - df: Processed DataFrame.\n",
    "    - fig: Bar plot figure.\n",
    "    - emm_fig: EMM plot figure.\n",
    "    - lmm_result: Linear mixed-effects model result.\n",
    "    \"\"\"\n",
    "    print(f\"Processing files with parameters: type={type_value}, img={img_value}, mask={mask_value}, denoise={denoise_value}\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract data\n",
    "    data_by_subject = extract_file_data(base_dir, acq_params, type_value, img_value, mask_value, denoise_value)\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return pd.DataFrame(columns=['subject'] + acq_params), plt.figure(), plt.figure(), None\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject, acq_params)\n",
    "    output_file = os.path.join(output_dir, f\"multiecho_data_{type_value}_{img_value}_{mask_value}_{denoise_value}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    print(f\"Missing values per column:\\n{df.isnull().sum()}\")\n",
    "\n",
    "    # Reshape data for statistical analysis\n",
    "    df_long = pd.melt(\n",
    "        df, \n",
    "        id_vars=['subject'], \n",
    "        value_vars=acq_params,\n",
    "        var_name='acq', \n",
    "        value_name=img_value\n",
    "    )\n",
    "    df_long['acq'] = pd.Categorical(df_long['acq'], categories=acq_params, ordered=True)\n",
    "\n",
    "    # Run Python-based linear mixed-effects model\n",
    "    print(f\"\\nRunning statistical analysis for {mask_value} ({img_value})...\")\n",
    "    df_long_clean = df_long.dropna(subset=[img_value])\n",
    "    if len(df_long_clean) < 2:\n",
    "        print(f\"Insufficient data for LMM after removing NaNs: {len(df_long_clean)} observations\")\n",
    "        result = None\n",
    "    else:\n",
    "        try:\n",
    "            model = smf.mixedlm(f\"{img_value} ~ acq\", df_long_clean, groups=df_long_clean[\"subject\"])\n",
    "            result = model.fit()\n",
    "            print(result.summary())\n",
    "            \n",
    "            # Pairwise comparisons for acq\n",
    "            print(f\"\\nPairwise comparisons for acquisition parameters:\")\n",
    "            tukey_acq = pairwise_tukeyhsd(endog=df_long_clean[img_value], groups=df_long_clean['acq'], alpha=0.05)\n",
    "            print(tukey_acq)\n",
    "        except Exception as e:\n",
    "            print(f\"LMM failed: {e}\")\n",
    "            print(f\"Shape of df_long_clean: {df_long_clean.shape}\")\n",
    "            print(f\"Missing values in df_long_clean:\\n{df_long_clean.isnull().sum()}\")\n",
    "            result = None\n",
    "\n",
    "    # Run R-based EMM analysis\n",
    "    print(f\"\\nRunning R-based EMM analysis for {mask_value} ({img_value})...\")\n",
    "    emm_fig = None\n",
    "    if len(df_long_clean) >= 2:\n",
    "        try:\n",
    "            # Convert to R dataframe\n",
    "            rdf = pandas2ri.py2rpy(df_long_clean)\n",
    "            ro.globalenv['rdf'] = rdf\n",
    "            ro.globalenv['img_value'] = img_value\n",
    "            \n",
    "            # Fit model and compute EMMs in R\n",
    "            ro.r('''\n",
    "            library(lme4)\n",
    "            library(emmeans)\n",
    "            \n",
    "            rdf$subject <- as.factor(rdf$subject)\n",
    "            rdf$acq <- factor(rdf$acq, levels = c(\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"))\n",
    "            \n",
    "            formula_str <- paste(img_value, \"~ acq + (1 | subject)\")\n",
    "            model <- lmer(as.formula(formula_str), data = rdf)\n",
    "            \n",
    "            emm <- emmeans(model, ~ acq)\n",
    "            emm_df <- as.data.frame(emm)\n",
    "            ''')\n",
    "            \n",
    "            # Retrieve EMM data\n",
    "            emm_r_df = ro.globalenv['emm_df']\n",
    "            emm_df = pandas2ri.rpy2py(emm_r_df)\n",
    "            \n",
    "            # Verify EMM data\n",
    "            print(f\"Debug: emm_df shape: {emm_df.shape}\")\n",
    "            print(f\"Debug: emm_df columns: {emm_df.columns.tolist()}\")\n",
    "            print(f\"Debug: emm_df head:\\n{emm_df.head()}\")\n",
    "            \n",
    "            # Create EMM line plot\n",
    "            emm_fig = create_emm_line_plot(emm_df, mask_value, output_dir, type_value, img_value, denoise_value)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"R-based EMM analysis failed: {e}\")\n",
    "\n",
    "    # Create bar plot\n",
    "    print(\"\\nCreating bar plot...\")\n",
    "    plot_data = prepare_plot_data(df, acq_params)\n",
    "    fig = create_bar_plot(plot_data, acq_params, f\"SP Subjects (n={plot_data['count']})\", f'{mask_value}, {img_value}')\n",
    "\n",
    "    plot_file = os.path.join(output_dir, f\"multiecho_plots_{type_value}_{img_value}_{mask_value}_{denoise_value}.png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Bar plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig, emm_fig, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f348f-83c1-4122-902f-f98d129ec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9. Beta estimates for activation for each acquisition in VS for ‘SP’ subjects\n",
    "if __name__ == \"__main__\":\n",
    "    BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    ACQ_PARAMS = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "    \n",
    "    df, fig = process_and_visualize(\n",
    "        base_dir=BASE_DIR, \n",
    "        acq_params=ACQ_PARAMS, \n",
    "        type_value=\"act\", \n",
    "        img_value=\"beta\", \n",
    "        mask_value=\"VSconstrained\", \n",
    "        denoise_value=\"base\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf296cbc-0cf7-46f2-a29a-b5a31b8b16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supp. Figure 9. zstat for activation for each acquisition in VS for ‘SP’ subjects\n",
    "if __name__ == \"__main__\":\n",
    "    BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "    ACQ_PARAMS = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "    \n",
    "    df, fig = process_and_visualize(\n",
    "        base_dir=BASE_DIR, \n",
    "        acq_params=ACQ_PARAMS, \n",
    "        type_value=\"act\", \n",
    "        img_value=\"zstat\", \n",
    "        mask_value=\"VSconstrained\", \n",
    "        denoise_value=\"base\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb356244-01b2-4cb3-a804-9fdb63e8cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
