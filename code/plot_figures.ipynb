{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2421219-ea75-4306-8b8f-706460fd1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS Act, Rew>Pun, Beta\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"act\"  # e.g., \"act\"\n",
    "IMG_VALUE = \"beta\"  # e.g., \"beta\"\n",
    "MASK_VALUE = \"VS_constrained\"   # e.g., \"VS\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-([^_]+)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VS Act, Rew>Pun (Beta)', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bcb78-4ad7-4802-bcd7-0a6b43793bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS Act, Rew>Pun, zstat\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"act\"  # e.g., \"act\"\n",
    "IMG_VALUE = \"zstat\"  # e.g., \"beta\"\n",
    "MASK_VALUE = \"VS\"   # e.g., \"VS\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-([^_]+)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VS Act, Rew>Pun (zstat)', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c5991-3e98-46ba-8c6e-0de7ec75d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS TSNR, Rew>Pun\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"act\"  # e.g., \"act\"\n",
    "IMG_VALUE = \"tsnr\"  # e.g., \"beta\"\n",
    "MASK_VALUE = \"VS\"   # e.g., \"VS\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-([^_]+)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VS TSNR, Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f7509-3a85-4b60-bfa1-3f6e96f826e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC TSNR\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"act\"  # e.g., \"act\"\n",
    "IMG_VALUE = \"tsnr\"  # e.g., \"beta\"\n",
    "MASK_VALUE = \"VMPFC\"   # e.g., \"VS\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-([^_]+)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VMPFC TSNR, Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a234b-81ac-4fec-b13c-df1483e35622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC Act Rew>Pun, Beta\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"act\"  # e.g., \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\"  # e.g., \"beta\" \"zstat\" \"tsnr\"\n",
    "MASK_VALUE = \"VMPFC\"   # e.g., \"VS\" \"VMPFC\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\" \"tedana\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-([^_]+)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VMPFC Beta, Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5aa8bd-8116-42ca-8c7c-9ccacd2b6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC Act Rew>Pun, zstat\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"act\"  # e.g., \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"zstat\"  # e.g., \"beta\" \"zstat\" \"tsnr\"\n",
    "MASK_VALUE = \"VMPFC\"   # e.g., \"VS\" \"VMPFC\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\" \"tedana\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-([^_]+)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VMPFC zstat, Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47035673-a2b4-46aa-ab9b-4f38e8e688cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS PPI Rew>Pun, beta\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\"  # e.g., \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\"  # e.g., \"beta\" \"zstat\" \"tsnr\"\n",
    "MASK_VALUE = \"VS\"   # e.g., \"VS\" \"VMPFC\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\" \"tedana\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    #print(\"Found files:\", [os.path.basename(f) for f in file_paths]) # Debug line\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            #print(f\"Matched: {filename} -> type={file_type}\") # Debug line\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VS beta (PPI), Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        print(\"Debug: data_by_subject =\", data_by_subject)  # Check its contents\n",
    "\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8fa2d-273a-4769-81ac-daa7f404e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS PPI Rew>Pun, zstat\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\"  # e.g., \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"zstat\"  # e.g., \"beta\" \"zstat\" \"tsnr\"\n",
    "MASK_VALUE = \"VS\"   # e.g., \"VS\" \"VMPFC\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\" \"tedana\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    #print(\"Found files:\", [os.path.basename(f) for f in file_paths]) # Debug line\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            #print(f\"Matched: {filename} -> type={file_type}\") # Debug line\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VS zstat (PPI), Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        print(\"Debug: data_by_subject =\", data_by_subject)  # Check its contents\n",
    "\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835e73d-aea4-4266-836b-ff32977f06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC PPI Rew>Pun, beta\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\"  # e.g., \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\"  # e.g., \"beta\" \"zstat\" \"tsnr\"\n",
    "MASK_VALUE = \"VMPFC\"   # e.g., \"VS\" \"VMPFC\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\" \"tedana\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    #print(\"Found files:\", [os.path.basename(f) for f in file_paths]) # Debug line\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            #print(f\"Matched: {filename} -> type={file_type}\") # Debug line\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VMPFC beta (PPI), Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        print(\"Debug: data_by_subject =\", data_by_subject)  # Check its contents\n",
    "\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39efe77-3e45-4e19-8df0-4c60b136f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC PPI Rew>Pun, zstat\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters that can be changed to repurpose the script\n",
    "# Change these values to match the files you want to process\n",
    "TYPE_VALUE = \"ppi_seed-VS_thr5\"  # e.g., \"act\" \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"zstat\"  # e.g., \"beta\" \"zstat\" \"tsnr\"\n",
    "MASK_VALUE = \"VMPFC\"   # e.g., \"VS\" \"VMPFC\"\n",
    "DENOISE_VALUE = \"base\"  # e.g., \"base\" \"tedana\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# List of all expected acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me1\", \"mb3me1\", \"mb6me1\", \"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil value of 64 (all others will be 20)\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data():\n",
    "    # Pattern to match filenames and extract parameters\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store data by subject\n",
    "    data_by_subject = {}\n",
    "    \n",
    "    # Find all text files in the directory\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    #print(\"Found files:\", [os.path.basename(f) for f in file_paths]) # Debug line\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            #print(f\"Matched: {filename} -> type={file_type}\") # Debug line\n",
    "            \n",
    "            # Skip subjects with 'sp' in their ID\n",
    "            if 'sp' in sub_id:\n",
    "                continue\n",
    "                \n",
    "            # Check if this file matches our target parameters\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE \n",
    "                and mask == MASK_VALUE and denoise == DENOISE_VALUE):\n",
    "                \n",
    "                # Read the value from the file\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        value = float(f.read().strip())\n",
    "                        \n",
    "                    # Initialize subject data if not already present\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    \n",
    "                    # Store the value\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    \n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    \n",
    "    # Reset index to make subject ID a column and rename it\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    # Add headcoil column\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    \n",
    "    # Reorder columns to ensure correct order (subject, headcoil, then acquisition parameters)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Sort by subject ID (as integers)\n",
    "    df['subject'] = df['subject'].astype(int)\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(df):\n",
    "    # Split by headcoil type\n",
    "    df_20 = df[df['headcoil'] == 20]\n",
    "    df_64 = df[df['headcoil'] == 64]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for hc_name, hc_df in [('20', df_20), ('64', df_64)]:\n",
    "        # Calculate means and standard errors for each acquisition\n",
    "        means = {}\n",
    "        errors = {}\n",
    "        \n",
    "        for acq in ACQ_PARAMS:\n",
    "            means[acq] = hc_df[acq].mean()\n",
    "            errors[acq] = hc_df[acq].sem()  # Standard error of the mean\n",
    "        \n",
    "        results[hc_name] = {\n",
    "            'means': means,\n",
    "            'errors': errors,\n",
    "            'count': len(hc_df)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to create the bar plots\n",
    "def create_bar_plots(plot_data):\n",
    "    # Set up figure and font sizes\n",
    "    plt.rcParams.update({'font.size': 14})  # Increase base font size\n",
    "    \n",
    "    # Set up the figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")  # Larger context for bigger fonts\n",
    "    \n",
    "    # Define the x positions for the bars - make them closer together\n",
    "    width = 0.4  # Increased width for thicker bars\n",
    "    \n",
    "    # Colors\n",
    "    me1_color = 'royalblue'\n",
    "    me4_color = 'darkorange'\n",
    "    \n",
    "    # Separate the means and errors for easier plotting\n",
    "    for i, (hc, ax, title) in enumerate([('20', ax1, 'Headcoil 20'), ('64', ax2, 'Headcoil 64')]):\n",
    "        data = plot_data[hc]\n",
    "        means = data['means']\n",
    "        errors = data['errors']\n",
    "        count = data['count']\n",
    "        \n",
    "        # Create two sets of bars (me1 and me4)\n",
    "        me1_means = [means['mb1me1'], means['mb3me1'], means['mb6me1']]\n",
    "        me1_errors = [errors['mb1me1'], errors['mb3me1'], errors['mb6me1']]\n",
    "        \n",
    "        me4_means = [means['mb1me4'], means['mb3me4'], means['mb6me4']]\n",
    "        me4_errors = [errors['mb1me4'], errors['mb3me4'], errors['mb6me4']]\n",
    "        \n",
    "        # Update x positions to have bars touching\n",
    "        x1 = [0, 2, 4]  # Positions for me1 bars\n",
    "        x2 = [0+width, 2+width, 4+width]  # Positions for me4 bars\n",
    "        \n",
    "        # Plot the bars\n",
    "        ax.bar(x1, me1_means, width, color=me1_color, label='me1', yerr=me1_errors, capsize=5)\n",
    "        ax.bar(x2, me4_means, width, color=me4_color, label='me4', yerr=me4_errors, capsize=5)\n",
    "        \n",
    "        # Set labels and title with increased font size\n",
    "        ax.set_ylabel('VMPFC zstat (PPI), Rew>Pun', fontsize=16)\n",
    "        ax.set_title(f\"{title} (n={count})\", fontsize=18, fontweight='bold')\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks([width/2, 2+width/2, 4+width/2])  # Center ticks between each pair of bars\n",
    "        ax.set_xticklabels(['mb1', 'mb3', 'mb6'], fontsize=16)\n",
    "        ax.set_xlabel('Multiband Factor', fontsize=16)\n",
    "        \n",
    "        # Increase tick label font size\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        # Add a legend with increased font size\n",
    "        legend = ax.legend(['me1', 'me4'], title='Multi-echo', fontsize=14)\n",
    "        legend.get_title().set_fontsize(16)\n",
    "        \n",
    "        # Set y-limit to start slightly below the minimum value\n",
    "        y_values = me1_means + me4_means\n",
    "        y_errors = me1_errors + me4_errors\n",
    "        \n",
    "        y_min = min([v-e for v, e in zip(y_values, y_errors)])\n",
    "        y_max = max([v+e for v, e in zip(y_values, y_errors)])\n",
    "        \n",
    "        margin = (y_max - y_min) * 0.1\n",
    "        ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    # Extract data from files\n",
    "    data_by_subject = extract_file_data()\n",
    "    \n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        print(\"Debug: data_by_subject =\", data_by_subject)  # Check its contents\n",
    "\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = create_dataframe(data_by_subject)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = f\"multiecho_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df)} subjects\")\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(\"\\nSample of the data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Count headcoil types\n",
    "    headcoil_counts = df['headcoil'].value_counts()\n",
    "    print(\"\\nHeadcoil counts:\")\n",
    "    print(f\"64-channel: {headcoil_counts.get(64, 0)}\")\n",
    "    print(f\"20-channel: {headcoil_counts.get(20, 0)}\")\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    plot_data = prepare_plot_data(df)\n",
    "    \n",
    "    # Create and save bar plots\n",
    "    print(\"\\nCreating bar plots...\")\n",
    "    fig = create_bar_plots(plot_data)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_file = f\"multiecho_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865e823-11ba-4c87-82c6-ce0381ccf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate avg fd_mean values for each ME acq\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "input_file = \"~/Documents/GitHub/multiecho-pilot/derivatives/Task-sharedreward_Level-Acq_Outlier-info_mriqc-0.16.1.tsv\"\n",
    "output_file = \"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\"\n",
    "\n",
    "# Load the TSV file\n",
    "df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "# Filter out subjects ending in 'sp' and acquisitions containing 'me1'\n",
    "df = df[~df['Sub'].str.endswith('sp')]\n",
    "df = df[~df['acq'].str.contains('me1', na=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "#print(\"Filtered data saved to:\", output_file)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your spreadsheet data\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Extract the base 'acq' substring (e.g., mb1me4, mb3me4, mb6me4) from the 'acq' column\n",
    "df['acq_base'] = df['acq'].str.extract(r'(mb\\dme4)')\n",
    "\n",
    "# Group by 'Sub' and 'acq_base' and calculate the average of 'fd_mean' for each group\n",
    "averages = df.groupby(['Sub', 'acq_base'])['fd_mean'].mean().reset_index()\n",
    "\n",
    "# Save the results to a new spreadsheet\n",
    "output_file_path = 'fd_mean_averages.xlsx'  # Replace with your desired output file path\n",
    "averages.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Optionally, print the averages to verify\n",
    "print(averages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee07de-0c75-491f-9357-08b755b0def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC PPI Rew>Pun, zstat (tedana - base difference) with fd_mean scatterplots\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters for this analysis (set to your current values)\n",
    "TYPE_VALUE = \"act\"    # Changed from \"ppi_seed-VS_thr5\"\n",
    "IMG_VALUE = \"beta\"    # Changed from \"zstat\"\n",
    "MASK_VALUE = \"VS\"     # Changed from \"VMPFC\"\n",
    "DENOISE_TEDANA = \"tedana\"\n",
    "DENOISE_BASE = \"base\"\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "FD_CSV_PATH = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "\n",
    "# Multi-echo acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil 64\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data_with_difference():\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {BASE_DIR}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in ACQ_PARAMS:\n",
    "                continue\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE and mask == MASK_VALUE and \n",
    "                denoise in [DENOISE_TEDANA, DENOISE_BASE]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        print(f\"Reading {filename}: raw content = '{raw_content}'\")\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                            for denoise in [DENOISE_TEDANA, DENOISE_BASE]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                    print(f\"Stored: {filename} -> {value}\")\n",
    "                except ValueError as e:\n",
    "                    print(f\"ValueError converting '{raw_content}' to float in {filename}: {e}\")\n",
    "                except IOError as e:\n",
    "                    print(f\"IOError reading {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Subjects with data: {len(data_by_subject)}\")\n",
    "    if data_by_subject:\n",
    "        print(\"Sample of data_by_subject:\")\n",
    "        for sub_id, data in list(data_by_subject.items())[:2]:\n",
    "            print(f\"Subject {sub_id}: {data}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in ACQ_PARAMS:\n",
    "            tedana_val = data[DENOISE_TEDANA].get(acq, np.nan)\n",
    "            base_val = data[DENOISE_BASE].get(acq, np.nan)\n",
    "            diff = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "            diff_by_subject[sub_id][acq] = diff\n",
    "            print(f\"Subject {sub_id}, acq {acq}: tedana={tedana_val}, base={base_val}, diff={diff}\")\n",
    "    \n",
    "    print(\"Sample of diff_by_subject:\")\n",
    "    for sub_id, diffs in list(diff_by_subject.items())[:2]:\n",
    "        print(f\"Subject {sub_id}: {diffs}\")\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject):\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject', 'headcoil'], value_vars=ACQ_PARAMS, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(FD_CSV_PATH)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me4)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    nan_count = df_merged['fd_mean'].isna().sum()\n",
    "    print(f\"\\nNumber of NaN fd_mean values after merge: {nan_count} out of {len(df_merged)} rows\")\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def create_scatter_plots(df):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    \n",
    "    colors = {20: 'royalblue', 64: 'darkorange'}\n",
    "    \n",
    "    for i, acq in enumerate(ACQ_PARAMS):\n",
    "        ax = axes[i]\n",
    "        acq_data = df[df['acq'] == acq]\n",
    "        sns.scatterplot(data=acq_data, x='fd_mean', y='tedana_minus_base', \n",
    "                        hue='headcoil', palette=colors, ax=ax, s=100)\n",
    "        ax.set_xlabel('Mean Framewise Displacement (fd_mean)', fontsize=16)\n",
    "        ax.set_title(f'Acquisition: {acq}', fontsize=18, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('VS beta (tedana - base)', fontsize=16)  # Updated label\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        if i == 2:\n",
    "            ax.legend(title='Headcoil', fontsize=14, title_fontsize=16)\n",
    "        else:\n",
    "            ax.legend().remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize_tedana_difference():\n",
    "    print(f\"Processing files for tedana - base difference: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}\")\n",
    "    \n",
    "    diff_by_subject = extract_file_data_with_difference()\n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    df = create_dataframe_with_fd(diff_by_subject)\n",
    "    \n",
    "    output_file = f\"multiecho_tedana_minus_base_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig = create_scatter_plots(df)\n",
    "    plot_file = f\"tedana_minus_base_scatter_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize_tedana_difference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c4857-6919-47e2-81e4-be3547293961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VS Act Rew>Pun, zstat (tedana - base difference) with fd_mean scatterplots\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters for this analysis\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"VS\"\n",
    "DENOISE_TEDANA = \"tedana\"\n",
    "DENOISE_BASE = \"base\"\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "FD_CSV_PATH = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "\n",
    "# Multi-echo acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil 64\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data_with_difference():\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {BASE_DIR}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in ACQ_PARAMS:\n",
    "                continue\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE and mask == MASK_VALUE and \n",
    "                denoise in [DENOISE_TEDANA, DENOISE_BASE]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                            for denoise in [DENOISE_TEDANA, DENOISE_BASE]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                except ValueError as e:\n",
    "                    print(f\"ValueError converting '{raw_content}' to float in {filename}: {e}\")\n",
    "                except IOError as e:\n",
    "                    print(f\"IOError reading {filename}: {e}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in ACQ_PARAMS:\n",
    "            tedana_val = data[DENOISE_TEDANA].get(acq, np.nan)\n",
    "            base_val = data[DENOISE_BASE].get(acq, np.nan)\n",
    "            diff_by_subject[sub_id][acq] = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject):\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject', 'headcoil'], value_vars=ACQ_PARAMS, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(FD_CSV_PATH)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me4)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def create_scatter_plots(df):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    \n",
    "    # Updated colors: red for 20, green for 64\n",
    "    colors = {20: 'red', 64: 'green'}\n",
    "    \n",
    "    for i, acq in enumerate(ACQ_PARAMS):\n",
    "        ax = axes[i]\n",
    "        acq_data = df[df['acq'] == acq].dropna(subset=['fd_mean', 'tedana_minus_base'])  # Drop NaNs for plotting\n",
    "        \n",
    "        # Scatterplot\n",
    "        sns.scatterplot(data=acq_data, x='fd_mean', y='tedana_minus_base', \n",
    "                        hue='headcoil', palette=colors, ax=ax, s=100)\n",
    "        \n",
    "        # Add trendlines for each headcoil group\n",
    "        for headcoil in [20, 64]:\n",
    "            group_data = acq_data[acq_data['headcoil'] == headcoil]\n",
    "            if not group_data.empty:\n",
    "                sns.regplot(data=group_data, x='fd_mean', y='tedana_minus_base', \n",
    "                            scatter=False, color=colors[headcoil], ax=ax)\n",
    "        \n",
    "        # Labels\n",
    "        ax.set_xlabel('Mean Framewise Displacement (fd_mean)', fontsize=16)\n",
    "        ax.set_title(f'Acquisition: {acq}', fontsize=18, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('VS beta (tedana - base)', fontsize=16)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        \n",
    "        # Custom legend with subject counts (only on the last plot)\n",
    "        if i == 2:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            n_20 = len(acq_data[acq_data['headcoil'] == 20]['subject'].unique())\n",
    "            n_64 = len(acq_data[acq_data['headcoil'] == 64]['subject'].unique())\n",
    "            new_labels = [f\"20 (n={n_20})\" if label == '20' else f\"64 (n={n_64})\" for label in labels]\n",
    "            ax.legend(handles, new_labels, title='Headcoil', fontsize=14, title_fontsize=16)\n",
    "        else:\n",
    "            ax.legend().remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize_tedana_difference():\n",
    "    print(f\"Processing files for tedana - base difference: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}\")\n",
    "    \n",
    "    diff_by_subject = extract_file_data_with_difference()\n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    df = create_dataframe_with_fd(diff_by_subject)\n",
    "    \n",
    "    output_file = f\"multiecho_tedana_minus_base_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig = create_scatter_plots(df)\n",
    "    plot_file = f\"tedana_minus_base_scatter_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize_tedana_difference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bac9e-f24a-44f7-99ab-953482eb6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC Act Rew>Pun, zstat (tedana - base difference) with fd_mean scatterplots\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters for this analysis\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"VMPFC\"\n",
    "DENOISE_TEDANA = \"tedana\"\n",
    "DENOISE_BASE = \"base\"\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "FD_CSV_PATH = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/code/fd_mean_values.csv\")\n",
    "\n",
    "# Multi-echo acquisition parameters\n",
    "ACQ_PARAMS = [\"mb1me4\", \"mb3me4\", \"mb6me4\"]\n",
    "\n",
    "# Subjects with headcoil 64\n",
    "HEADCOIL_64_SUBJECTS = [\n",
    "    \"10015\", \"10017\", \"10024\", \"10028\", \"10035\", \"10041\", \"10043\", \"10046\", \n",
    "    \"10054\", \"10059\", \"10069\", \"10074\", \"10078\", \"10080\", \"10085\", \"10094\", \n",
    "    \"10108\", \"10125\", \"10130\", \"10136\", \"10137\", \"10142\", \"10150\", \"10154\", \n",
    "    \"10186\", \"10188\", \"10221\"\n",
    "]\n",
    "\n",
    "def extract_file_data_with_difference():\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {BASE_DIR}\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' in sub_id or acq not in ACQ_PARAMS:\n",
    "                continue\n",
    "            if (file_type == TYPE_VALUE and img == IMG_VALUE and mask == MASK_VALUE and \n",
    "                denoise in [DENOISE_TEDANA, DENOISE_BASE]):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {\n",
    "                            denoise: {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                            for denoise in [DENOISE_TEDANA, DENOISE_BASE]\n",
    "                        }\n",
    "                    data_by_subject[sub_id][denoise][acq] = value\n",
    "                except ValueError as e:\n",
    "                    print(f\"ValueError converting '{raw_content}' to float in {filename}: {e}\")\n",
    "                except IOError as e:\n",
    "                    print(f\"IOError reading {filename}: {e}\")\n",
    "    \n",
    "    diff_by_subject = {}\n",
    "    for sub_id, data in data_by_subject.items():\n",
    "        diff_by_subject[sub_id] = {}\n",
    "        for acq in ACQ_PARAMS:\n",
    "            tedana_val = data[DENOISE_TEDANA].get(acq, np.nan)\n",
    "            base_val = data[DENOISE_BASE].get(acq, np.nan)\n",
    "            diff_by_subject[sub_id][acq] = tedana_val - base_val if not (np.isnan(tedana_val) or np.isnan(base_val)) else np.nan\n",
    "    \n",
    "    return diff_by_subject\n",
    "\n",
    "def create_dataframe_with_fd(diff_by_subject):\n",
    "    df = pd.DataFrame.from_dict(diff_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df['headcoil'] = df['subject'].apply(lambda x: 64 if x in HEADCOIL_64_SUBJECTS else 20)\n",
    "    column_order = ['subject', 'headcoil'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    df_long = df.melt(id_vars=['subject', 'headcoil'], value_vars=ACQ_PARAMS, \n",
    "                      var_name='acq', value_name='tedana_minus_base')\n",
    "    \n",
    "    fd_df = pd.read_csv(FD_CSV_PATH)\n",
    "    fd_df = fd_df.rename(columns={'Sub': 'subject', 'acq_base': 'acq'})\n",
    "    fd_df['subject'] = fd_df['subject'].str.replace('sub-', '', regex=False)\n",
    "    fd_df['acq'] = fd_df['acq'].str.extract(r'(mb[1-6]me4)')\n",
    "    \n",
    "    df_merged = pd.merge(df_long, fd_df[['subject', 'acq', 'fd_mean']], \n",
    "                         on=['subject', 'acq'], how='left')\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "def create_scatter_plots(df):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    \n",
    "    # Updated colors: red for 20, green for 64\n",
    "    colors = {20: 'red', 64: 'green'}\n",
    "    \n",
    "    for i, acq in enumerate(ACQ_PARAMS):\n",
    "        ax = axes[i]\n",
    "        acq_data = df[df['acq'] == acq].dropna(subset=['fd_mean', 'tedana_minus_base'])  # Drop NaNs for plotting\n",
    "        \n",
    "        # Scatterplot\n",
    "        sns.scatterplot(data=acq_data, x='fd_mean', y='tedana_minus_base', \n",
    "                        hue='headcoil', palette=colors, ax=ax, s=100)\n",
    "        \n",
    "        # Add trendlines for each headcoil group\n",
    "        for headcoil in [20, 64]:\n",
    "            group_data = acq_data[acq_data['headcoil'] == headcoil]\n",
    "            if not group_data.empty:\n",
    "                sns.regplot(data=group_data, x='fd_mean', y='tedana_minus_base', \n",
    "                            scatter=False, color=colors[headcoil], ax=ax)\n",
    "        \n",
    "        # Labels\n",
    "        ax.set_xlabel('Mean Framewise Displacement (fd_mean)', fontsize=16)\n",
    "        ax.set_title(f'Acquisition: {acq}', fontsize=18, fontweight='bold')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('VS beta (tedana - base)', fontsize=16)\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        \n",
    "        # Custom legend with subject counts (only on the last plot)\n",
    "        if i == 2:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            n_20 = len(acq_data[acq_data['headcoil'] == 20]['subject'].unique())\n",
    "            n_64 = len(acq_data[acq_data['headcoil'] == 64]['subject'].unique())\n",
    "            new_labels = [f\"20 (n={n_20})\" if label == '20' else f\"64 (n={n_64})\" for label in labels]\n",
    "            ax.legend(handles, new_labels, title='Headcoil', fontsize=14, title_fontsize=16)\n",
    "        else:\n",
    "            ax.legend().remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize_tedana_difference():\n",
    "    print(f\"Processing files for tedana - base difference: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}\")\n",
    "    \n",
    "    diff_by_subject = extract_file_data_with_difference()\n",
    "    if not diff_by_subject:\n",
    "        print(\"No matching files found.\")\n",
    "        return\n",
    "    \n",
    "    df = create_dataframe_with_fd(diff_by_subject)\n",
    "    \n",
    "    output_file = f\"multiecho_tedana_minus_base_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Found data for {len(df['subject'].unique())} subjects\")\n",
    "    print(\"\\nSample of the merged data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nCreating scatter plots...\")\n",
    "    fig = create_scatter_plots(df)\n",
    "    plot_file = f\"tedana_minus_base_scatter_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, fig = process_and_visualize_tedana_difference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440f476-dcd5-4295-bca8-9d1f65565057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC PPI Rew>Pun, zstat for \"sp\" subjects with custom acquisitions (20-channel only)\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"zstat\"\n",
    "MASK_VALUE = \"VS\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# New list of acquisition parameters\n",
    "ACQ_PARAMS = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "\n",
    "def extract_file_data():\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+[a-zA-Z]*)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {BASE_DIR}\")\n",
    "    \n",
    "    matched_files = 0\n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' not in sub_id:\n",
    "                continue\n",
    "            if (file_type.lower() == TYPE_VALUE.lower() and \n",
    "                img.lower() == IMG_VALUE.lower() and \n",
    "                mask.lower() == MASK_VALUE.lower() and \n",
    "                denoise.lower() == DENOISE_VALUE.lower() and \n",
    "                acq in ACQ_PARAMS):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    matched_files += 1\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Total matched files: {matched_files}\")\n",
    "    if data_by_subject:\n",
    "        print(\"Sample of data_by_subject:\")\n",
    "        for sub_id, data in list(data_by_subject.items())[:2]:\n",
    "            print(f\"Subject {sub_id}: {data}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    column_order = ['subject'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_plot_data(df):\n",
    "    means = {}\n",
    "    errors = {}\n",
    "    for acq in ACQ_PARAMS:\n",
    "        means[acq] = df[acq].mean()\n",
    "        errors[acq] = df[acq].sem()\n",
    "    results = {\n",
    "        'means': means,\n",
    "        'errors': errors,\n",
    "        'count': len(df)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def create_bar_plot(plot_data):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    \n",
    "    width = 0.8\n",
    "    means = [plot_data['means'][acq] for acq in ACQ_PARAMS]\n",
    "    errors = [plot_data['errors'][acq] for acq in ACQ_PARAMS]\n",
    "    count = plot_data['count']\n",
    "    \n",
    "    x_positions = np.arange(len(ACQ_PARAMS))\n",
    "    ax.bar(x_positions, means, width, color='lavender', yerr=errors, capsize=5)  # Changed to lavender\n",
    "    \n",
    "    ax.set_ylabel('VS zstat, Reward > Punishment', fontsize=16)\n",
    "    ax.set_title(f\"sp Subjects (n={count})\", fontsize=18, fontweight='bold')\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(ACQ_PARAMS, fontsize=14, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Acquisition', fontsize=16)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    y_values = means\n",
    "    y_errors = errors\n",
    "    y_min = min([v - e for v, e in zip(y_values, y_errors) if not np.isnan(v)])\n",
    "    y_max = max([v + e for v, e in zip(y_values, y_errors) if not np.isnan(v)])\n",
    "    margin = (y_max - y_min) * 0.1\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    data_by_subject = extract_file_data()\n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found for subjects with 'sp' in ID.\")\n",
    "        df = pd.DataFrame(columns=['subject'] + ACQ_PARAMS)\n",
    "        fig = plt.figure()\n",
    "    else:\n",
    "        df = create_dataframe(data_by_subject)\n",
    "        output_file = f\"multiecho_sp_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"Data saved to {output_file}\")\n",
    "        print(f\"Found data for {len(df)} subjects\")\n",
    "        print(\"\\nSample of the data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        plot_data = prepare_plot_data(df)\n",
    "        print(\"\\nCreating bar plot...\")\n",
    "        fig = create_bar_plot(plot_data)\n",
    "        \n",
    "        plot_file = f\"multiecho_sp_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df, fig = process_and_visualize()\n",
    "    except TypeError as e:\n",
    "        print(f\"Error during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea631cd-85dc-46f4-9949-1f543aa3d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VMPFC PPI Rew>Pun, beta for \"sp\" subjects with custom acquisitions (20-channel only)\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# Parameters\n",
    "TYPE_VALUE = \"act\"\n",
    "IMG_VALUE = \"beta\"\n",
    "MASK_VALUE = \"VS\"\n",
    "DENOISE_VALUE = \"base\"\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/GitHub/multiecho-pilot/derivatives/extractions\")\n",
    "\n",
    "# New list of acquisition parameters\n",
    "ACQ_PARAMS = [\"mb3me1fa50\", \"mb3me3\", \"mb3me3ip0\", \"mb2me4\", \"mb3me4\", \"mb3me4fa50\"]\n",
    "\n",
    "def extract_file_data():\n",
    "    pattern = re.compile(\n",
    "        r\"ts_sub-(\\d+[a-zA-Z]*)_acq_([^_]+)_type-(.+?)_img-([^_]+)_mask-([^_]+)_denoise_([^\\.]+)\\.txt\"\n",
    "    )\n",
    "    \n",
    "    data_by_subject = {}\n",
    "    file_paths = glob.glob(os.path.join(BASE_DIR, \"*.txt\"))\n",
    "    print(f\"Found {len(file_paths)} files in {BASE_DIR}\")\n",
    "    \n",
    "    matched_files = 0\n",
    "    for file_path in file_paths:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            sub_id, acq, file_type, img, mask, denoise = match.groups()\n",
    "            if 'sp' not in sub_id:\n",
    "                continue\n",
    "            if (file_type.lower() == TYPE_VALUE.lower() and \n",
    "                img.lower() == IMG_VALUE.lower() and \n",
    "                mask.lower() == MASK_VALUE.lower() and \n",
    "                denoise.lower() == DENOISE_VALUE.lower() and \n",
    "                acq in ACQ_PARAMS):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        raw_content = f.read().strip()\n",
    "                        value = float(raw_content)\n",
    "                    if sub_id not in data_by_subject:\n",
    "                        data_by_subject[sub_id] = {acq_param: np.nan for acq_param in ACQ_PARAMS}\n",
    "                    data_by_subject[sub_id][acq] = value\n",
    "                    matched_files += 1\n",
    "                except (ValueError, IOError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Total matched files: {matched_files}\")\n",
    "    if data_by_subject:\n",
    "        print(\"Sample of data_by_subject:\")\n",
    "        for sub_id, data in list(data_by_subject.items())[:2]:\n",
    "            print(f\"Subject {sub_id}: {data}\")\n",
    "    return data_by_subject\n",
    "\n",
    "def create_dataframe(data_by_subject):\n",
    "    df = pd.DataFrame.from_dict(data_by_subject, orient='index')\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "    \n",
    "    column_order = ['subject'] + ACQ_PARAMS\n",
    "    df = df[column_order]\n",
    "    df.sort_values('subject', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_plot_data(df):\n",
    "    means = {}\n",
    "    errors = {}\n",
    "    for acq in ACQ_PARAMS:\n",
    "        means[acq] = df[acq].mean()\n",
    "        errors[acq] = df[acq].sem()\n",
    "    results = {\n",
    "        'means': means,\n",
    "        'errors': errors,\n",
    "        'count': len(df)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def create_bar_plot(plot_data):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    \n",
    "    width = 0.8\n",
    "    means = [plot_data['means'][acq] for acq in ACQ_PARAMS]\n",
    "    errors = [plot_data['errors'][acq] for acq in ACQ_PARAMS]\n",
    "    count = plot_data['count']\n",
    "    \n",
    "    x_positions = np.arange(len(ACQ_PARAMS))\n",
    "    ax.bar(x_positions, means, width, color='lavender', yerr=errors, capsize=5)  # Changed to lavender\n",
    "    \n",
    "    ax.set_ylabel('VS beta, Reward > Punishment', fontsize=16)\n",
    "    ax.set_title(f\"sp Subjects (n={count})\", fontsize=18, fontweight='bold')\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(ACQ_PARAMS, fontsize=14, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Acquisition', fontsize=16)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    y_values = means\n",
    "    y_errors = errors\n",
    "    y_min = min([v - e for v, e in zip(y_values, y_errors) if not np.isnan(v)])\n",
    "    y_max = max([v + e for v, e in zip(y_values, y_errors) if not np.isnan(v)])\n",
    "    margin = (y_max - y_min) * 0.1\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_and_visualize():\n",
    "    print(f\"Processing files with parameters: type={TYPE_VALUE}, img={IMG_VALUE}, mask={MASK_VALUE}, denoise={DENOISE_VALUE}\")\n",
    "    \n",
    "    data_by_subject = extract_file_data()\n",
    "    if not data_by_subject:\n",
    "        print(\"No matching files found for subjects with 'sp' in ID.\")\n",
    "        df = pd.DataFrame(columns=['subject'] + ACQ_PARAMS)\n",
    "        fig = plt.figure()\n",
    "    else:\n",
    "        df = create_dataframe(data_by_subject)\n",
    "        output_file = f\"multiecho_sp_data_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"Data saved to {output_file}\")\n",
    "        print(f\"Found data for {len(df)} subjects\")\n",
    "        print(\"\\nSample of the data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        plot_data = prepare_plot_data(df)\n",
    "        print(\"\\nCreating bar plot...\")\n",
    "        fig = create_bar_plot(plot_data)\n",
    "        \n",
    "        plot_file = f\"multiecho_sp_plots_{TYPE_VALUE}_{IMG_VALUE}_{MASK_VALUE}_{DENOISE_VALUE}.png\"\n",
    "        plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as '{plot_file}'\")\n",
    "    \n",
    "    return df, fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df, fig = process_and_visualize()\n",
    "    except TypeError as e:\n",
    "        print(f\"Error during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb356244-01b2-4cb3-a804-9fdb63e8cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
